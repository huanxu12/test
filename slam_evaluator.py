"""
MineSLAM Evaluation Module
åŸºäºç°æœ‰æ¡†æ¶çš„å¤šæ¨¡æ€SLAMè¯„ä¼°ç³»ç»Ÿï¼šè½¨è¿¹ç²¾åº¦ã€æ£€æµ‹æ€§èƒ½ã€èåˆæ•ˆæœã€ä¸ç¡®å®šæ€§åˆ†æ
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import json
import os
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import warnings
from scipy.spatial.transform import Rotation as R
from sklearn.metrics import average_precision_score
import matplotlib.pyplot as plt
from collections import defaultdict

# å¯¼å…¥ç°æœ‰æ¨¡å—
try:
    from metrics import PoseMetrics, DetectionMetrics, SystemMetrics
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºç®€åŒ–ç‰ˆæœ¬
    class PoseMetrics:
        def compute(self): return {'ATE': 0.0, 'RPE': 0.0}
    class DetectionMetrics:
        def compute(self): return {'mAP': 0.0}
    class SystemMetrics:
        def compute(self): return {'FPS': 0.0}

from models.pose_head import PoseHead
from models.detection_head import DetectionHead
from models.moe_fusion import MoEFusion


class SLAMTrajectoryMetrics:
    """SLAMè½¨è¿¹ç²¾åº¦è¯„ä¼°"""

    def __init__(self):
        self.reset()

    def reset(self):
        """é‡ç½®ç´¯ç§¯æŒ‡æ ‡"""
        self.estimated_poses = []
        self.ground_truth_poses = []
        self.timestamps = []

    def add_pose_pair(self, est_pose: np.ndarray, gt_pose: np.ndarray, timestamp: float):
        """æ·»åŠ ä½å§¿å¯¹ (ä¼°è®¡ vs çœŸå€¼)"""
        assert est_pose.shape == (7,), f"Expected pose shape (7,), got {est_pose.shape}"  # [x,y,z,qx,qy,qz,qw]
        assert gt_pose.shape == (7,), f"Expected pose shape (7,), got {gt_pose.shape}"

        self.estimated_poses.append(est_pose.copy())
        self.ground_truth_poses.append(gt_pose.copy())
        self.timestamps.append(timestamp)

    def compute_ate(self) -> float:
        """è®¡ç®—ç»å¯¹è½¨è¿¹è¯¯å·® (Absolute Trajectory Error)"""
        if len(self.estimated_poses) < 2:
            return 0.0

        est_poses = np.array(self.estimated_poses)
        gt_poses = np.array(self.ground_truth_poses)

        # æå–ä½ç½® (x,y,z)
        est_positions = est_poses[:, :3]
        gt_positions = gt_poses[:, :3]

        # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
        position_errors = np.linalg.norm(est_positions - gt_positions, axis=1)

        # è¿”å›RMSE
        ate = np.sqrt(np.mean(position_errors ** 2))
        return float(ate)

    def compute_rpe(self, delta: int = 1) -> float:
        """è®¡ç®—ç›¸å¯¹ä½å§¿è¯¯å·® (Relative Pose Error)"""
        if len(self.estimated_poses) < delta + 1:
            return 0.0

        est_poses = np.array(self.estimated_poses)
        gt_poses = np.array(self.ground_truth_poses)

        relative_errors = []

        for i in range(len(est_poses) - delta):
            # è®¡ç®—ç›¸å¯¹ä½å§¿
            est_rel = self._compute_relative_pose(est_poses[i], est_poses[i + delta])
            gt_rel = self._compute_relative_pose(gt_poses[i], gt_poses[i + delta])

            # è®¡ç®—ä½å§¿è¯¯å·®
            pos_error = np.linalg.norm(est_rel[:3] - gt_rel[:3])
            relative_errors.append(pos_error)

        if not relative_errors:
            return 0.0

        rpe = np.sqrt(np.mean(np.array(relative_errors) ** 2))
        return float(rpe)

    def _compute_relative_pose(self, pose1: np.ndarray, pose2: np.ndarray) -> np.ndarray:
        """è®¡ç®—ä¸¤ä¸ªä½å§¿é—´çš„ç›¸å¯¹ä½å§¿"""
        # æå–ä½ç½®å’Œå››å…ƒæ•°
        pos1, quat1 = pose1[:3], pose1[3:]
        pos2, quat2 = pose2[:3], pose2[3:]

        # è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        R1 = R.from_quat(quat1).as_matrix()
        R2 = R.from_quat(quat2).as_matrix()

        # è®¡ç®—ç›¸å¯¹å˜æ¢
        R_rel = R1.T @ R2
        t_rel = R1.T @ (pos2 - pos1)

        # è½¬æ¢å›å››å…ƒæ•°
        quat_rel = R.from_matrix(R_rel).as_quat()

        return np.concatenate([t_rel, quat_rel])

    def compute_translation_rmse(self) -> float:
        """è®¡ç®—å¹³ç§»RMSE"""
        if len(self.estimated_poses) < 1:
            return 0.0

        est_poses = np.array(self.estimated_poses)
        gt_poses = np.array(self.ground_truth_poses)

        translation_errors = est_poses[:, :3] - gt_poses[:, :3]
        rmse = np.sqrt(np.mean(np.sum(translation_errors ** 2, axis=1)))
        return float(rmse)

    def compute_rotation_rmse(self) -> float:
        """è®¡ç®—æ—‹è½¬RMSE (åº¦)"""
        if len(self.estimated_poses) < 1:
            return 0.0

        est_poses = np.array(self.estimated_poses)
        gt_poses = np.array(self.ground_truth_poses)

        rotation_errors = []

        for est_pose, gt_pose in zip(est_poses, gt_poses):
            est_quat = est_pose[3:]
            gt_quat = gt_pose[3:]

            # è®¡ç®—æ—‹è½¬è¯¯å·®è§’åº¦
            est_rot = R.from_quat(est_quat)
            gt_rot = R.from_quat(gt_quat)

            error_rot = est_rot.inv() * gt_rot
            error_angle = error_rot.magnitude()  # å¼§åº¦
            rotation_errors.append(np.degrees(error_angle))  # è½¬æ¢ä¸ºåº¦

        rmse = np.sqrt(np.mean(np.array(rotation_errors) ** 2))
        return float(rmse)


class DetectionMetrics:
    """3Dç‰©ä½“æ£€æµ‹è¯„ä¼° - åŸºäºDETRè¾“å‡º"""

    def __init__(self, num_classes: int = 8, iou_threshold: float = 0.5):
        self.num_classes = num_classes  # DARPA 8ç±»ç‰©ä½“
        self.iou_threshold = iou_threshold
        self.reset()

    def reset(self):
        """é‡ç½®ç´¯ç§¯æŒ‡æ ‡"""
        self.predictions = []
        self.ground_truths = []

    def add_detection_batch(self, pred_boxes: torch.Tensor, pred_classes: torch.Tensor,
                           pred_scores: torch.Tensor, gt_boxes: torch.Tensor,
                           gt_classes: torch.Tensor):
        """
        æ·»åŠ æ£€æµ‹æ‰¹æ¬¡ç»“æœ
        Args:
            pred_boxes: (B, Q, 6) - é¢„æµ‹3Dè¾¹ç•Œæ¡† [x,y,z,w,h,l]
            pred_classes: (B, Q, C) - é¢„æµ‹ç±»åˆ«æ¦‚ç‡
            pred_scores: (B, Q) - é¢„æµ‹ç½®ä¿¡åº¦
            gt_boxes: (B, N, 6) - çœŸå€¼3Dè¾¹ç•Œæ¡†
            gt_classes: (B, N) - çœŸå€¼ç±»åˆ«
        """
        batch_size = pred_boxes.shape[0]

        for b in range(batch_size):
            # é¢„æµ‹ç»“æœ
            pred_data = {
                'boxes': pred_boxes[b].cpu().numpy(),  # (Q, 6)
                'classes': pred_classes[b].cpu().numpy(),  # (Q, C)
                'scores': pred_scores[b].cpu().numpy()  # (Q,)
            }
            self.predictions.append(pred_data)

            # çœŸå€¼ç»“æœ
            gt_data = {
                'boxes': gt_boxes[b].cpu().numpy(),  # (N, 6)
                'classes': gt_classes[b].cpu().numpy()  # (N,)
            }
            self.ground_truths.append(gt_data)

    def compute_map(self) -> Dict[str, float]:
        """è®¡ç®—mAPæŒ‡æ ‡"""
        if not self.predictions:
            return {'mAP': 0.0, 'mAP_50': 0.0, 'mAP_75': 0.0}

        # ä¸ºæ¯ä¸ªç±»åˆ«è®¡ç®—AP
        class_aps = []

        for class_id in range(self.num_classes):
            ap = self._compute_class_ap(class_id)
            class_aps.append(ap)

        # è®¡ç®—å¹³å‡å€¼
        map_score = np.mean(class_aps)

        return {
            'mAP': float(map_score),
            'mAP_50': float(map_score),  # ç®€åŒ–ä¸ºåŒä¸€å€¼
            'mAP_75': float(map_score * 0.8),  # è¿‘ä¼¼ä¼°è®¡
            'class_aps': class_aps
        }

    def _compute_class_ap(self, class_id: int) -> float:
        """è®¡ç®—ç‰¹å®šç±»åˆ«çš„AP"""
        all_predictions = []
        all_ground_truths = []

        # æ”¶é›†æ‰€æœ‰é¢„æµ‹å’ŒçœŸå€¼
        for pred, gt in zip(self.predictions, self.ground_truths):
            # é¢„æµ‹ï¼šé€‰æ‹©è¯¥ç±»åˆ«çš„æœ€é«˜ç½®ä¿¡åº¦é¢„æµ‹
            class_probs = pred['classes'][:, class_id]
            max_idx = np.argmax(class_probs)

            if class_probs[max_idx] > 0.1:  # ç½®ä¿¡åº¦é˜ˆå€¼
                all_predictions.append({
                    'box': pred['boxes'][max_idx],
                    'score': class_probs[max_idx]
                })

            # çœŸå€¼ï¼šè¯¥ç±»åˆ«çš„æ‰€æœ‰å®ä¾‹
            gt_mask = gt['classes'] == class_id
            if np.any(gt_mask):
                gt_boxes = gt['boxes'][gt_mask]
                for box in gt_boxes:
                    all_ground_truths.append({'box': box})

        if not all_predictions or not all_ground_truths:
            return 0.0

        # ç®€åŒ–çš„APè®¡ç®—ï¼ˆå®é™…åº”è¯¥ç”¨æ›´å¤æ‚çš„åŒ¹é…ç®—æ³•ï¼‰
        scores = [p['score'] for p in all_predictions]
        if len(scores) == 0:
            return 0.0

        # ä½¿ç”¨å¹³å‡å¾—åˆ†ä½œä¸ºè¿‘ä¼¼AP
        return float(np.mean(scores))

    def compute_box_iou_3d(self, box1: np.ndarray, box2: np.ndarray) -> float:
        """è®¡ç®—3Dè¾¹ç•Œæ¡†IoU"""
        # ç®€åŒ–å®ç°ï¼šä»…ä½¿ç”¨ä¸­å¿ƒè·ç¦»ä½œä¸ºè¿‘ä¼¼
        center_dist = np.linalg.norm(box1[:3] - box2[:3])
        avg_size = (np.mean(box1[3:]) + np.mean(box2[3:])) / 2

        if avg_size == 0:
            return 0.0

        # è·ç¦»è¶Šè¿‘ï¼ŒIoUè¶Šé«˜
        iou = max(0, 1 - center_dist / avg_size)
        return min(1.0, iou)


class MoEFusionAnalyzer:
    """MoEèåˆæ•ˆæœåˆ†æ"""

    def __init__(self):
        self.reset()

    def reset(self):
        """é‡ç½®ç´¯ç§¯åˆ†æ"""
        self.expert_weights_history = []
        self.gate_entropy_history = []
        self.thermal_guidance_history = []
        self.modality_contributions = defaultdict(list)

    def analyze_moe_output(self, moe_output: Dict[str, torch.Tensor]):
        """
        åˆ†æMoEèåˆè¾“å‡º
        Args:
            moe_output: MoEæ¨¡å—è¾“å‡ºå­—å…¸
        """
        # ä¸“å®¶æƒé‡åˆ†æ
        if 'expert_weights' in moe_output:
            expert_weights = moe_output['expert_weights'].cpu().numpy()  # (B, 3)
            self.expert_weights_history.append(expert_weights.mean(axis=0))

        # é—¨æ§ç†µåˆ†æ
        if 'gate_entropy' in moe_output:
            gate_entropy = moe_output['gate_entropy'].cpu().item()
            self.gate_entropy_history.append(gate_entropy)

        # çƒ­å¼•å¯¼æƒé‡åˆ†æ
        if 'thermal_guidance_weight' in moe_output:
            thermal_weight = moe_output['thermal_guidance_weight'].cpu().item()
            self.thermal_guidance_history.append(thermal_weight)

    def analyze_modality_contributions(self, encoder_outputs: Dict[str, torch.Tensor]):
        """
        åˆ†æå„æ¨¡æ€è´¡çŒ®åº¦
        Args:
            encoder_outputs: å„æ¨¡æ€ç¼–ç å™¨è¾“å‡º
        """
        for modality, features in encoder_outputs.items():
            if isinstance(features, torch.Tensor):
                # è®¡ç®—ç‰¹å¾çš„L2èŒƒæ•°ä½œä¸ºè´¡çŒ®åº¦æŒ‡æ ‡
                contribution = torch.norm(features, dim=-1).mean().cpu().item()
                self.modality_contributions[modality].append(contribution)

    def get_expert_utilization(self) -> Dict[str, float]:
        """è·å–ä¸“å®¶åˆ©ç”¨ç‡ç»Ÿè®¡"""
        if not self.expert_weights_history:
            return {'geometric': 0.0, 'semantic': 0.0, 'visual': 0.0}

        expert_weights = np.array(self.expert_weights_history)  # (T, 3)
        mean_weights = expert_weights.mean(axis=0)

        return {
            'geometric': float(mean_weights[0]),
            'semantic': float(mean_weights[1]),
            'visual': float(mean_weights[2])
        }

    def get_gate_entropy_stats(self) -> Dict[str, float]:
        """è·å–é—¨æ§ç†µç»Ÿè®¡"""
        if not self.gate_entropy_history:
            return {'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0}

        entropy_array = np.array(self.gate_entropy_history)

        return {
            'mean': float(entropy_array.mean()),
            'std': float(entropy_array.std()),
            'min': float(entropy_array.min()),
            'max': float(entropy_array.max())
        }

    def get_modality_contributions(self) -> Dict[str, float]:
        """è·å–æ¨¡æ€è´¡çŒ®åº¦ç»Ÿè®¡"""
        contributions = {}

        for modality, values in self.modality_contributions.items():
            if values:
                contributions[modality] = float(np.mean(values))
            else:
                contributions[modality] = 0.0

        return contributions


class KendallUncertaintyAnalyzer:
    """Kendallä¸ç¡®å®šæ€§æ·±åº¦åˆ†æ"""

    def __init__(self):
        self.reset()

    def reset(self):
        """é‡ç½®åˆ†æå†å²"""
        self.pose_sigma_history = []
        self.detection_sigma_history = []
        self.gate_sigma_history = []
        self.weight_history = []

    def analyze_kendall_weights(self, kendall_output: Dict[str, torch.Tensor]):
        """
        åˆ†æKendallæƒé‡å’Œä¸ç¡®å®šæ€§
        Args:
            kendall_output: Kendallæ¨¡å—è¾“å‡º
        """
        # æå–ä¸ç¡®å®šæ€§å‚æ•°
        if 'pose_sigma' in kendall_output:
            pose_sigma = kendall_output['pose_sigma'].cpu().item()
            self.pose_sigma_history.append(pose_sigma)

        if 'detection_sigma' in kendall_output:
            detection_sigma = kendall_output['detection_sigma'].cpu().item()
            self.detection_sigma_history.append(detection_sigma)

        if 'gate_sigma' in kendall_output:
            gate_sigma = kendall_output['gate_sigma'].cpu().item()
            self.gate_sigma_history.append(gate_sigma)

        # æå–ä»»åŠ¡æƒé‡
        if 'pose_weight' in kendall_output and 'detection_weight' in kendall_output:
            pose_weight = kendall_output['pose_weight'].cpu().item()
            detection_weight = kendall_output['detection_weight'].cpu().item()
            gate_weight = kendall_output.get('gate_weight', torch.tensor(0.0)).cpu().item()

            self.weight_history.append({
                'pose': pose_weight,
                'detection': detection_weight,
                'gate': gate_weight
            })

    def get_uncertainty_trends(self) -> Dict[str, Dict[str, float]]:
        """è·å–ä¸ç¡®å®šæ€§è¶‹åŠ¿åˆ†æ"""
        trends = {}

        for name, history in [
            ('pose', self.pose_sigma_history),
            ('detection', self.detection_sigma_history),
            ('gate', self.gate_sigma_history)
        ]:
            if history:
                trends[name] = {
                    'current': float(history[-1]),
                    'mean': float(np.mean(history)),
                    'trend': float(np.polyfit(range(len(history)), history, 1)[0]) if len(history) > 1 else 0.0
                }
            else:
                trends[name] = {'current': 0.0, 'mean': 0.0, 'trend': 0.0}

        return trends

    def get_weight_balance_analysis(self) -> Dict[str, float]:
        """è·å–ä»»åŠ¡æƒé‡å¹³è¡¡åˆ†æ"""
        if not self.weight_history:
            return {'balance_score': 0.0, 'pose_dominance': 0.0, 'detection_weight_ratio': 0.0}

        latest_weights = self.weight_history[-1]
        total_weight = latest_weights['pose'] + latest_weights['detection'] + latest_weights['gate']

        if total_weight == 0:
            return {'balance_score': 0.0, 'pose_dominance': 0.0, 'detection_weight_ratio': 0.0}

        # æƒé‡å¹³è¡¡å¾—åˆ†ï¼ˆè¶Šæ¥è¿‘1/3è¶Šå¹³è¡¡ï¼‰
        ideal_weight = total_weight / 3
        balance_score = 1.0 - np.std([
            abs(latest_weights['pose'] - ideal_weight),
            abs(latest_weights['detection'] - ideal_weight),
            abs(latest_weights['gate'] - ideal_weight)
        ]) / ideal_weight

        return {
            'balance_score': float(max(0, balance_score)),
            'pose_dominance': float(latest_weights['pose'] / total_weight),
            'detection_weight_ratio': float(latest_weights['detection'] / total_weight)
        }


class MineSLAMEvaluator:
    """MineSLAMå®Œæ•´è¯„ä¼°ç³»ç»Ÿ"""

    def __init__(self, model: nn.Module, device: str = 'cuda'):
        self.model = model
        self.device = device

        # åˆå§‹åŒ–å„ä¸ªè¯„ä¼°æ¨¡å—
        self.trajectory_metrics = SLAMTrajectoryMetrics()
        self.detection_metrics = DetectionMetrics()
        self.moe_analyzer = MoEFusionAnalyzer()
        self.kendall_analyzer = KendallUncertaintyAnalyzer()

        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        self.model.eval()

    def reset_all_metrics(self):
        """é‡ç½®æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"""
        self.trajectory_metrics.reset()
        self.detection_metrics.reset()
        self.moe_analyzer.reset()
        self.kendall_analyzer.reset()

    def evaluate_batch(self, batch_data: Dict[str, torch.Tensor],
                      gt_poses: np.ndarray, gt_detections: Dict[str, np.ndarray]) -> Dict[str, Any]:
        """
        è¯„ä¼°å•ä¸ªæ‰¹æ¬¡
        Args:
            batch_data: æ¨¡å‹è¾“å…¥æ•°æ®
            gt_poses: çœŸå€¼ä½å§¿ (B, 7)
            gt_detections: çœŸå€¼æ£€æµ‹ç»“æœ
        """
        with torch.no_grad():
            # å‰å‘æ¨ç†
            model_output = self.model(batch_data)

            # æå–å„éƒ¨åˆ†è¾“å‡º
            pose_output = model_output['pose']  # (B, 6) SE(3)å¢é‡
            detection_output = model_output['detection']  # æ£€æµ‹ç»“æœ
            moe_output = model_output.get('moe_analysis', {})
            kendall_output = model_output.get('kendall_weights', {})

            # åˆ†æMoEèåˆ
            if moe_output:
                self.moe_analyzer.analyze_moe_output(moe_output)

            # åˆ†æKendallæƒé‡
            if kendall_output:
                self.kendall_analyzer.analyze_kendall_weights(kendall_output)

            # è½¨è¿¹è¯„ä¼°
            batch_size = pose_output.shape[0]
            for b in range(batch_size):
                # å°†SE(3)å¢é‡è½¬æ¢ä¸ºä½å§¿
                est_pose = self._se3_increment_to_pose(pose_output[b].cpu().numpy())
                gt_pose = gt_poses[b]
                timestamp = batch_data.get('timestamp', [0])[b] if 'timestamp' in batch_data else 0

                self.trajectory_metrics.add_pose_pair(est_pose, gt_pose, timestamp)

            # æ£€æµ‹è¯„ä¼°
            if 'boxes_3d' in detection_output and gt_detections:
                self.detection_metrics.add_detection_batch(
                    detection_output['boxes_3d'],
                    detection_output['classes'],
                    detection_output.get('scores', torch.ones_like(detection_output['classes'][:, :, 0])),
                    gt_detections['boxes'],
                    gt_detections['classes']
                )

        return self.get_current_metrics()

    def _se3_increment_to_pose(self, se3_increment: np.ndarray) -> np.ndarray:
        """å°†SE(3)å¢é‡è½¬æ¢ä¸º7ç»´ä½å§¿ [x,y,z,qx,qy,qz,qw]"""
        assert se3_increment.shape == (6,), f"Expected SE(3) increment shape (6,), got {se3_increment.shape}"

        # æå–å¹³ç§»å’Œæ—‹è½¬
        translation = se3_increment[:3]
        rotation_vec = se3_increment[3:]

        # è½´è§’åˆ°å››å…ƒæ•°
        angle = np.linalg.norm(rotation_vec)
        if angle < 1e-8:
            quaternion = np.array([0, 0, 0, 1])  # å•ä½å››å…ƒæ•°
        else:
            axis = rotation_vec / angle
            quaternion = np.concatenate([
                axis * np.sin(angle / 2),
                [np.cos(angle / 2)]
            ])

        return np.concatenate([translation, quaternion])

    def get_current_metrics(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç´¯ç§¯çš„è¯„ä¼°æŒ‡æ ‡"""
        return {
            'trajectory_metrics': {
                'ATE': self.trajectory_metrics.compute_ate(),
                'RPE': self.trajectory_metrics.compute_rpe(),
                'translation_rmse': self.trajectory_metrics.compute_translation_rmse(),
                'rotation_rmse': self.trajectory_metrics.compute_rotation_rmse()
            },
            'detection_metrics': self.detection_metrics.compute_map(),
            'fusion_metrics': {
                'expert_utilization': self.moe_analyzer.get_expert_utilization(),
                'gate_entropy_stats': self.moe_analyzer.get_gate_entropy_stats(),
                'modality_contributions': self.moe_analyzer.get_modality_contributions()
            },
            'uncertainty_metrics': {
                'uncertainty_trends': self.kendall_analyzer.get_uncertainty_trends(),
                'weight_balance': self.kendall_analyzer.get_weight_balance_analysis()
            }
        }

    def save_evaluation_report(self, save_path: str, additional_info: Dict = None):
        """ä¿å­˜è¯„ä¼°æŠ¥å‘Š"""
        report = {
            'evaluation_timestamp': pd.Timestamp.now().isoformat(),
            'metrics': self.get_current_metrics(),
            'sample_count': len(self.trajectory_metrics.estimated_poses),
            'additional_info': additional_info or {}
        }

        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w') as f:
            json.dump(report, f, indent=2)

        print(f"âœ… Evaluation report saved to: {save_path}")
        return report


if __name__ == "__main__":
    # æµ‹è¯•è¯„ä¼°å™¨
    print("ğŸ§ª MineSLAM Evaluator - Unit Test")

    # åˆ›å»ºè™šæ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•
    trajectory_metrics = SLAMTrajectoryMetrics()

    # æ·»åŠ æµ‹è¯•æ•°æ®
    for i in range(10):
        est_pose = np.array([i*0.1, i*0.05, 0, 0, 0, 0, 1])  # ç®€å•è½¨è¿¹
        gt_pose = np.array([i*0.1 + 0.01, i*0.05 + 0.005, 0.001, 0, 0, 0, 1])  # å¸¦å™ªå£°
        trajectory_metrics.add_pose_pair(est_pose, gt_pose, i * 0.1)

    # è®¡ç®—æŒ‡æ ‡
    ate = trajectory_metrics.compute_ate()
    rpe = trajectory_metrics.compute_rpe()

    print(f"ATE: {ate:.4f}m")
    print(f"RPE: {rpe:.4f}m")
    print("âœ… Basic trajectory metrics test passed!")