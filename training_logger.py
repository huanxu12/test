"""
Advanced Training Logger for MineSLAM
é«˜çº§è®­ç»ƒæ—¥å¿—è®°å½•ç³»ç»Ÿï¼šè®°å½•çœŸå®æ•°æ®çš„ATE/RPE/mAP/FPSã€é—¨æ§æƒé‡ã€GPUæ˜¾å­˜
"""

import os
import sys
import json
import time
import csv
import threading
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
from datetime import datetime
import logging

import torch
import numpy as np
from collections import defaultdict, deque


class MetricsBuffer:
    """
    Metrics Buffer with Statistical Analysis
    å¸¦ç»Ÿè®¡åˆ†æçš„æŒ‡æ ‡ç¼“å†²åŒº
    """

    def __init__(self, maxlen: int = 1000):
        """
        Args:
            maxlen: ç¼“å†²åŒºæœ€å¤§é•¿åº¦
        """
        self.maxlen = maxlen
        self.data = deque(maxlen=maxlen)
        self.timestamps = deque(maxlen=maxlen)

    def add(self, value: float, timestamp: Optional[float] = None):
        """æ·»åŠ æ•°æ®ç‚¹"""
        if timestamp is None:
            timestamp = time.time()

        self.data.append(value)
        self.timestamps.append(timestamp)

    def get_statistics(self, window: Optional[int] = None) -> Dict[str, float]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.data:
            return {}

        # é€‰æ‹©çª—å£æ•°æ®
        if window is not None and window < len(self.data):
            data = list(self.data)[-window:]
        else:
            data = list(self.data)

        if not data:
            return {}

        return {
            'mean': np.mean(data),
            'std': np.std(data),
            'min': np.min(data),
            'max': np.max(data),
            'median': np.median(data),
            'count': len(data),
            'latest': data[-1] if data else 0.0
        }

    def get_recent_trend(self, window: int = 10) -> Optional[float]:
        """è·å–æœ€è¿‘è¶‹åŠ¿ï¼ˆæ­£æ•°è¡¨ç¤ºä¸Šå‡ï¼Œè´Ÿæ•°è¡¨ç¤ºä¸‹é™ï¼‰"""
        if len(self.data) < window:
            return None

        recent_data = list(self.data)[-window:]
        x = np.arange(len(recent_data))
        y = np.array(recent_data)

        # ç®€å•çº¿æ€§å›å½’æ±‚æ–œç‡
        if len(x) > 1:
            slope = np.polyfit(x, y, 1)[0]
            return float(slope)

        return None


class GPUMonitor:
    """
    GPU Memory and Utilization Monitor
    GPUå†…å­˜å’Œåˆ©ç”¨ç‡ç›‘æ§å™¨
    """

    def __init__(self):
        self.available = torch.cuda.is_available()
        if self.available:
            self.device_count = torch.cuda.device_count()
            self.device_names = [torch.cuda.get_device_name(i)
                               for i in range(self.device_count)]
        else:
            self.device_count = 0
            self.device_names = []

    def get_memory_info(self, device_id: int = 0) -> Dict[str, float]:
        """è·å–GPUå†…å­˜ä¿¡æ¯ï¼ˆMBï¼‰"""
        if not self.available or device_id >= self.device_count:
            return {'allocated': 0.0, 'cached': 0.0, 'total': 0.0}

        try:
            allocated = torch.cuda.memory_allocated(device_id) / 1024 / 1024
            cached = torch.cuda.memory_reserved(device_id) / 1024 / 1024
            total = torch.cuda.get_device_properties(device_id).total_memory / 1024 / 1024

            return {
                'allocated': allocated,
                'cached': cached,
                'total': total,
                'free': total - cached,
                'utilization': allocated / total * 100 if total > 0 else 0.0
            }
        except:
            return {'allocated': 0.0, 'cached': 0.0, 'total': 0.0}

    def get_all_devices_info(self) -> Dict[str, Dict[str, float]]:
        """è·å–æ‰€æœ‰GPUè®¾å¤‡ä¿¡æ¯"""
        info = {}
        for i in range(self.device_count):
            info[f'gpu_{i}'] = self.get_memory_info(i)
            info[f'gpu_{i}']['name'] = self.device_names[i]

        return info


class TrainingLogger:
    """
    Comprehensive Training Logger
    ç»¼åˆè®­ç»ƒæ—¥å¿—è®°å½•å™¨
    """

    def __init__(self, log_dir: str, experiment_name: str = None,
                 save_interval: int = 100, buffer_size: int = 1000):
        """
        Args:
            log_dir: æ—¥å¿—ç›®å½•
            experiment_name: å®éªŒåç§°
            save_interval: ä¿å­˜é—´éš”ï¼ˆæ­¥æ•°ï¼‰
            buffer_size: ç¼“å†²åŒºå¤§å°
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # å®éªŒåç§°å’Œæ—¶é—´æˆ³
        if experiment_name is None:
            experiment_name = f"mineslam_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.experiment_name = experiment_name

        self.save_interval = save_interval
        self.step_count = 0

        # æ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.log_files = {
            'training': self.log_dir / f'{experiment_name}_training.log',
            'metrics': self.log_dir / f'{experiment_name}_metrics.json',
            'csv': self.log_dir / f'{experiment_name}_metrics.csv',
            'weights': self.log_dir / f'{experiment_name}_weights.json',
            'gpu': self.log_dir / f'{experiment_name}_gpu.json'
        }

        # è®¾ç½®Pythonæ—¥å¿—
        self.logger = self._setup_logger()

        # æŒ‡æ ‡ç¼“å†²åŒº
        self.metrics_buffers = {
            'train_loss': MetricsBuffer(buffer_size),
            'val_loss': MetricsBuffer(buffer_size),
            'ate': MetricsBuffer(buffer_size),
            'rpe': MetricsBuffer(buffer_size),
            'map': MetricsBuffer(buffer_size),
            'fps': MetricsBuffer(buffer_size),
            'gpu_memory': MetricsBuffer(buffer_size),
            'learning_rate': MetricsBuffer(buffer_size)
        }

        # GPUç›‘æ§å™¨
        self.gpu_monitor = GPUMonitor()

        # å†å²è®°å½•
        self.training_history = []
        self.kendall_weights_history = []
        self.gpu_history = []

        # æœ€ä½³æŒ‡æ ‡è®°å½•
        self.best_metrics = {
            'best_ate': float('inf'),
            'best_rpe': float('inf'),
            'best_map': 0.0,
            'best_val_loss': float('inf'),
            'best_epoch': 0
        }

        # åˆå§‹åŒ–CSVæ–‡ä»¶
        self._init_csv_file()

        self.logger.info(f"TrainingLogger initialized: {experiment_name}")
        self.logger.info(f"Log directory: {self.log_dir}")
        self.logger.info(f"GPU available: {self.gpu_monitor.available}")

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®Pythonæ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(f'MineSLAM_{self.experiment_name}')
        logger.setLevel(logging.INFO)

        # é¿å…é‡å¤æ·»åŠ handler
        if logger.handlers:
            logger.handlers.clear()

        # æ–‡ä»¶handler
        file_handler = logging.FileHandler(self.log_files['training'])
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)

        # æ§åˆ¶å°handler
        console_handler = logging.StreamHandler()
        console_formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)

        return logger

    def _init_csv_file(self):
        """åˆå§‹åŒ–CSVæ–‡ä»¶"""
        csv_path = self.log_files['csv']
        if not csv_path.exists():
            with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow([
                    'timestamp', 'epoch', 'step', 'phase',
                    'total_loss', 'pose_loss', 'detection_loss', 'gate_loss',
                    'ate', 'rpe', 'map_score', 'fps',
                    'learning_rate', 'gpu_memory_mb', 'gpu_utilization',
                    'kendall_pose_weight', 'kendall_det_weight', 'kendall_gate_weight'
                ])

    def log_training_step(self, epoch: int, step: int, losses: Dict[str, float],
                         kendall_weights: Optional[Dict[str, float]] = None,
                         learning_rate: float = 0.0, fps: float = 0.0):
        """è®°å½•è®­ç»ƒæ­¥éª¤"""
        timestamp = time.time()
        self.step_count += 1

        # æ›´æ–°ç¼“å†²åŒº
        if 'total_loss' in losses:
            self.metrics_buffers['train_loss'].add(losses['total_loss'], timestamp)
        self.metrics_buffers['learning_rate'].add(learning_rate, timestamp)
        self.metrics_buffers['fps'].add(fps, timestamp)

        # GPUä¿¡æ¯
        gpu_info = self.gpu_monitor.get_memory_info()
        gpu_memory = gpu_info.get('allocated', 0.0)
        gpu_utilization = gpu_info.get('utilization', 0.0)
        self.metrics_buffers['gpu_memory'].add(gpu_memory, timestamp)

        # è®°å½•åˆ°å†å²
        log_entry = {
            'timestamp': timestamp,
            'epoch': epoch,
            'step': step,
            'phase': 'train',
            'losses': losses,
            'fps': fps,
            'learning_rate': learning_rate,
            'gpu_memory_mb': gpu_memory,
            'gpu_utilization': gpu_utilization
        }

        if kendall_weights:
            log_entry['kendall_weights'] = kendall_weights

        self.training_history.append(log_entry)

        # å†™å…¥CSV
        self._write_csv_row(log_entry)

        # æ—¥å¿—ä¿¡æ¯
        if step % 50 == 0:
            self.logger.info(
                f"Epoch {epoch}, Step {step}: "
                f"Loss={losses.get('total_loss', 0):.6f}, "
                f"FPS={fps:.1f}, GPU={gpu_memory:.1f}MB"
            )

        # å®šæœŸä¿å­˜
        if self.step_count % self.save_interval == 0:
            self._save_metrics()

    def log_validation_epoch(self, epoch: int, val_loss: float, ate: float,
                           rpe: float, map_score: float):
        """è®°å½•éªŒè¯epoch"""
        timestamp = time.time()

        # æ›´æ–°ç¼“å†²åŒº
        self.metrics_buffers['val_loss'].add(val_loss, timestamp)
        self.metrics_buffers['ate'].add(ate, timestamp)
        self.metrics_buffers['rpe'].add(rpe, timestamp)
        self.metrics_buffers['map'].add(map_score, timestamp)

        # æ£€æŸ¥æœ€ä½³æŒ‡æ ‡
        is_best = False
        if ate < self.best_metrics['best_ate']:
            self.best_metrics['best_ate'] = ate
            self.best_metrics['best_epoch'] = epoch
            is_best = True

        if rpe < self.best_metrics['best_rpe']:
            self.best_metrics['best_rpe'] = rpe

        if map_score > self.best_metrics['best_map']:
            self.best_metrics['best_map'] = map_score

        if val_loss < self.best_metrics['best_val_loss']:
            self.best_metrics['best_val_loss'] = val_loss

        # è®°å½•åˆ°å†å²
        log_entry = {
            'timestamp': timestamp,
            'epoch': epoch,
            'step': self.step_count,
            'phase': 'val',
            'val_loss': val_loss,
            'ate': ate,
            'rpe': rpe,
            'map_score': map_score,
            'is_best': is_best
        }

        self.training_history.append(log_entry)

        # å†™å…¥CSV
        self._write_csv_row(log_entry)

        # æ—¥å¿—ä¿¡æ¯
        status = "ğŸ¯ NEW BEST" if is_best else ""
        self.logger.info(
            f"Epoch {epoch} Validation: "
            f"Loss={val_loss:.6f}, ATE={ate:.3f}m, RPE={rpe:.3f}, mAP={map_score:.3f} {status}"
        )

        # è®°å½•ç›®æ ‡è¾¾æˆ
        if ate <= 1.5 and map_score >= 0.6:
            self.logger.info(f"ğŸ‰ TARGET REACHED! ATE={ate:.3f}â‰¤1.5m, mAP={map_score:.3f}â‰¥60%")

    def log_kendall_weights(self, epoch: int, weights: Dict[str, float]):
        """è®°å½•Kendallæƒé‡"""
        timestamp = time.time()

        weight_entry = {
            'timestamp': timestamp,
            'epoch': epoch,
            'step': self.step_count,
            'weights': weights
        }

        self.kendall_weights_history.append(weight_entry)

        # æ¯10ä¸ªepochè¯¦ç»†è®°å½•æƒé‡å˜åŒ–
        if epoch % 10 == 0:
            self.logger.info(f"Kendall Weights (Epoch {epoch}):")
            for key, value in weights.items():
                if 'weight' in key:
                    self.logger.info(f"  {key}: {value:.6f}")

    def log_gpu_stats(self):
        """è®°å½•GPUç»Ÿè®¡"""
        if not self.gpu_monitor.available:
            return

        timestamp = time.time()
        gpu_info = self.gpu_monitor.get_all_devices_info()

        self.gpu_history.append({
            'timestamp': timestamp,
            'gpu_info': gpu_info
        })

        # åªä¿ç•™æœ€è¿‘1000æ¡è®°å½•
        if len(self.gpu_history) > 1000:
            self.gpu_history = self.gpu_history[-1000:]

    def _write_csv_row(self, log_entry: Dict):
        """å†™å…¥CSVè¡Œ"""
        csv_path = self.log_files['csv']

        with open(csv_path, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)

            # å‡†å¤‡æ•°æ®è¡Œ
            row = [
                log_entry.get('timestamp', time.time()),
                log_entry.get('epoch', 0),
                log_entry.get('step', 0),
                log_entry.get('phase', 'unknown'),
                log_entry.get('losses', {}).get('total_loss', log_entry.get('val_loss', 0)),
                log_entry.get('losses', {}).get('pose_loss', 0),
                log_entry.get('losses', {}).get('detection_loss', 0),
                log_entry.get('losses', {}).get('gate_loss', 0),
                log_entry.get('ate', 0),
                log_entry.get('rpe', 0),
                log_entry.get('map_score', 0),
                log_entry.get('fps', 0),
                log_entry.get('learning_rate', 0),
                log_entry.get('gpu_memory_mb', 0),
                log_entry.get('gpu_utilization', 0),
                log_entry.get('kendall_weights', {}).get('pose_weight', 0),
                log_entry.get('kendall_weights', {}).get('detection_weight', 0),
                log_entry.get('kendall_weights', {}).get('gate_weight', 0)
            ]

            writer.writerow(row)

    def _save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡åˆ°JSONæ–‡ä»¶"""
        metrics_data = {
            'experiment_name': self.experiment_name,
            'timestamp': time.time(),
            'step_count': self.step_count,
            'best_metrics': self.best_metrics,
            'recent_statistics': {
                name: buffer.get_statistics(window=100)
                for name, buffer in self.metrics_buffers.items()
            },
            'trends': {
                name: buffer.get_recent_trend(window=20)
                for name, buffer in self.metrics_buffers.items()
            }
        }

        # ä¿å­˜ä¸»è¦æŒ‡æ ‡
        with open(self.log_files['metrics'], 'w', encoding='utf-8') as f:
            json.dump(metrics_data, f, indent=2, ensure_ascii=False)

        # ä¿å­˜Kendallæƒé‡å†å²
        with open(self.log_files['weights'], 'w', encoding='utf-8') as f:
            json.dump(self.kendall_weights_history, f, indent=2, ensure_ascii=False)

        # ä¿å­˜GPUå†å²
        if self.gpu_history:
            with open(self.log_files['gpu'], 'w', encoding='utf-8') as f:
                json.dump(self.gpu_history[-100:], f, indent=2, ensure_ascii=False)

    def get_training_summary(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒæ€»ç»“"""
        summary = {
            'experiment_name': self.experiment_name,
            'total_steps': self.step_count,
            'best_metrics': self.best_metrics,
            'current_statistics': {}
        }

        # å½“å‰ç»Ÿè®¡
        for name, buffer in self.metrics_buffers.items():
            stats = buffer.get_statistics()
            if stats:
                summary['current_statistics'][name] = stats

        return summary

    def save_final_report(self):
        """ä¿å­˜æœ€ç»ˆæŠ¥å‘Š"""
        self._save_metrics()

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        report = {
            'experiment_info': {
                'name': self.experiment_name,
                'start_time': self.training_history[0]['timestamp'] if self.training_history else time.time(),
                'end_time': time.time(),
                'total_steps': self.step_count
            },
            'final_metrics': self.best_metrics,
            'training_summary': self.get_training_summary(),
            'convergence_analysis': self._analyze_convergence()
        }

        report_path = self.log_dir / f'{self.experiment_name}_final_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        self.logger.info(f"âœ… Final report saved: {report_path}")
        self.logger.info(f"ğŸ“Š Training completed with {self.step_count} steps")
        self.logger.info(f"ğŸ† Best ATE: {self.best_metrics['best_ate']:.3f}m")
        self.logger.info(f"ğŸ† Best mAP: {self.best_metrics['best_map']:.3f}")

        return report_path

    def _analyze_convergence(self) -> Dict[str, Any]:
        """åˆ†ææ”¶æ•›æ€§"""
        analysis = {}

        for name, buffer in self.metrics_buffers.items():
            if len(buffer.data) < 10:
                continue

            stats = buffer.get_statistics()
            trend = buffer.get_recent_trend(window=min(50, len(buffer.data)))

            analysis[name] = {
                'converged': abs(trend) < 1e-5 if trend is not None else False,
                'trend_slope': trend,
                'stability': stats['std'] / max(abs(stats['mean']), 1e-8),
                'final_value': stats['latest']
            }

        return analysis


def create_training_logger(log_dir: str, experiment_name: str = None,
                          **kwargs) -> TrainingLogger:
    """
    Factory function to create training logger

    Args:
        log_dir: æ—¥å¿—ç›®å½•
        experiment_name: å®éªŒåç§°
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        é…ç½®å¥½çš„è®­ç»ƒæ—¥å¿—è®°å½•å™¨
    """
    return TrainingLogger(log_dir, experiment_name, **kwargs)


if __name__ == '__main__':
    print("ğŸ§ª Testing Training Logger...")

    # åˆ›å»ºæµ‹è¯•æ—¥å¿—è®°å½•å™¨
    logger = create_training_logger('test_logs', 'test_experiment')

    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for epoch in range(5):
        for step in range(10):
            # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
            losses = {
                'total_loss': 0.5 + 0.1 * np.random.randn(),
                'pose_loss': 0.1 + 0.02 * np.random.randn(),
                'detection_loss': 0.3 + 0.05 * np.random.randn(),
                'gate_loss': 0.1 + 0.01 * np.random.randn()
            }

            kendall_weights = {
                'pose_weight': 0.5 + 0.1 * np.random.randn(),
                'detection_weight': 1.0 + 0.2 * np.random.randn(),
                'gate_weight': 0.3 + 0.05 * np.random.randn()
            }

            logger.log_training_step(
                epoch, step, losses, kendall_weights,
                learning_rate=1e-4, fps=15.0
            )

        # æ¨¡æ‹ŸéªŒè¯
        val_loss = 0.4 + 0.05 * np.random.randn()
        ate = 1.0 + 0.2 * np.random.randn()
        rpe = 0.8 + 0.1 * np.random.randn()
        map_score = 0.7 + 0.05 * np.random.randn()

        logger.log_validation_epoch(epoch, val_loss, ate, rpe, map_score)

    # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
    report_path = logger.save_final_report()
    print(f"âœ… Test completed! Report saved to: {report_path}")