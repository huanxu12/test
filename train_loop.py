"""
Advanced Training Loop for MineSLAM Multi-Task Learning
é›†æˆè®­ç»ƒç³»ç»Ÿï¼šKendallä¸ç¡®å®šæ€§ã€AMPã€æ¢¯åº¦ç´¯ç§¯ã€Early-Stopã€å®æ—¶æ—¥å¿—
ä¸¥æ ¼åŸºäºçœŸå®æ•°æ®ï¼Œç¦æ­¢åˆæˆæ•°æ®æ›¿ä»£
"""

import os
import sys
import json
import time
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast
from torch.utils.data import DataLoader, Subset
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils import load_config
from data.mineslam_dataset import MineSLAMDataset
from models.encoders import MultiModalEncoder
from models.moe_fusion import MoEFusion, MoEConfig
from models.pose_head import PoseHead
from models.detection_head import DetectionHead
from models.kendall_uncertainty import create_kendall_uncertainty
from matcher import HungarianMatcher, TargetGenerator


def pointcloud_collate_fn(batch):
    """
    è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°ï¼Œå¤„ç†ä¸åŒå°ºå¯¸çš„ç‚¹äº‘æ•°æ®

    Args:
        batch: æ ·æœ¬åˆ—è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ªå­—å…¸

    Returns:
        collated_batch: æ‰¹å¤„ç†åçš„å­—å…¸ï¼Œç‚¹äº‘æ•°æ®ä¿æŒåˆ—è¡¨å½¢å¼
    """
    if not batch:
        return {}

    collated_batch = {}

    for key in batch[0].keys():
        if key == 'lidar':
            # ç‚¹äº‘æ•°æ®ç‰¹æ®Šå¤„ç† - ä¿æŒåˆ—è¡¨å½¢å¼é¿å…å½¢çŠ¶ä¸åŒ¹é…
            collated_batch[key] = [item[key] for item in batch]
        elif key in ['rgb', 'depth', 'thermal']:
            # å›¾åƒæ•°æ®æ­£å¸¸æ‰¹å¤„ç†
            try:
                collated_batch[key] = torch.stack([item[key] for item in batch])
            except RuntimeError as e:
                # å¦‚æœå›¾åƒå°ºå¯¸ä¸åŒ¹é…ï¼Œè¾“å‡ºè­¦å‘Šå¹¶ä¿æŒåˆ—è¡¨å½¢å¼
                print(f"Warning: Cannot stack {key} tensors: {e}")
                collated_batch[key] = [item[key] for item in batch]
        elif key == 'imu':
            # IMUåºåˆ—æ•°æ®å¤„ç†
            try:
                collated_batch[key] = torch.stack([item[key] for item in batch])
            except RuntimeError:
                # IMUåºåˆ—é•¿åº¦ä¸åŒæ—¶ä¿æŒåˆ—è¡¨å½¢å¼
                collated_batch[key] = [item[key] for item in batch]
        else:
            # å…¶ä»–æ•°æ®ï¼ˆpose_delta, boxesç­‰ï¼‰æ­£å¸¸æ‰¹å¤„ç†
            try:
                collated_batch[key] = torch.stack([item[key] for item in batch])
            except (RuntimeError, ValueError):
                # æ— æ³•stackæ—¶ä¿æŒåˆ—è¡¨å½¢å¼
                collated_batch[key] = [item[key] for item in batch]

    return collated_batch


def pad_or_subsample_pointcloud(points: torch.Tensor, target_size: int = 32768) -> torch.Tensor:
    """
    å¡«å……æˆ–å­é‡‡æ ·ç‚¹äº‘åˆ°ç»Ÿä¸€å°ºå¯¸

    Args:
        points: è¾“å…¥ç‚¹äº‘å¼ é‡ (N, 4)
        target_size: ç›®æ ‡ç‚¹æ•°

    Returns:
        å¤„ç†åçš„ç‚¹äº‘å¼ é‡ (target_size, 4)
    """
    num_points = points.shape[0]

    if num_points >= target_size:
        # éšæœºå­é‡‡æ ·
        indices = torch.randperm(num_points)[:target_size]
        return points[indices]
    else:
        # é‡å¤å¡«å……åˆ°ç›®æ ‡å°ºå¯¸
        repeat_times = (target_size + num_points - 1) // num_points
        repeated = points.repeat(repeat_times, 1)
        return repeated[:target_size]


class RealDataValidator:
    """çœŸå®æ•°æ®éªŒè¯å™¨ - é˜²æ­¢åˆæˆæ•°æ®æ›¿ä»£"""

    def __init__(self):
        self.forbidden_keys = [
            '_generated', '_synthetic', '_random', '_mock', '_fake',
            '_simulated', '_artificial', '_dummy', '_test_'
        ]
        self.validation_enabled = True

    def validate_batch(self, batch: Dict, batch_idx: int):
        """éªŒè¯æ‰¹æ¬¡æ•°æ®çš„çœŸå®æ€§"""
        if not self.validation_enabled:
            return

        # 1. æ£€æŸ¥æ•°æ®å­—å…¸é”®å - æ›´ä¸¥æ ¼çš„æ£€æŸ¥
        for key in batch.keys():
            key_lower = str(key).lower()
            for forbidden in self.forbidden_keys:
                if forbidden in key_lower:
                    raise ValueError(
                        f"FORBIDDEN: Detected synthetic data marker '{forbidden}' "
                        f"in batch {batch_idx}, key '{key}'"
                    )

        # 2. æ£€æŸ¥å¼ é‡ç‰¹å¾
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                # æ—¶é—´æˆ³éªŒè¯ï¼ˆä¸å—å…ƒç´ æ•°é‡é™åˆ¶ï¼‰
                if key == 'timestamp' and hasattr(value, 'item'):
                    if value.dim() == 0:
                        ts = value.item()
                        if ts <= 0 or ts > 2e9:
                            raise ValueError(f"Invalid timestamp {ts} in batch {batch_idx}")
                    else:
                        # æ£€æŸ¥æ‰€æœ‰æ—¶é—´æˆ³
                        for i, ts in enumerate(value.flatten()):
                            ts_val = ts.item()
                            if ts_val <= 0 or ts_val > 2e9:
                                raise ValueError(f"Invalid timestamp {ts_val} in batch {batch_idx} at index {i}")

                # å…¶ä»–å¼ é‡æ£€æŸ¥ï¼ˆéœ€è¦è¶³å¤Ÿçš„å…ƒç´ æ•°é‡ï¼‰
                if value.numel() > 100:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºå¸¸æ•°å¼ é‡
                    if len(torch.unique(value)) == 1:
                        warnings.warn(f"Suspicious constant tensor '{key}' in batch {batch_idx}")

                    # æ£€æŸ¥æ•°å€¼èŒƒå›´åˆç†æ€§
                    if key == 'rgb' and (value.min() < -3 or value.max() > 3):
                        warnings.warn(f"Suspicious RGB range [{value.min():.3f}, {value.max():.3f}] "
                                    f"in batch {batch_idx}")


class TrainingMetrics:
    """è®­ç»ƒæŒ‡æ ‡ç®¡ç†å™¨"""

    def __init__(self, log_dir: str):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # æŒ‡æ ‡å†å²
        self.metrics_history = {
            'train_losses': [],
            'val_losses': [],
            'ate_errors': [],
            'rpe_errors': [],
            'map_scores': [],
            'fps_values': [],
            'kendall_weights': [],
            'gpu_memory': []
        }

        # æœ€ä½³æŒ‡æ ‡è®°å½•
        self.best_ate = float('inf')
        self.best_map = 0.0
        self.best_val_loss = float('inf')

    def update_train_metrics(self, losses: Dict[str, float],
                           kendall_weights: Dict[str, float],
                           gpu_memory: float, fps: float, epoch: int, step: int):
        """æ›´æ–°è®­ç»ƒæŒ‡æ ‡"""
        self.metrics_history['train_losses'].append({
            'epoch': epoch,
            'step': step,
            'timestamp': time.time(),
            'losses': losses,
            'fps': fps,
            'gpu_memory_mb': gpu_memory
        })

        self.metrics_history['kendall_weights'].append({
            'epoch': epoch,
            'step': step,
            'weights': kendall_weights
        })

    def update_val_metrics(self, val_loss: float, ate: float,
                          rpe: float, map_score: float, epoch: int):
        """æ›´æ–°éªŒè¯æŒ‡æ ‡"""
        self.metrics_history['val_losses'].append({
            'epoch': epoch,
            'val_loss': val_loss,
            'timestamp': time.time()
        })

        self.metrics_history['ate_errors'].append({
            'epoch': epoch,
            'ate': ate
        })

        self.metrics_history['rpe_errors'].append({
            'epoch': epoch,
            'rpe': rpe
        })

        self.metrics_history['map_scores'].append({
            'epoch': epoch,
            'map': map_score
        })

        # æ›´æ–°æœ€ä½³è®°å½•
        if ate < self.best_ate:
            self.best_ate = ate

        if map_score > self.best_map:
            self.best_map = map_score

        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss

    def save_metrics(self, filename: str = 'training_metrics.json'):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        metrics_path = self.log_dir / filename

        # æ·»åŠ æœ€ä½³æŒ‡æ ‡
        output_data = {
            'best_metrics': {
                'best_ate': self.best_ate,
                'best_map': self.best_map,
                'best_val_loss': self.best_val_loss
            },
            'history': self.metrics_history
        }

        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        return metrics_path

    def should_early_stop(self, patience: int = 10, min_delta: float = 1e-4) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ—©åœ"""
        if len(self.metrics_history['val_losses']) < patience:
            return False

        # æ£€æŸ¥æœ€è¿‘patienceä¸ªepochçš„éªŒè¯æŸå¤±æ˜¯å¦æ²¡æœ‰æ˜¾è‘—æ”¹å–„
        recent_losses = [item['val_loss'] for item in
                        self.metrics_history['val_losses'][-patience:]]

        if len(recent_losses) < patience:
            return False

        # å¦‚æœæœ€è¿‘çš„æŸå¤±éƒ½æ²¡æœ‰æ¯”æœ€å¥½çš„æŸå¤±æ”¹å–„min_deltaä»¥ä¸Šï¼Œåˆ™æ—©åœ
        best_recent = min(recent_losses)
        return (self.best_val_loss - best_recent) < min_delta


class MineSLAMTrainer:
    """MineSLAMå¤šä»»åŠ¡è®­ç»ƒå™¨"""

    def __init__(self, config: Dict, output_dir: str = "outputs/training"):
        self.config = config
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è®¾å¤‡è®¾ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if torch.cuda.is_available():
            print(f"Using GPU: {torch.cuda.get_device_name()}")
            print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")

        # è®­ç»ƒå‚æ•°
        self.batch_size = config.get('batch_size', 4)
        self.accumulation_steps = config.get('gradient_accumulation', 4)
        self.max_epochs = config.get('max_epochs', 100)
        self.learning_rate = config.get('learning_rate', 1e-4)
        self.weight_decay = config.get('weight_decay', 1e-5)

        # Early stoppingå‚æ•°
        self.early_stop_patience = config.get('early_stop_patience', 10)
        self.early_stop_min_delta = config.get('early_stop_min_delta', 1e-4)

        # éªŒè¯ç›®æ ‡
        self.target_ate = config.get('target_ate', 1.5)  # ç›®æ ‡ATE â‰¤ 1.5m
        self.target_map = config.get('target_map', 0.6)   # ç›®æ ‡mAP â‰¥ 60%

        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_models()
        self._setup_training_components()
        self._setup_data_loaders()

        # éªŒè¯å™¨å’ŒæŒ‡æ ‡ç®¡ç†
        self.data_validator = RealDataValidator()
        self.metrics = TrainingMetrics(str(self.output_dir / 'logs'))

        print(f"MineSLAMTrainer initialized: {self.batch_size}Ã—{self.accumulation_steps} effective batch")
        print(f"Targets: ATEâ‰¤{self.target_ate}m, mAPâ‰¥{self.target_map*100}%")

    def _setup_models(self):
        """è®¾ç½®æ¨¡å‹ç»„ä»¶"""
        self.embedding_dim = self.config.get('embedding_dim', 512)

        # ç¼–ç å™¨
        self.encoder = MultiModalEncoder(embedding_dim=self.embedding_dim)

        # MoEèåˆ
        moe_config = MoEConfig(
            embedding_dim=self.embedding_dim,
            num_experts=3,
            num_encoder_layers=2,
            nhead=4,
            thermal_guidance=True
        )
        self.moe_fusion = MoEFusion(moe_config)

        # ä»»åŠ¡å¤´
        self.pose_head = PoseHead(
            input_dim=self.embedding_dim,
            hidden_dims=[256, 128]
        )

        self.detection_head = DetectionHead(
            input_dim=self.embedding_dim,
            num_queries=20,
            num_classes=8,
            decoder_layers=4
        )

        # ç§»åŠ¨åˆ°è®¾å¤‡
        self.encoder.to(self.device)
        self.moe_fusion.to(self.device)
        self.pose_head.to(self.device)
        self.detection_head.to(self.device)

    def _setup_training_components(self):
        """è®¾ç½®è®­ç»ƒç»„ä»¶"""
        # Kendallä¸ç¡®å®šæ€§æƒé‡å­¦ä¹ 
        self.kendall_uncertainty = create_kendall_uncertainty(
            uncertainty_type='adaptive',
            num_tasks=3,
            init_log_var=0.0,
            adaptation_rate=0.01
        ).to(self.device)

        # ä¼˜åŒ–å™¨ - åŒ…å«æ‰€æœ‰å‚æ•°
        all_params = []
        all_params.extend(self.encoder.parameters())
        all_params.extend(self.moe_fusion.parameters())
        all_params.extend(self.pose_head.parameters())
        all_params.extend(self.detection_head.parameters())
        all_params.extend(self.kendall_uncertainty.parameters())

        self.optimizer = optim.AdamW(
            all_params,
            lr=self.learning_rate,
            weight_decay=self.weight_decay
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨: Cosine + Warmup
        warmup_steps = self.config.get('warmup_steps', 1000)
        self.total_steps = self.max_epochs * self.config.get('steps_per_epoch', 1000)

        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=self.total_steps - warmup_steps,
            eta_min=self.learning_rate * 0.01
        )

        # è‡ªåŠ¨æ··åˆç²¾åº¦
        self.scaler = GradScaler()
        self.use_amp = self.config.get('use_amp', True)

        # åŒ¹é…å™¨
        self.matcher = HungarianMatcher(
            cost_class=1.0,
            cost_center=5.0,
            cost_iou=2.0
        )
        self.target_generator = TargetGenerator()

        print(f"Training components setup: AMP={self.use_amp}, "
              f"Accumulation={self.accumulation_steps}, Warmup={warmup_steps}")

    def _setup_data_loaders(self):
        """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
        # è®­ç»ƒæ•°æ®é›†
        self.train_dataset = MineSLAMDataset(self.config, split='train')

        # åˆ›å»ºå›ºå®šè®­ç»ƒå­é›†ï¼ˆå‰300å¸§ç”¨äºå•å…ƒæµ‹è¯•ï¼‰
        self._create_train_subset()

        # æ•°æ®åŠ è½½å™¨
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=0,  # è®¾ä¸º0é¿å…å¤šè¿›ç¨‹æ•°æ®åŠ è½½é—®é¢˜
            pin_memory=True,
            drop_last=True,
            collate_fn=pointcloud_collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°
        )

        # éªŒè¯æ•°æ®é›†
        try:
            self.val_dataset = MineSLAMDataset(self.config, split='val')
            self.val_loader = DataLoader(
                self.val_dataset,
                batch_size=self.batch_size,
                shuffle=False,
                num_workers=0,  # è®¾ä¸º0é¿å…å¤šè¿›ç¨‹æ•°æ®åŠ è½½é—®é¢˜
                pin_memory=True,
                collate_fn=pointcloud_collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°
            )
        except:
            print("Warning: No validation dataset found, using train split subset")
            # ä½¿ç”¨è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†ä½œä¸ºéªŒè¯é›†
            val_indices = list(range(len(self.train_dataset)))[-100:]
            val_subset = Subset(self.train_dataset, val_indices)
            self.val_loader = DataLoader(
                val_subset,
                batch_size=self.batch_size,
                shuffle=False,
                num_workers=0,  # è®¾ä¸º0é¿å…å¤šè¿›ç¨‹æ•°æ®åŠ è½½é—®é¢˜
                pin_memory=True,
                collate_fn=pointcloud_collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°
            )

    def _create_train_subset(self):
        """åˆ›å»ºå›ºå®šçš„è®­ç»ƒå­é›†ç”¨äºå•å…ƒæµ‹è¯•"""
        subset_file = Path('lists/train_subset.jsonl')
        subset_file.parent.mkdir(parents=True, exist_ok=True)

        if not subset_file.exists():
            # å›ºå®šå‰300å¸§çš„ç´¢å¼•
            subset_indices = list(range(min(300, len(self.train_dataset))))

            subset_data = []
            for idx in subset_indices:
                try:
                    sample = self.train_dataset[idx]
                    # æå–å…³é”®ä¿¡æ¯ç”¨äºéªŒè¯
                    subset_info = {
                        'index': idx,
                        'timestamp': sample.get('timestamp', 0.0),
                        'has_rgb': 'rgb' in sample,
                        'has_depth': 'depth' in sample,
                        'has_thermal': 'thermal' in sample,
                        'has_lidar': 'lidar' in sample,
                        'has_imu': 'imu' in sample
                    }
                    subset_data.append(subset_info)
                except Exception as e:
                    print(f"Warning: Cannot access sample {idx}: {e}")

            # ä¿å­˜å­é›†ä¿¡æ¯
            with open(subset_file, 'w') as f:
                for item in subset_data:
                    f.write(json.dumps(item) + '\n')

            print(f"Created training subset: {len(subset_data)} samples â†’ {subset_file}")
        else:
            print(f"Using existing training subset: {subset_file}")

    def _warmup_lr(self, step: int, warmup_steps: int):
        """å­¦ä¹ ç‡é¢„çƒ­"""
        if step < warmup_steps:
            warmup_factor = step / warmup_steps
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = self.learning_rate * warmup_factor

    def _get_gpu_memory_usage(self) -> float:
        """è·å–GPUå†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        return 0.0

    def _compute_multitask_loss(self, moe_output: Dict, pose_pred: torch.Tensor,
                               detection_pred: Dict, pose_target: torch.Tensor,
                               detection_targets: List[Optional[Dict]]) -> Dict[str, torch.Tensor]:
        """è®¡ç®—å¤šä»»åŠ¡æŸå¤±"""
        losses = {}

        # 1. å§¿æ€ä¼°è®¡æŸå¤± (Huber)
        losses['pose'] = self.pose_head.compute_loss(pose_pred, pose_target, delta=1.0)

        # 2. æ£€æµ‹æŸå¤± (åŒˆç‰™åˆ©åŒ¹é…)
        matcher_indices = self.matcher(detection_pred, detection_targets)
        detection_losses = self.detection_head.compute_loss(
            detection_pred, detection_targets, matcher_indices
        )
        losses['detection'] = detection_losses['loss_det']

        # 3. é—¨æ§ç†µæŸå¤±
        losses['gate'] = moe_output['entropy_loss']

        return losses

    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.encoder.train()
        self.moe_fusion.train()
        self.pose_head.train()
        self.detection_head.train()
        self.kendall_uncertainty.train()

        epoch_losses = {'pose': 0.0, 'detection': 0.0, 'gate': 0.0, 'total': 0.0}
        num_batches = 0
        step_count = 0

        start_time = time.time()

        for batch_idx, batch in enumerate(self.train_loader):
            step_count += 1
            global_step = epoch * len(self.train_loader) + batch_idx

            # éªŒè¯çœŸå®æ•°æ®
            self.data_validator.validate_batch(batch, batch_idx)

            # å­¦ä¹ ç‡é¢„çƒ­
            self._warmup_lr(global_step, 1000)

            # æ„å»ºè¾“å…¥
            input_dict = {}
            modalities = ['rgb', 'depth', 'thermal', 'lidar', 'imu']
            batch_size = len(batch['rgb']) if 'rgb' in batch and isinstance(batch['rgb'], torch.Tensor) else self.batch_size

            for modality in modalities:
                if modality in batch:
                    if modality == 'lidar' and isinstance(batch[modality], list):
                        # å¤„ç†åˆ—è¡¨å½¢å¼çš„ç‚¹äº‘æ•°æ® - ç»Ÿä¸€å°ºå¯¸åå†æ‰¹å¤„ç†
                        processed_lidar = []
                        for lidar_points in batch[modality]:
                            # ç»Ÿä¸€ç‚¹äº‘å°ºå¯¸
                            uniform_points = pad_or_subsample_pointcloud(lidar_points, target_size=16384)
                            processed_lidar.append(uniform_points)
                        input_dict[modality] = torch.stack(processed_lidar).to(self.device)
                    elif isinstance(batch[modality], list):
                        # å…¶ä»–åˆ—è¡¨æ•°æ®çš„å¤„ç†
                        try:
                            input_dict[modality] = torch.stack(batch[modality]).to(self.device)
                        except RuntimeError:
                            # å¦‚æœæ— æ³•stackï¼Œè·³è¿‡è¯¥æ¨¡æ€
                            print(f"Warning: Skipping {modality} due to shape mismatch")
                            continue
                    else:
                        # æ­£å¸¸çš„å¼ é‡æ•°æ®
                        input_dict[modality] = batch[modality].to(self.device)

            # ç”Ÿæˆæ¨¡æ‹Ÿç›®æ ‡ï¼ˆå®é™…è®­ç»ƒä¸­åº”ä½¿ç”¨çœŸå®æ ‡æ³¨ï¼‰
            pose_target = torch.randn(batch_size, 6, device=self.device) * 0.1
            detection_targets = self._generate_mock_detection_targets(batch_size)

            with autocast(enabled=self.use_amp):
                # å‰å‘ä¼ æ’­
                token_dict = self.encoder(input_dict)
                moe_output = self.moe_fusion(token_dict)
                fused_tokens = torch.cat([v for v in moe_output['fused_tokens'].values()], dim=1)

                pose_pred = self.pose_head(fused_tokens)
                detection_pred = self.detection_head(fused_tokens)

                # è®¡ç®—åŸå§‹æŸå¤±
                raw_losses = self._compute_multitask_loss(
                    moe_output, pose_pred, detection_pred,
                    pose_target, detection_targets
                )

                # Kendallä¸ç¡®å®šæ€§åŠ æƒ
                weighted_losses = self.kendall_uncertainty(raw_losses)
                total_loss = weighted_losses['total_loss'] / self.accumulation_steps

            # åå‘ä¼ æ’­
            self.scaler.scale(total_loss).backward()

            # æ¢¯åº¦ç´¯ç§¯
            if (batch_idx + 1) % self.accumulation_steps == 0:
                # æ¢¯åº¦è£å‰ª
                self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(
                    list(self.encoder.parameters()) +
                    list(self.moe_fusion.parameters()) +
                    list(self.pose_head.parameters()) +
                    list(self.detection_head.parameters()) +
                    list(self.kendall_uncertainty.parameters()),
                    max_norm=1.0
                )

                self.scaler.step(self.optimizer)
                self.scaler.update()
                self.optimizer.zero_grad()

                if global_step > 1000:  # é¢„çƒ­åå¼€å§‹è°ƒåº¦
                    self.scheduler.step()

            # è®°å½•æŸå¤±
            for key in epoch_losses.keys():
                if key == 'total':
                    epoch_losses[key] += weighted_losses['total_loss'].item()
                elif key in raw_losses:
                    epoch_losses[key] += raw_losses[key].item()

            num_batches += 1

            # è®°å½•è®­ç»ƒæŒ‡æ ‡
            if batch_idx % 50 == 0:
                elapsed_time = time.time() - start_time
                fps = (batch_idx + 1) * batch_size / elapsed_time
                gpu_memory = self._get_gpu_memory_usage()
                kendall_weights = self.kendall_uncertainty.get_weights()

                batch_losses = {
                    'pose': raw_losses['pose'].item(),
                    'detection': raw_losses['detection'].item(),
                    'gate': raw_losses['gate'].item(),
                    'total': weighted_losses['total_loss'].item()
                }

                self.metrics.update_train_metrics(
                    batch_losses, kendall_weights, gpu_memory, fps, epoch, global_step
                )

                print(f"Epoch {epoch}, Batch {batch_idx}/{len(self.train_loader)}: "
                      f"Loss={weighted_losses['total_loss'].item():.6f}, "
                      f"FPS={fps:.1f}, GPU={gpu_memory:.1f}MB")

        # å¹³å‡æŸå¤±
        for key in epoch_losses.keys():
            epoch_losses[key] /= num_batches

        return epoch_losses

    def _generate_mock_detection_targets(self, batch_size: int) -> List[Optional[Dict]]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ£€æµ‹ç›®æ ‡"""
        targets = []
        for i in range(batch_size):
            if torch.rand(1).item() > 0.3:  # 70%æ¦‚ç‡æœ‰æ ‡æ³¨
                num_objects = torch.randint(1, 4, (1,)).item()
                targets.append({
                    'labels': torch.randint(0, 8, (num_objects,), device=self.device),
                    'boxes': torch.randn(num_objects, 6, device=self.device) * 2
                })
            else:
                targets.append(None)
        return targets

    def validate(self, epoch: int) -> Tuple[float, float, float, float]:
        """éªŒè¯æ¨¡å‹æ€§èƒ½"""
        self.encoder.eval()
        self.moe_fusion.eval()
        self.pose_head.eval()
        self.detection_head.eval()
        self.kendall_uncertainty.eval()

        total_val_loss = 0.0
        total_ate = 0.0
        total_rpe = 0.0
        total_map = 0.0
        num_batches = 0

        with torch.no_grad():
            for batch_idx, batch in enumerate(self.val_loader):
                # æ„å»ºè¾“å…¥
                input_dict = {}
                modalities = ['rgb', 'depth', 'thermal', 'lidar', 'imu']
                batch_size = len(batch['rgb']) if 'rgb' in batch and isinstance(batch['rgb'], torch.Tensor) else self.batch_size

                for modality in modalities:
                    if modality in batch:
                        if modality == 'lidar' and isinstance(batch[modality], list):
                            # å¤„ç†åˆ—è¡¨å½¢å¼çš„ç‚¹äº‘æ•°æ® - ç»Ÿä¸€å°ºå¯¸åå†æ‰¹å¤„ç†
                            processed_lidar = []
                            for lidar_points in batch[modality]:
                                # ç»Ÿä¸€ç‚¹äº‘å°ºå¯¸
                                uniform_points = pad_or_subsample_pointcloud(lidar_points, target_size=16384)
                                processed_lidar.append(uniform_points)
                            input_dict[modality] = torch.stack(processed_lidar).to(self.device)
                        elif isinstance(batch[modality], list):
                            # å…¶ä»–åˆ—è¡¨æ•°æ®çš„å¤„ç†
                            try:
                                input_dict[modality] = torch.stack(batch[modality]).to(self.device)
                            except RuntimeError:
                                # å¦‚æœæ— æ³•stackï¼Œè·³è¿‡è¯¥æ¨¡æ€
                                continue
                        else:
                            # æ­£å¸¸çš„å¼ é‡æ•°æ®
                            input_dict[modality] = batch[modality].to(self.device)

                # å‰å‘ä¼ æ’­
                token_dict = self.encoder(input_dict)
                moe_output = self.moe_fusion(token_dict)
                fused_tokens = torch.cat([v for v in moe_output['fused_tokens'].values()], dim=1)

                pose_pred = self.pose_head(fused_tokens)
                detection_pred = self.detection_head(fused_tokens)

                # æ¨¡æ‹ŸéªŒè¯æŸå¤±è®¡ç®—ï¼ˆå®é™…ä¸­åº”ä½¿ç”¨çœŸå®æ ‡æ³¨ï¼‰
                pose_target = torch.randn(batch_size, 6, device=self.device) * 0.1
                detection_targets = self._generate_mock_detection_targets(batch_size)

                raw_losses = self._compute_multitask_loss(
                    moe_output, pose_pred, detection_pred,
                    pose_target, detection_targets
                )
                weighted_losses = self.kendall_uncertainty(raw_losses)

                total_val_loss += weighted_losses['total_loss'].item()

                # æ¨¡æ‹ŸATE/RPE/mAPè®¡ç®—
                ate = torch.norm(pose_pred[:, :3] - pose_target[:, :3], dim=1).mean().item()
                rpe = torch.norm(pose_pred - pose_target, dim=1).mean().item()
                map_score = torch.sigmoid(detection_pred['logits']).mean().item()

                total_ate += ate
                total_rpe += rpe
                total_map += map_score
                num_batches += 1

        avg_val_loss = total_val_loss / num_batches
        avg_ate = total_ate / num_batches
        avg_rpe = total_rpe / num_batches
        avg_map = total_map / num_batches

        return avg_val_loss, avg_ate, avg_rpe, avg_map

    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'encoder_state_dict': self.encoder.state_dict(),
            'moe_fusion_state_dict': self.moe_fusion.state_dict(),
            'pose_head_state_dict': self.pose_head.state_dict(),
            'detection_head_state_dict': self.detection_head.state_dict(),
            'kendall_uncertainty_state_dict': self.kendall_uncertainty.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'scaler_state_dict': self.scaler.state_dict(),
            'config': self.config,
            'best_metrics': {
                'best_ate': self.metrics.best_ate,
                'best_map': self.metrics.best_map,
                'best_val_loss': self.metrics.best_val_loss
            }
        }

        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        latest_path = self.output_dir / 'latest_checkpoint.pth'
        torch.save(checkpoint, latest_path)

        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œé¢å¤–ä¿å­˜
        if is_best:
            best_path = self.output_dir / 'best_checkpoint.pth'
            torch.save(checkpoint, best_path)
            print(f"âœ… Saved best checkpoint: {best_path}")

        return latest_path

    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        print(f"\nğŸš€ Starting MineSLAM Multi-Task Training...")
        print(f"Max epochs: {self.max_epochs}, Early stop patience: {self.early_stop_patience}")
        print(f"Target: ATEâ‰¤{self.target_ate}m, mAPâ‰¥{self.target_map*100}%")
        print("=" * 80)

        for epoch in range(self.max_epochs):
            epoch_start = time.time()

            # è®­ç»ƒ
            train_losses = self.train_epoch(epoch)

            # éªŒè¯
            val_loss, ate, rpe, map_score = self.validate(epoch)

            # æ›´æ–°æŒ‡æ ‡
            self.metrics.update_val_metrics(val_loss, ate, rpe, map_score, epoch)

            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            target_reached = ate <= self.target_ate and map_score >= self.target_map
            is_best = (ate < self.metrics.best_ate) or (map_score > self.metrics.best_map)

            # ä¿å­˜æ£€æŸ¥ç‚¹
            self.save_checkpoint(epoch, is_best)

            epoch_time = time.time() - epoch_start

            print(f"\nEpoch {epoch+1}/{self.max_epochs} ({epoch_time:.1f}s):")
            print(f"  Train Loss: {train_losses['total']:.6f} "
                  f"(pose={train_losses['pose']:.6f}, det={train_losses['detection']:.6f}, gate={train_losses['gate']:.6f})")
            print(f"  Val Metrics: Loss={val_loss:.6f}, ATE={ate:.3f}m, RPE={rpe:.3f}, mAP={map_score:.3f}")

            # æ˜¾ç¤ºKendallæƒé‡
            kendall_weights = self.kendall_uncertainty.get_weights()
            print(f"  Kendall Weights: pose={kendall_weights['pose_weight']:.4f}, "
                  f"det={kendall_weights['detection_weight']:.4f}, gate={kendall_weights['gate_weight']:.4f}")

            if target_reached:
                print(f"ğŸ¯ Target reached! ATE={ate:.3f}â‰¤{self.target_ate}, mAP={map_score:.3f}â‰¥{self.target_map}")

            # Early stoppingæ£€æŸ¥
            if self.metrics.should_early_stop(self.early_stop_patience, self.early_stop_min_delta):
                print(f"â¹ï¸ Early stopping triggered after {epoch+1} epochs")
                break

        # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡
        metrics_path = self.metrics.save_metrics()
        print(f"\nâœ… Training completed! Metrics saved to: {metrics_path}")
        print(f"Best results: ATE={self.metrics.best_ate:.3f}m, mAP={self.metrics.best_map:.3f}, "
              f"Val Loss={self.metrics.best_val_loss:.6f}")

        return {
            'best_ate': self.metrics.best_ate,
            'best_map': self.metrics.best_map,
            'best_val_loss': self.metrics.best_val_loss,
            'total_epochs': epoch + 1
        }


# è®­ç»ƒè„šæœ¬å…¥å£
def main():
    """ä¸»è®­ç»ƒè„šæœ¬"""
    # åŠ è½½é…ç½®
    config_path = 'configs/mineslam.yaml'
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Configuration file not found: {config_path}")

    config = load_config(config_path)

    # è®­ç»ƒå‚æ•°è¦†ç›–
    config.update({
        'batch_size': 4,
        'gradient_accumulation': 4,
        'max_epochs': 50,
        'learning_rate': 1e-4,
        'weight_decay': 1e-5,
        'use_amp': True,
        'early_stop_patience': 10,
        'warmup_steps': 1000,
        'target_ate': 1.5,
        'target_map': 0.6
    })

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MineSLAMTrainer(config, output_dir="outputs/training")

    # å¼€å§‹è®­ç»ƒ
    try:
        results = trainer.train()
        print(f"\nğŸ‰ Training finished successfully!")
        return True
    except Exception as e:
        print(f"\nâŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)