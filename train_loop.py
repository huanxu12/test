"""
Advanced Training Loop for MineSLAM Multi-Task Learning
é›†æˆè®­ç»ƒç³»ç»Ÿï¼šKendallä¸ç¡®å®šæ€§ã€AMPã€æ¢¯åº¦ç´¯ç§¯ã€Early-Stopã€å®æ—¶æ—¥å¿—
ä¸¥æ ¼åŸºäºçœŸå®æ•°æ®ï¼Œç¦æ­¢åˆæˆæ•°æ®æ›¿ä»£
"""

import os
import sys
import json
import time
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import GradScaler
try:
    # æ–°ç‰ˆæœ¬PyTorch (â‰¥1.10)
    from torch.amp import autocast
except ImportError:
    # æ—§ç‰ˆæœ¬PyTorch
    from torch.cuda.amp import autocast
from torch.utils.data import DataLoader, Subset
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils import load_config
from data.mineslam_dataset import MineSLAMDataset
from models.encoders import MultiModalEncoder
from models.moe_fusion import MoEFusion, MoEConfig
from models.pose_head import PoseHead
from models.detection_head import DetectionHead
from models.kendall_uncertainty import create_fixed_kendall_uncertainty
from matcher import HungarianMatcher, TargetGenerator

# é›†æˆè¯„ä¼°å’Œå¯è§†åŒ–ç³»ç»Ÿ
try:
    from slam_evaluator import MineSLAMEvaluator, SLAMTrajectoryMetrics
    from slam_visualizer import SLAMVisualizer, TrainingMonitor
    SLAM_INTEGRATION_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ SLAM integration partially unavailable: {e}")
    SLAM_INTEGRATION_AVAILABLE = False

# æŠ‘åˆ¶é‡å¤è­¦å‘Š - è·¯çº¿Bä¼˜åŒ–
warnings.filterwarnings("ignore", message="coordinates implicitly converted to torch.IntTensor")
warnings.filterwarnings("ignore", message="`torch.cuda.amp.autocast.*` is deprecated")

# å…¨å±€è®¡æ•°å™¨ï¼Œç”¨äºé™åˆ¶æŸäº›è­¦å‘Šæ˜¾ç¤º
_warning_counters = {
    'minkowski_coords': 0,
    'autocast_deprecated': 0,
    'missing_modality': 0
}


def pointcloud_collate_fn(batch):
    """
    è·¯çº¿Bï¼šæŸ”æ€§æ‰¹å¤„ç†å‡½æ•°ï¼Œå¼ºåˆ¶å¯¹é½batch_sizeï¼Œé›¶å¡«å……+æ©ç 

    æ ¸å¿ƒåŸåˆ™ï¼š
    1. ä¸ä¸¢æ ·æœ¬ï¼Œæ‰€æœ‰æ¨¡æ€å¼ºåˆ¶å¯¹é½ç›¸åŒbatch_size B
    2. ç¼ºå¤±æ¨¡æ€ç”¨é›¶æ ·æœ¬å ä½
    3. è¿”å›present_maskæŒ‡ç¤ºçœŸå®/å¡«å……æ•°æ®
    4. ç¦æ­¢filter(None)
    5. ç‚¹äº‘ç»Ÿä¸€åˆ°å›ºå®šé•¿åº¦Pï¼Œå›¾åƒç»Ÿä¸€å°ºå¯¸

    Args:
        batch: æ ·æœ¬åˆ—è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ªå­—å…¸

    Returns:
        collated_batch: æ‰¹å¤„ç†åçš„å­—å…¸ï¼ŒåŒ…å«ï¼š
        - å„æ¨¡æ€æ•°æ®ï¼šç»Ÿä¸€batch_sizeçš„å¼ é‡
        - present_maskï¼šæŒ‡ç¤ºçœŸå®/å¡«å……æ•°æ®çš„æ©ç å­—å…¸
    """
    if not batch:
        return {}

    batch_size = len(batch)
    collated_batch = {}
    present_mask = {}

    # å›ºå®šå‚æ•° - è·¯çº¿Bè¦æ±‚
    FIXED_LIDAR_SIZE = 16384  # På‚æ•°ï¼šç‚¹äº‘ç»Ÿä¸€é•¿åº¦

    for key in batch[0].keys():
        # ç¡®å®šå“ªäº›æ ·æœ¬æœ‰æ­¤æ¨¡æ€çš„æ•°æ®
        valid_indices = [i for i, item in enumerate(batch) if key in item]

        # åˆ›å»ºpresent_mask - è·¯çº¿Bæ ¼å¼
        mask = torch.zeros(batch_size, dtype=torch.bool)
        mask[valid_indices] = True
        present_mask[key] = mask

        if key == 'lidar':
            # ç‚¹äº‘ï¼šç»Ÿä¸€åˆ°å›ºå®šé•¿åº¦Pï¼Œå¼ºåˆ¶å¯¹é½batch_size B
            standardized_lidar = []
            for i in range(batch_size):
                if i in valid_indices:
                    # çœŸå®ç‚¹äº‘ï¼šç»Ÿä¸€åˆ°å›ºå®šé•¿åº¦
                    points = batch[i][key]
                    uniform_points = pad_or_subsample_pointcloud(points, target_size=FIXED_LIDAR_SIZE)
                    standardized_lidar.append(uniform_points)
                else:
                    # å¡«å……ç‚¹äº‘ï¼šå›ºå®šé•¿åº¦çš„é›¶ç‚¹äº‘
                    dummy_lidar = torch.zeros(FIXED_LIDAR_SIZE, 4, dtype=torch.float32)
                    standardized_lidar.append(dummy_lidar)

            collated_batch[key] = torch.stack(standardized_lidar)  # [B, P, C]

        elif key in ['rgb', 'depth', 'thermal']:
            # å›¾åƒæ•°æ®ï¼šå¼ºåˆ¶å¯¹é½batch_size B
            if valid_indices:
                # è·å–å‚è€ƒå°ºå¯¸ï¼ˆåº”åœ¨datasetä¸­é¢„å¤„ç†ä¸ºç»Ÿä¸€å°ºå¯¸ï¼‰
                ref_shape = batch[valid_indices[0]][key].shape
                standardized_images = []

                for i in range(batch_size):
                    if i in valid_indices:
                        # çœŸå®å›¾åƒ
                        standardized_images.append(batch[i][key])
                    else:
                        # å¡«å……å›¾åƒï¼šç›¸åŒå°ºå¯¸çš„é›¶å›¾åƒ
                        dummy_image = torch.zeros(ref_shape, dtype=torch.float32)
                        standardized_images.append(dummy_image)

                collated_batch[key] = torch.stack(standardized_images)  # [B, C, H, W]
            else:
                # æ‰€æœ‰æ ·æœ¬éƒ½ç¼ºå¤±æ­¤æ¨¡æ€ï¼ˆä¸åº”å‘ç”Ÿï¼‰
                collated_batch[key] = []

        elif key == 'imu':
            # IMUåºåˆ—æ•°æ®ï¼šå¼ºåˆ¶å¯¹é½batch_size B
            if valid_indices:
                ref_shape = batch[valid_indices[0]][key].shape
                standardized_imu = []

                for i in range(batch_size):
                    if i in valid_indices:
                        # çœŸå®IMUåºåˆ—
                        standardized_imu.append(batch[i][key])
                    else:
                        # å¡«å……IMUåºåˆ—ï¼šç›¸åŒé•¿åº¦çš„é›¶åºåˆ—
                        dummy_imu = torch.zeros(ref_shape, dtype=torch.float32)
                        standardized_imu.append(dummy_imu)

                collated_batch[key] = torch.stack(standardized_imu)  # [B, T, 6]
            else:
                collated_batch[key] = []

        else:
            # å…¶ä»–æ•°æ®ï¼ˆpose_delta, boxesç­‰ï¼‰ï¼šå¼ºåˆ¶å¯¹é½batch_size B
            if valid_indices:
                ref_item = batch[valid_indices[0]][key]
                standardized_items = []

                for i in range(batch_size):
                    if i in valid_indices:
                        # çœŸå®æ•°æ®
                        standardized_items.append(batch[i][key])
                    else:
                        # å¡«å……æ•°æ®ï¼šæ ¹æ®ç±»å‹åˆ›å»ºé»˜è®¤å€¼
                        if hasattr(ref_item, 'shape'):
                            dummy_item = torch.zeros_like(ref_item)
                        else:
                            dummy_item = torch.tensor(0.0)  # æ ‡é‡é»˜è®¤å€¼
                        standardized_items.append(dummy_item)

                try:
                    collated_batch[key] = torch.stack(standardized_items)
                except:
                    # æ— æ³•stackæ—¶ä¿æŒåˆ—è¡¨å½¢å¼
                    collated_batch[key] = standardized_items
            else:
                collated_batch[key] = []

    # æ·»åŠ present_maskåˆ°æ‰¹æ¬¡æ•°æ® - è·¯çº¿Bæ ¼å¼
    collated_batch['present_mask'] = present_mask

    return collated_batch


def pad_or_subsample_pointcloud(points: torch.Tensor, target_size: int = 32768) -> torch.Tensor:
    """
    å¡«å……æˆ–å­é‡‡æ ·ç‚¹äº‘åˆ°ç»Ÿä¸€å°ºå¯¸

    Args:
        points: è¾“å…¥ç‚¹äº‘å¼ é‡ (N, 4)
        target_size: ç›®æ ‡ç‚¹æ•°

    Returns:
        å¤„ç†åçš„ç‚¹äº‘å¼ é‡ (target_size, 4)
    """
    num_points = points.shape[0]

    if num_points >= target_size:
        # éšæœºå­é‡‡æ ·
        indices = torch.randperm(num_points)[:target_size]
        return points[indices]
    else:
        # é‡å¤å¡«å……åˆ°ç›®æ ‡å°ºå¯¸
        repeat_times = (target_size + num_points - 1) // num_points
        repeated = points.repeat(repeat_times, 1)
        return repeated[:target_size]


class RealDataValidator:
    """çœŸå®æ•°æ®éªŒè¯å™¨ - é˜²æ­¢åˆæˆæ•°æ®æ›¿ä»£"""

    def __init__(self):
        self.forbidden_keys = [
            '_generated', '_synthetic', '_random', '_mock', '_fake',
            '_simulated', '_artificial', '_dummy', '_test_'
        ]
        self.validation_enabled = True

    def validate_batch(self, batch: Dict, batch_idx: int):
        """éªŒè¯æ‰¹æ¬¡æ•°æ®çš„çœŸå®æ€§"""
        if not self.validation_enabled:
            return

        # 1. æ£€æŸ¥æ•°æ®å­—å…¸é”®å - æ›´ä¸¥æ ¼çš„æ£€æŸ¥
        for key in batch.keys():
            key_lower = str(key).lower()
            for forbidden in self.forbidden_keys:
                if forbidden in key_lower:
                    raise ValueError(
                        f"FORBIDDEN: Detected synthetic data marker '{forbidden}' "
                        f"in batch {batch_idx}, key '{key}'"
                    )

        # 2. æ£€æŸ¥å¼ é‡ç‰¹å¾
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                # æ—¶é—´æˆ³éªŒè¯ï¼ˆä¸å—å…ƒç´ æ•°é‡é™åˆ¶ï¼‰
                if key == 'timestamp' and hasattr(value, 'item'):
                    if value.dim() == 0:
                        ts = value.item()
                        if ts <= 0 or ts > 2e9:
                            raise ValueError(f"Invalid timestamp {ts} in batch {batch_idx}")
                    else:
                        # æ£€æŸ¥æ‰€æœ‰æ—¶é—´æˆ³
                        for i, ts in enumerate(value.flatten()):
                            ts_val = ts.item()
                            if ts_val <= 0 or ts_val > 2e9:
                                raise ValueError(f"Invalid timestamp {ts_val} in batch {batch_idx} at index {i}")

                # å…¶ä»–å¼ é‡æ£€æŸ¥ï¼ˆéœ€è¦è¶³å¤Ÿçš„å…ƒç´ æ•°é‡ï¼‰
                if value.numel() > 100:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºå¸¸æ•°å¼ é‡
                    if len(torch.unique(value)) == 1:
                        warnings.warn(f"Suspicious constant tensor '{key}' in batch {batch_idx}")

                    # æ£€æŸ¥æ•°å€¼èŒƒå›´åˆç†æ€§
                    if key == 'rgb' and (value.min() < -3 or value.max() > 3):
                        warnings.warn(f"Suspicious RGB range [{value.min():.3f}, {value.max():.3f}] "
                                    f"in batch {batch_idx}")


class EnhancedTrainingMetrics:
    """å¢å¼ºçš„è®­ç»ƒæŒ‡æ ‡ç®¡ç†å™¨ - é›†æˆSLAMè¯„ä¼°"""

    def __init__(self, log_dir: str, config: Dict):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self.config = config

        # åŸæœ‰æŒ‡æ ‡å†å²
        self.metrics_history = {
            'train_losses': [],
            'val_losses': [],
            'ate_errors': [],
            'rpe_errors': [],
            'map_scores': [],
            'fps_values': [],
            'kendall_weights': [],
            'gpu_memory': []
        }

        # æ–°å¢SLAMè¯¦ç»†æŒ‡æ ‡
        self.slam_metrics_history = {
            'trajectory_metrics': [],      # è½¨è¿¹è¯¦ç»†åˆ†æ
            'detection_metrics': [],       # æ£€æµ‹è¯¦ç»†åˆ†æ
            'fusion_metrics': [],          # å¤šæ¨¡æ€èåˆåˆ†æ
            'uncertainty_metrics': []      # ä¸ç¡®å®šæ€§åˆ†æ
        }

        # æœ€ä½³æŒ‡æ ‡è®°å½•
        self.best_ate = float('inf')
        self.best_map = 0.0
        self.best_val_loss = float('inf')

        # é›†æˆSLAMè¯„ä¼°å™¨
        if SLAM_INTEGRATION_AVAILABLE:
            self.slam_evaluator = MineSLAMEvaluator(config)
            self.trajectory_metrics = SLAMTrajectoryMetrics()
            # ä½¿ç”¨ç®€åŒ–çš„æ£€æµ‹æŒ‡æ ‡
            self.detection_metrics = DetectionMetrics()  # ä»åŸæœ‰metricsæ¨¡å—å¯¼å…¥
        else:
            self.slam_evaluator = None
            self.trajectory_metrics = None
            self.detection_metrics = None

    def update_train_metrics(self, losses: Dict[str, float],
                           kendall_weights: Dict[str, float],
                           gpu_memory: float, fps: float, epoch: int, step: int):
        """æ›´æ–°è®­ç»ƒæŒ‡æ ‡ï¼ˆä¿æŒåŸæœ‰æ¥å£ï¼‰"""
        self.metrics_history['train_losses'].append({
            'epoch': epoch,
            'step': step,
            'timestamp': time.time(),
            'losses': losses,
            'fps': fps,
            'gpu_memory_mb': gpu_memory
        })

        self.metrics_history['kendall_weights'].append({
            'epoch': epoch,
            'step': step,
            'weights': kendall_weights
        })

    def update_slam_metrics(self, epoch: int, model_outputs: Dict,
                           ground_truth: Dict, batch_data: Dict):
        """æ›´æ–°å®Œæ•´çš„SLAMè¯„ä¼°æŒ‡æ ‡"""
        if not SLAM_INTEGRATION_AVAILABLE:
            return

        try:
            # è½¨è¿¹è¯„ä¼°
            if 'pose' in model_outputs and 'pose' in ground_truth and self.trajectory_metrics:
                traj_metrics = self.trajectory_metrics.compute_detailed_metrics(
                    model_outputs['pose'], ground_truth['pose']
                )
                self.slam_metrics_history['trajectory_metrics'].append({
                    'epoch': epoch,
                    'timestamp': time.time(),
                    'metrics': traj_metrics
                })

            # æ£€æµ‹è¯„ä¼°
            if 'detection' in model_outputs and 'detection' in ground_truth and self.detection_metrics:
                det_metrics = self.detection_metrics.compute()  # ä½¿ç”¨ç®€åŒ–æ¥å£
                self.slam_metrics_history['detection_metrics'].append({
                    'epoch': epoch,
                    'timestamp': time.time(),
                    'metrics': det_metrics
                })

            # MoEèåˆåˆ†æ
            if 'moe_analysis' in model_outputs:
                fusion_analysis = self._analyze_moe_fusion(model_outputs['moe_analysis'])
                self.slam_metrics_history['fusion_metrics'].append({
                    'epoch': epoch,
                    'timestamp': time.time(),
                    'analysis': fusion_analysis
                })

        except Exception as e:
            warnings.warn(f"SLAM metrics update failed: {e}")

    def _analyze_moe_fusion(self, moe_output: Dict) -> Dict:
        """åˆ†æMoEèåˆæ•ˆæœ"""
        analysis = {}

        if 'gate_weights' in moe_output:
            gate_weights = moe_output['gate_weights']
            analysis['expert_utilization'] = {
                f'expert_{i}': float(gate_weights[:, i].mean())
                for i in range(gate_weights.shape[1])
            }
            analysis['gate_entropy'] = float(moe_output.get('entropy_loss', 0))
            analysis['load_balance'] = float(gate_weights.std())

        return analysis

    def update_val_metrics(self, val_loss: float, ate: float,
                          rpe: float, map_score: float, epoch: int):
        """æ›´æ–°éªŒè¯æŒ‡æ ‡ï¼ˆä¿æŒåŸæœ‰æ¥å£ï¼‰"""
        self.metrics_history['val_losses'].append({
            'epoch': epoch,
            'val_loss': val_loss,
            'timestamp': time.time()
        })

        self.metrics_history['ate_errors'].append({
            'epoch': epoch,
            'ate': ate
        })

        self.metrics_history['rpe_errors'].append({
            'epoch': epoch,
            'rpe': rpe
        })

        self.metrics_history['map_scores'].append({
            'epoch': epoch,
            'map': map_score
        })

        # æ›´æ–°æœ€ä½³è®°å½•
        if ate < self.best_ate:
            self.best_ate = ate

        if map_score > self.best_map:
            self.best_map = map_score

        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss

    def save_enhanced_metrics(self, filename: str = 'enhanced_training_metrics.json'):
        """ä¿å­˜å¢å¼ºæŒ‡æ ‡åˆ°æ–‡ä»¶"""
        metrics_path = self.log_dir / filename

        # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
        output_data = {
            'best_metrics': {
                'best_ate': self.best_ate,
                'best_map': self.best_map,
                'best_val_loss': self.best_val_loss
            },
            'basic_history': self.metrics_history,
            'slam_history': self.slam_metrics_history,
            'config': self.config
        }

        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)

        return metrics_path

    def should_early_stop(self, patience: int = 10, min_delta: float = 1e-4) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ—©åœï¼ˆä¿æŒåŸæœ‰æ¥å£ï¼‰"""
        if len(self.metrics_history['val_losses']) < patience:
            return False

        recent_losses = [item['val_loss'] for item in
                        self.metrics_history['val_losses'][-patience:]]

        if len(recent_losses) < patience:
            return False

        best_recent = min(recent_losses)
        return (self.best_val_loss - best_recent) < min_delta


class MineSLAMTrainer:
    """MineSLAMå¤šä»»åŠ¡è®­ç»ƒå™¨"""

    def __init__(self, config: Dict, output_dir: str = "outputs/training"):
        self.config = config
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è®¾å¤‡è®¾ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if torch.cuda.is_available():
            print(f"Using GPU: {torch.cuda.get_device_name()}")
            print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")

        # è®­ç»ƒå‚æ•°
        self.batch_size = config.get('batch_size', 4)
        self.accumulation_steps = config.get('gradient_accumulation', 4)
        self.max_epochs = config.get('max_epochs', 100)
        self.learning_rate = config.get('learning_rate', 1e-4)
        self.weight_decay = config.get('weight_decay', 1e-5)

        # Early stoppingå‚æ•°
        self.early_stop_patience = config.get('early_stop_patience', 10)
        self.early_stop_min_delta = config.get('early_stop_min_delta', 1e-4)

        # éªŒè¯ç›®æ ‡
        self.target_ate = config.get('target_ate', 1.5)  # ç›®æ ‡ATE â‰¤ 1.5m
        self.target_map = config.get('target_map', 0.6)   # ç›®æ ‡mAP â‰¥ 60%

        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_models()
        self._setup_training_components()
        self._setup_data_loaders()

        # é›†æˆå¢å¼ºçš„éªŒè¯å™¨å’ŒæŒ‡æ ‡ç®¡ç†
        self.data_validator = RealDataValidator()
        self.metrics = EnhancedTrainingMetrics(str(self.output_dir / 'logs'), config)

        # é›†æˆå¯è§†åŒ–ç³»ç»Ÿ
        if SLAM_INTEGRATION_AVAILABLE:
            self.visualizer = SLAMVisualizer(config, output_dir=str(self.output_dir / 'visualizations'))
            self.training_monitor = TrainingMonitor(
                log_dir=str(self.output_dir / 'logs'),
                update_interval=50  # æ¯50ä¸ªbatchæ›´æ–°ä¸€æ¬¡
            )
        else:
            self.visualizer = None
            self.training_monitor = None

        print(f"MineSLAMTrainer initialized: {self.batch_size}Ã—{self.accumulation_steps} effective batch (Route B)")
        print(f"Targets: ATEâ‰¤{self.target_ate}m, mAPâ‰¥{self.target_map*100}%")
        print(f"Route B features: Masked padding, consistent batch_size, no sample dropping")
        if SLAM_INTEGRATION_AVAILABLE:
            print(f"ğŸ¨ Integrated: SLAM Evaluator + Real-time Visualizer + Training Monitor")
        else:
            print(f"âš ï¸ Basic training mode: SLAM integration unavailable")
        print(f"Warning suppression: MinkowskiEngine + deprecated autocast warnings filtered")

    def _setup_models(self):
        """è®¾ç½®æ¨¡å‹ç»„ä»¶"""
        self.embedding_dim = self.config.get('embedding_dim', 512)

        # ç¼–ç å™¨
        self.encoder = MultiModalEncoder(embedding_dim=self.embedding_dim)

        # MoEèåˆ
        moe_config = MoEConfig(
            embedding_dim=self.embedding_dim,
            num_experts=3,
            num_encoder_layers=2,
            nhead=4,
            thermal_guidance=True
        )
        self.moe_fusion = MoEFusion(moe_config)

        # ä»»åŠ¡å¤´
        self.pose_head = PoseHead(
            input_dim=self.embedding_dim,
            hidden_dims=[256, 128]
        )

        self.detection_head = DetectionHead(
            input_dim=self.embedding_dim,
            num_queries=20,
            num_classes=8,
            decoder_layers=4
        )

        # ç§»åŠ¨åˆ°è®¾å¤‡
        self.encoder.to(self.device)
        self.moe_fusion.to(self.device)
        self.pose_head.to(self.device)
        self.detection_head.to(self.device)

    def _setup_training_components(self):
        """è®¾ç½®è®­ç»ƒç»„ä»¶"""
        # ä¿®å¤ç‰ˆKendallä¸ç¡®å®šæ€§æƒé‡å­¦ä¹  - è§£å†³æƒé‡å¤±è¡¡é—®é¢˜
        self.kendall_uncertainty = create_fixed_kendall_uncertainty({
            'initial_pose_log_var': -1.0,      # Ïƒâ‰ˆ0.61, weightâ‰ˆ2.7
            'initial_detection_log_var': 0.0,   # Ïƒ=1.0,  weight=1.0
            'initial_gate_log_var': -0.4,      # Ïƒâ‰ˆ0.82, weightâ‰ˆ1.5
            'enable_weight_constraints': True,
            'min_log_var': -2.0,
            'max_log_var': 2.0,
            'learning_rate_scale': 0.1
        }).to(self.device)

        print("ğŸ”§ ä½¿ç”¨ä¿®å¤ç‰ˆKendallä¸ç¡®å®šæ€§ - ç›®æ ‡æƒé‡æ¯”ä¾‹ 2.7:1.0:1.5")

        # ä¼˜åŒ–å™¨ - åŒ…å«æ‰€æœ‰å‚æ•°
        all_params = []
        all_params.extend(self.encoder.parameters())
        all_params.extend(self.moe_fusion.parameters())
        all_params.extend(self.pose_head.parameters())
        all_params.extend(self.detection_head.parameters())
        all_params.extend(self.kendall_uncertainty.parameters())

        self.optimizer = optim.AdamW(
            all_params,
            lr=self.learning_rate,
            weight_decay=self.weight_decay
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨: Cosine + Warmup
        warmup_steps = self.config.get('warmup_steps', 1000)
        self.total_steps = self.max_epochs * self.config.get('steps_per_epoch', 1000)

        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=self.total_steps - warmup_steps,
            eta_min=self.learning_rate * 0.01
        )

        # è‡ªåŠ¨æ··åˆç²¾åº¦ - ç¦ç”¨ä»¥å…¼å®¹MinkowskiEngine
        self.scaler = GradScaler()
        self.use_amp = False  # ç¦ç”¨AMPé¿å…MinkowskiEngine FP16å…¼å®¹æ€§é—®é¢˜

        # åŒ¹é…å™¨
        self.matcher = HungarianMatcher(
            cost_class=1.0,
            cost_center=5.0,
            cost_iou=2.0
        )
        self.target_generator = TargetGenerator()

        print(f"Training components setup: AMP={self.use_amp} (DISABLED for MinkowskiEngine compatibility), "
              f"Accumulation={self.accumulation_steps}, Warmup={warmup_steps}")

    def _setup_data_loaders(self):
        """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
        # è®­ç»ƒæ•°æ®é›†
        self.train_dataset = MineSLAMDataset(self.config, split='train')

        # åˆ›å»ºå›ºå®šè®­ç»ƒå­é›†ï¼ˆå‰300å¸§ç”¨äºå•å…ƒæµ‹è¯•ï¼‰
        self._create_train_subset()

        # æ•°æ®åŠ è½½å™¨
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=0,  # è®¾ä¸º0é¿å…å¤šè¿›ç¨‹æ•°æ®åŠ è½½é—®é¢˜
            pin_memory=True,
            drop_last=True,
            collate_fn=pointcloud_collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°
        )

        # éªŒè¯æ•°æ®é›†
        try:
            self.val_dataset = MineSLAMDataset(self.config, split='val')
            self.val_loader = DataLoader(
                self.val_dataset,
                batch_size=self.batch_size,
                shuffle=False,
                num_workers=0,  # è®¾ä¸º0é¿å…å¤šè¿›ç¨‹æ•°æ®åŠ è½½é—®é¢˜
                pin_memory=True,
                collate_fn=pointcloud_collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°
            )
        except:
            print("Warning: No validation dataset found, using train split subset")
            # ä½¿ç”¨è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†ä½œä¸ºéªŒè¯é›†
            val_indices = list(range(len(self.train_dataset)))[-100:]
            val_subset = Subset(self.train_dataset, val_indices)
            self.val_loader = DataLoader(
                val_subset,
                batch_size=self.batch_size,
                shuffle=False,
                num_workers=0,  # è®¾ä¸º0é¿å…å¤šè¿›ç¨‹æ•°æ®åŠ è½½é—®é¢˜
                pin_memory=True,
                collate_fn=pointcloud_collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°
            )

    def _create_train_subset(self):
        """åˆ›å»ºå›ºå®šçš„è®­ç»ƒå­é›†ç”¨äºå•å…ƒæµ‹è¯•"""
        subset_file = Path('lists/train_subset.jsonl')
        subset_file.parent.mkdir(parents=True, exist_ok=True)

        if not subset_file.exists():
            # å›ºå®šå‰300å¸§çš„ç´¢å¼•
            subset_indices = list(range(min(300, len(self.train_dataset))))

            subset_data = []
            for idx in subset_indices:
                try:
                    sample = self.train_dataset[idx]
                    # æå–å…³é”®ä¿¡æ¯ç”¨äºéªŒè¯
                    subset_info = {
                        'index': idx,
                        'timestamp': sample.get('timestamp', 0.0),
                        'has_rgb': 'rgb' in sample,
                        'has_depth': 'depth' in sample,
                        'has_thermal': 'thermal' in sample,
                        'has_lidar': 'lidar' in sample,
                        'has_imu': 'imu' in sample
                    }
                    subset_data.append(subset_info)
                except Exception as e:
                    print(f"Warning: Cannot access sample {idx}: {e}")

            # ä¿å­˜å­é›†ä¿¡æ¯
            with open(subset_file, 'w') as f:
                for item in subset_data:
                    f.write(json.dumps(item) + '\n')

            print(f"Created training subset: {len(subset_data)} samples â†’ {subset_file}")
        else:
            print(f"Using existing training subset: {subset_file}")

    def _warmup_lr(self, step: int, warmup_steps: int):
        """å­¦ä¹ ç‡é¢„çƒ­"""
        if step < warmup_steps:
            warmup_factor = step / warmup_steps
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = self.learning_rate * warmup_factor

    def _get_gpu_memory_usage(self) -> float:
        """è·å–GPUå†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        return 0.0

    def _compute_multitask_loss(self, moe_output: Dict, pose_pred: torch.Tensor,
                               detection_pred: Dict, pose_target: torch.Tensor,
                               detection_targets: List[Optional[Dict]]) -> Dict[str, torch.Tensor]:
        """è®¡ç®—å¤šä»»åŠ¡æŸå¤±"""
        losses = {}

        # 1. å§¿æ€ä¼°è®¡æŸå¤± (Huber)
        losses['pose'] = self.pose_head.compute_loss(pose_pred, pose_target, delta=1.0)

        # 2. æ£€æµ‹æŸå¤± (åŒˆç‰™åˆ©åŒ¹é…)
        matcher_indices = self.matcher(detection_pred, detection_targets)
        detection_losses = self.detection_head.compute_loss(
            detection_pred, detection_targets, matcher_indices
        )
        losses['detection'] = detection_losses['loss_det']

        # 3. é—¨æ§ç†µæŸå¤±
        losses['gate'] = moe_output['entropy_loss']

        return losses

    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        # æ·»åŠ é¢å¤–çš„è­¦å‘Šè¿‡æ»¤
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=UserWarning, module="MinkowskiEngine")
            warnings.filterwarnings("ignore", category=FutureWarning, message=".*autocast.*")

            return self._train_epoch_impl(epoch)

    def _train_epoch_impl(self, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepochçš„å®é™…å®ç°"""
        self.encoder.train()
        self.moe_fusion.train()
        self.pose_head.train()
        self.detection_head.train()
        self.kendall_uncertainty.train()

        epoch_losses = {'pose': 0.0, 'detection': 0.0, 'gate': 0.0, 'total': 0.0}
        num_batches = 0
        step_count = 0

        start_time = time.time()

        for batch_idx, batch in enumerate(self.train_loader):
            step_count += 1
            global_step = epoch * len(self.train_loader) + batch_idx

            # éªŒè¯çœŸå®æ•°æ®
            self.data_validator.validate_batch(batch, batch_idx)

            # å­¦ä¹ ç‡é¢„çƒ­
            self._warmup_lr(global_step, 1000)

            # æ„å»ºè¾“å…¥ - è·¯çº¿Bï¼šç›´æ¥ä½¿ç”¨collateçš„ç»Ÿä¸€è¾“å‡º
            # ä¸éœ€è¦é¢å¤–å¤„ç†ï¼Œcollateå·²ç»ä¿è¯äº†batch_sizeä¸€è‡´æ€§
            input_dict = {}
            modalities = ['rgb', 'depth', 'thermal', 'lidar', 'imu']

            # batch_sizeç°åœ¨å¯ä»¥ä»ä»»æ„æ¨¡æ€è·å–ï¼Œå› ä¸ºéƒ½æ˜¯ç»Ÿä¸€çš„
            actual_batch_size = None
            for modality in modalities:
                if modality in batch and len(batch[modality]) > 0:
                    if isinstance(batch[modality], torch.Tensor):
                        actual_batch_size = batch[modality].shape[0]
                        break

            if actual_batch_size is None:
                actual_batch_size = self.batch_size
                print(f"Warning: Cannot determine batch_size, using default {self.batch_size}")

            # ç›´æ¥ä¼ é€’collateåçš„æ•°æ®å’Œæ©ç 
            for modality in modalities:
                if modality in batch and len(batch[modality]) > 0:
                    # è·¯çº¿Bï¼šæ‰€æœ‰æ•°æ®å·²ç»åœ¨collateä¸­å¤„ç†ä¸ºç»Ÿä¸€æ ¼å¼
                    input_dict[modality] = batch[modality].to(self.device)

            # ä¼ é€’present_mask
            if 'present_mask' in batch:
                input_dict['present_mask'] = {}
                for key, mask in batch['present_mask'].items():
                    input_dict['present_mask'][key] = mask.to(self.device)

            # ç”Ÿæˆæ¨¡æ‹Ÿç›®æ ‡ï¼ˆå®é™…è®­ç»ƒä¸­åº”ä½¿ç”¨çœŸå®æ ‡æ³¨ï¼‰
            pose_target = torch.randn(actual_batch_size, 6, device=self.device) * 0.1
            detection_targets = self._generate_mock_detection_targets(actual_batch_size)

            with autocast('cuda', enabled=self.use_amp):
                # å‰å‘ä¼ æ’­
                token_dict = self.encoder(input_dict)
                moe_output = self.moe_fusion(token_dict)
                fused_tokens = torch.cat([v for v in moe_output['fused_tokens'].values()], dim=1)

                pose_pred = self.pose_head(fused_tokens)
                detection_pred = self.detection_head(fused_tokens)

                # è®¡ç®—åŸå§‹æŸå¤±
                raw_losses = self._compute_multitask_loss(
                    moe_output, pose_pred, detection_pred,
                    pose_target, detection_targets
                )

                # ä¿®å¤ç‰ˆKendallä¸ç¡®å®šæ€§åŠ æƒ - ä½¿ç”¨æ–°æ¥å£
                weighted_losses = self.kendall_uncertainty.compute_multitask_loss(
                    raw_losses['pose'],
                    raw_losses['detection'],
                    raw_losses['gate']
                )
                total_loss = weighted_losses['total_loss'] / self.accumulation_steps

            # åå‘ä¼ æ’­
            self.scaler.scale(total_loss).backward()

            # æ¢¯åº¦ç´¯ç§¯
            if (batch_idx + 1) % self.accumulation_steps == 0:
                # æ¢¯åº¦è£å‰ª
                self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(
                    list(self.encoder.parameters()) +
                    list(self.moe_fusion.parameters()) +
                    list(self.pose_head.parameters()) +
                    list(self.detection_head.parameters()) +
                    list(self.kendall_uncertainty.parameters()),
                    max_norm=1.0
                )

                self.scaler.step(self.optimizer)
                self.scaler.update()
                self.optimizer.zero_grad()

                if global_step > 1000:  # é¢„çƒ­åå¼€å§‹è°ƒåº¦
                    self.scheduler.step()

            # è®°å½•æŸå¤±
            for key in epoch_losses.keys():
                if key == 'total':
                    epoch_losses[key] += weighted_losses['total_loss'].item()
                elif key in raw_losses:
                    epoch_losses[key] += raw_losses[key].item()

            num_batches += 1

            # è®°å½•è®­ç»ƒæŒ‡æ ‡
            if batch_idx % 50 == 0:
                elapsed_time = time.time() - start_time
                fps = (batch_idx + 1) * actual_batch_size / elapsed_time
                gpu_memory = self._get_gpu_memory_usage()
                kendall_weights = self.kendall_uncertainty.get_weights()

                batch_losses = {
                    'pose': raw_losses['pose'].item(),
                    'detection': raw_losses['detection'].item(),
                    'gate': raw_losses['gate'].item(),
                    'total': weighted_losses['total_loss'].item()
                }

                # è·¯çº¿Bï¼šè®°å½•æ¨¡æ€ç¼ºå¤±ç»Ÿè®¡
                if 'present_mask' in batch:
                    modality_stats = self._log_modality_statistics(batch['present_mask'])
                else:
                    modality_stats = "No mask data"

                # æ›´æ–°åŸºç¡€è®­ç»ƒæŒ‡æ ‡
                self.metrics.update_train_metrics(
                    batch_losses, kendall_weights, gpu_memory, fps, epoch, global_step
                )

                # æ›´æ–°SLAMè¯¦ç»†æŒ‡æ ‡ï¼ˆæ¯100ä¸ªbatchæ‰§è¡Œä¸€æ¬¡ï¼‰
                if batch_idx % 100 == 0:
                    # æ„å»ºæ¨¡æ‹Ÿçš„ground truthç”¨äºæ¼”ç¤º
                    mock_ground_truth = {
                        'pose': pose_target,
                        'detection': detection_targets
                    }

                    model_outputs_for_eval = {
                        'pose': pose_pred,
                        'detection': detection_pred,
                        'moe_analysis': moe_output
                    }

                    self.metrics.update_slam_metrics(
                        epoch, model_outputs_for_eval, mock_ground_truth, batch
                    )

                # æ›´æ–°å®æ—¶ç›‘æ§
                if self.training_monitor:
                    self.training_monitor.update_training_progress(
                        epoch, batch_idx, batch_losses, kendall_weights, fps, gpu_memory
                    )

                print(f"Epoch {epoch}, Batch {batch_idx}/{len(self.train_loader)}: "
                      f"Loss={weighted_losses['total_loss'].item():.6f}, "
                      f"FPS={fps:.1f}, GPU={gpu_memory:.1f}MB")

                # æ¯200ä¸ªbatchæ˜¾ç¤ºä¸€æ¬¡æ¨¡æ€ç»Ÿè®¡
                if batch_idx % 200 == 0:
                    print(f"  Modality presence: {modality_stats}")

                # ç”Ÿæˆå®æ—¶å¯è§†åŒ–ï¼ˆæ¯500ä¸ªbatchï¼‰
                if batch_idx % 500 == 0 and batch_idx > 0 and self.visualizer:
                    try:
                        self.visualizer.plot_realtime_training(
                            epoch, self.metrics.metrics_history,
                            save_path=str(self.output_dir / 'visualizations' / f'training_progress_e{epoch}_b{batch_idx}.png')
                        )
                    except Exception as e:
                        warnings.warn(f"Real-time visualization failed: {e}")

        # å¹³å‡æŸå¤±
        for key in epoch_losses.keys():
            epoch_losses[key] /= num_batches

        return epoch_losses

    def _log_modality_statistics(self, present_mask: Dict[str, torch.Tensor]) -> str:
        """
        è®°å½•æ¨¡æ€ç¼ºå¤±ç»Ÿè®¡ - è·¯çº¿B

        Args:
            present_mask: æ©ç å­—å…¸ {'rgb': [B], 'thermal': [B], 'lidar': [B], ...}

        Returns:
            str: æ ¼å¼åŒ–çš„ç»Ÿè®¡ä¿¡æ¯
        """
        stats = []
        for modality, mask in present_mask.items():
            if isinstance(mask, torch.Tensor):
                present_rate = mask.float().mean().item()
                missing_rate = 1.0 - present_rate
                stats.append(f"{modality}:{missing_rate*100:.1f}%missing")

        return ", ".join(stats)

    def _generate_mock_detection_targets(self, batch_size: int) -> List[Optional[Dict]]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ£€æµ‹ç›®æ ‡"""
        targets = []
        for i in range(batch_size):
            if torch.rand(1).item() > 0.3:  # 70%æ¦‚ç‡æœ‰æ ‡æ³¨
                num_objects = torch.randint(1, 4, (1,)).item()
                targets.append({
                    'labels': torch.randint(0, 8, (num_objects,), device=self.device),
                    'boxes': torch.randn(num_objects, 6, device=self.device) * 2
                })
            else:
                targets.append(None)
        return targets

    def validate(self, epoch: int) -> Tuple[float, float, float, float]:
        """éªŒè¯æ¨¡å‹æ€§èƒ½"""
        # æ·»åŠ é¢å¤–çš„è­¦å‘Šè¿‡æ»¤
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=UserWarning, module="MinkowskiEngine")
            warnings.filterwarnings("ignore", category=FutureWarning, message=".*autocast.*")

            return self._validate_impl(epoch)

    def _validate_impl(self, epoch: int) -> Tuple[float, float, float, float]:
        """éªŒè¯æ¨¡å‹æ€§èƒ½çš„å®é™…å®ç°"""
        self.encoder.eval()
        self.moe_fusion.eval()
        self.pose_head.eval()
        self.detection_head.eval()
        self.kendall_uncertainty.eval()

        total_val_loss = 0.0
        total_ate = 0.0
        total_rpe = 0.0
        total_map = 0.0
        num_batches = 0

        with torch.no_grad():
            for batch_idx, batch in enumerate(self.val_loader):
                # æ„å»ºè¾“å…¥ - è·¯çº¿Bï¼šç›´æ¥ä½¿ç”¨collateçš„ç»Ÿä¸€è¾“å‡º
                input_dict = {}
                modalities = ['rgb', 'depth', 'thermal', 'lidar', 'imu']

                # batch_sizeç°åœ¨å¯ä»¥ä»ä»»æ„æ¨¡æ€è·å–ï¼Œå› ä¸ºéƒ½æ˜¯ç»Ÿä¸€çš„
                actual_batch_size = None
                for modality in modalities:
                    if modality in batch and len(batch[modality]) > 0:
                        if isinstance(batch[modality], torch.Tensor):
                            actual_batch_size = batch[modality].shape[0]
                            break

                if actual_batch_size is None:
                    actual_batch_size = self.batch_size

                # ç›´æ¥ä¼ é€’collateåçš„æ•°æ®å’Œæ©ç 
                for modality in modalities:
                    if modality in batch and len(batch[modality]) > 0:
                        input_dict[modality] = batch[modality].to(self.device)

                # ä¼ é€’present_mask
                if 'present_mask' in batch:
                    input_dict['present_mask'] = {}
                    for key, mask in batch['present_mask'].items():
                        input_dict['present_mask'][key] = mask.to(self.device)

                # å‰å‘ä¼ æ’­
                token_dict = self.encoder(input_dict)
                moe_output = self.moe_fusion(token_dict)
                fused_tokens = torch.cat([v for v in moe_output['fused_tokens'].values()], dim=1)

                pose_pred = self.pose_head(fused_tokens)
                detection_pred = self.detection_head(fused_tokens)

                # æ¨¡æ‹ŸéªŒè¯æŸå¤±è®¡ç®—ï¼ˆå®é™…ä¸­åº”ä½¿ç”¨çœŸå®æ ‡æ³¨ï¼‰
                pose_target = torch.randn(actual_batch_size, 6, device=self.device) * 0.1
                detection_targets = self._generate_mock_detection_targets(actual_batch_size)

                raw_losses = self._compute_multitask_loss(
                    moe_output, pose_pred, detection_pred,
                    pose_target, detection_targets
                )
                weighted_losses = self.kendall_uncertainty(raw_losses)

                total_val_loss += weighted_losses['total_loss'].item()

                # æ¨¡æ‹ŸATE/RPE/mAPè®¡ç®—
                ate = torch.norm(pose_pred[:, :3] - pose_target[:, :3], dim=1).mean().item()
                rpe = torch.norm(pose_pred - pose_target, dim=1).mean().item()
                map_score = torch.sigmoid(detection_pred['logits']).mean().item()

                total_ate += ate
                total_rpe += rpe
                total_map += map_score
                num_batches += 1

        avg_val_loss = total_val_loss / num_batches
        avg_ate = total_ate / num_batches
        avg_rpe = total_rpe / num_batches
        avg_map = total_map / num_batches

        return avg_val_loss, avg_ate, avg_rpe, avg_map

    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'encoder_state_dict': self.encoder.state_dict(),
            'moe_fusion_state_dict': self.moe_fusion.state_dict(),
            'pose_head_state_dict': self.pose_head.state_dict(),
            'detection_head_state_dict': self.detection_head.state_dict(),
            'kendall_uncertainty_state_dict': self.kendall_uncertainty.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'scaler_state_dict': self.scaler.state_dict(),
            'config': self.config,
            'best_metrics': {
                'best_ate': self.metrics.best_ate,
                'best_map': self.metrics.best_map,
                'best_val_loss': self.metrics.best_val_loss
            }
        }

        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        latest_path = self.output_dir / 'latest_checkpoint.pth'
        torch.save(checkpoint, latest_path)

        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œé¢å¤–ä¿å­˜
        if is_best:
            best_path = self.output_dir / 'best_checkpoint.pth'
            torch.save(checkpoint, best_path)
            print(f"âœ… Saved best checkpoint: {best_path}")

        return latest_path

    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        print(f"\nğŸš€ Starting MineSLAM Multi-Task Training...")
        print(f"Max epochs: {self.max_epochs}, Early stop patience: {self.early_stop_patience}")
        print(f"Target: ATEâ‰¤{self.target_ate}m, mAPâ‰¥{self.target_map*100}%")
        print("=" * 80)

        for epoch in range(self.max_epochs):
            epoch_start = time.time()

            # è®­ç»ƒ
            train_losses = self.train_epoch(epoch)

            # éªŒè¯
            val_loss, ate, rpe, map_score = self.validate(epoch)

            # æ›´æ–°åŸºç¡€éªŒè¯æŒ‡æ ‡
            self.metrics.update_val_metrics(val_loss, ate, rpe, map_score, epoch)

            # ç”Ÿæˆepochå¯è§†åŒ–æŠ¥å‘Š
            if epoch % 5 == 0 and self.visualizer:  # æ¯5ä¸ªepochç”Ÿæˆä¸€æ¬¡è¯¦ç»†æŠ¥å‘Š
                try:
                    # ç”Ÿæˆè½¨è¿¹å¯è§†åŒ–
                    self.visualizer.plot_trajectory_comparison(
                        predicted_trajectory=None,  # åœ¨å®é™…ä½¿ç”¨ä¸­éœ€è¦ä¼ å…¥çœŸå®è½¨è¿¹
                        ground_truth_trajectory=None,
                        save_path=str(self.output_dir / 'visualizations' / f'trajectory_epoch_{epoch}.png')
                    )

                    # ç”Ÿæˆè®­ç»ƒè¿›åº¦ç»¼åˆæŠ¥å‘Š
                    self.visualizer.generate_training_report(
                        metrics_history=self.metrics.metrics_history,
                        slam_metrics=self.metrics.slam_metrics_history,
                        epoch=epoch,
                        output_dir=str(self.output_dir / 'reports')
                    )

                    # ç”ŸæˆKendallæƒé‡åˆ†æå›¾
                    self.visualizer.plot_kendall_weight_evolution(
                        kendall_history=self.metrics.metrics_history['kendall_weights'],
                        save_path=str(self.output_dir / 'visualizations' / f'kendall_weights_epoch_{epoch}.png')
                    )

                except Exception as e:
                    warnings.warn(f"Epoch visualization failed: {e}")

            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            target_reached = ate <= self.target_ate and map_score >= self.target_map
            is_best = (ate < self.metrics.best_ate) or (map_score > self.metrics.best_map)

            # ä¿å­˜æ£€æŸ¥ç‚¹
            self.save_checkpoint(epoch, is_best)

            epoch_time = time.time() - epoch_start

            print(f"\nEpoch {epoch+1}/{self.max_epochs} ({epoch_time:.1f}s):")
            print(f"  Train Loss: {train_losses['total']:.6f} "
                  f"(pose={train_losses['pose']:.6f}, det={train_losses['detection']:.6f}, gate={train_losses['gate']:.6f})")
            print(f"  Val Metrics: Loss={val_loss:.6f}, ATE={ate:.3f}m, RPE={rpe:.3f}, mAP={map_score:.3f}")

            # æ˜¾ç¤ºä¿®å¤ç‰ˆKendallæƒé‡çŠ¶æ€
            kendall_weights = self.kendall_uncertainty.get_weights()
            print(f"  Kendall Weights: pose={kendall_weights['pose_weight']:.4f}, "
                  f"det={kendall_weights['detection_weight']:.4f}, gate={kendall_weights['gate_weight']:.4f}")

            # æ·»åŠ æƒé‡å¹³è¡¡ç›‘æ§
            balance_metrics = self.kendall_uncertainty.get_weight_balance_metrics()
            print(f"  Weight Balance: Score={balance_metrics['balance_score']:.3f}, "
                  f"MaxRatio={balance_metrics['max_ratio']:.1f}:1")

            # æ£€æŸ¥æƒé‡å¤±è¡¡è­¦å‘Š
            if balance_metrics['max_ratio'] > 50:
                print(f"  âš ï¸ Warning: Severe weight imbalance detected!")
                suggestions = self.kendall_uncertainty.get_optimization_suggestions()
                for suggestion in suggestions.values():
                    print(f"    - {suggestion}")

            # å®šæœŸè¯¦ç»†çŠ¶æ€æŠ¥å‘Š
            if epoch % 5 == 0:
                self.kendall_uncertainty.print_status(epoch)

            if target_reached:
                print(f"ğŸ¯ Target reached! ATE={ate:.3f}â‰¤{self.target_ate}, mAP={map_score:.3f}â‰¥{self.target_map}")

            # Early stoppingæ£€æŸ¥
            if self.metrics.should_early_stop(self.early_stop_patience, self.early_stop_min_delta):
                print(f"â¹ï¸ Early stopping triggered after {epoch+1} epochs")
                break

        # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡ï¼ˆä½¿ç”¨å¢å¼ºç‰ˆï¼‰
        metrics_path = self.metrics.save_enhanced_metrics()
        print(f"\nâœ… Training completed! Metrics saved to: {metrics_path}")
        print(f"Best results: ATE={self.metrics.best_ate:.3f}m, mAP={self.metrics.best_map:.3f}, "
              f"Val Loss={self.metrics.best_val_loss:.6f}")

        return {
            'best_ate': self.metrics.best_ate,
            'best_map': self.metrics.best_map,
            'best_val_loss': self.metrics.best_val_loss,
            'total_epochs': epoch + 1
        }


# è®­ç»ƒè„šæœ¬å…¥å£
def main():
    """ä¸»è®­ç»ƒè„šæœ¬"""
    # åŠ è½½é…ç½®
    config_path = 'configs/mineslam.yaml'
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Configuration file not found: {config_path}")

    config = load_config(config_path)

    # è®­ç»ƒå‚æ•°è¦†ç›–
    config.update({
        'batch_size': 4,
        'gradient_accumulation': 4,
        'max_epochs': 50,
        'learning_rate': 1e-4,
        'weight_decay': 1e-5,
        'use_amp': True,
        'early_stop_patience': 10,
        'warmup_steps': 1000,
        'target_ate': 1.5,
        'target_map': 0.6
    })

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MineSLAMTrainer(config, output_dir="outputs/training")

    # å¼€å§‹è®­ç»ƒ
    try:
        results = trainer.train()
        print(f"\nğŸ‰ Training finished successfully!")
        return True
    except Exception as e:
        print(f"\nâŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)