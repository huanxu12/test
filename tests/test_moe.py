#!/usr/bin/env python3
"""
MoE Transformer Unit Tests - REAL DATA ONLY
ä¸‰ä¸“å®¶MoEæµ‹è¯•ï¼šGeometric/Semantic/Visual Ã— 2å±‚Encoderï¼Œnhead=4
é—¨æ§ç»Ÿè®¡éªŒè¯ï¼Œçƒ­å¼•å¯¼æ³¨æ„åŠ›ï¼ŒçœŸå®æ ·æœ¬æ£€éªŒ
ä»val_indexå–å‰N=10æ‰¹çœŸå®æ ·æœ¬ï¼Œä¸¥ç¦éšæœºå¼ é‡/æ¨¡æ‹Ÿmask
"""

import os
import sys
import unittest
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import LinearSegmentedColormap
import json
import time

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils import load_config
from data.mineslam_dataset import MineSLAMDataset
from models.moe_fusion import MoEFusion, MoEConfig
from models.encoders import MultiModalEncoder


class MoETester:
    """MoEæµ‹è¯•å™¨"""
    
    def __init__(self, config: Dict, output_dir: str = "outputs/moe"):
        self.config = config
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {self.device}")
        
        # æµ‹è¯•å‚æ•°
        self.batch_size = 2
        self.num_batches = 10  # N=10æ‰¹æ¬¡
        self.sample_ids_log = []  # è®°å½•æ‰€ç”¨æ ·æœ¬ID
        
        # MoEé…ç½®
        self.moe_config = MoEConfig(
            embedding_dim=512,
            num_experts=3,  # Geometric, Semantic, Visual
            num_encoder_layers=2,  # 2å±‚Encoder
            nhead=4,  # 4å¤´æ³¨æ„åŠ›
            feedforward_dim=2048,
            dropout=0.1,
            gate_hidden_dim=256,
            thermal_guidance=True,
            gate_entropy_weight=0.01
        )
        
        # åˆ›å»ºç¼–ç å™¨å’ŒMoE
        self.encoder = MultiModalEncoder(embedding_dim=512)
        self.moe_fusion = MoEFusion(self.moe_config)
        
        self.encoder.to(self.device)
        self.moe_fusion.to(self.device)
        
        print(f"MoETester initialized: {self.num_batches} batches Ã— {self.batch_size} samples")
    
    def _validate_real_sample(self, sample: Dict, batch_idx: int, sample_idx: int):
        """éªŒè¯æ ·æœ¬æ¥è‡ªçœŸå®æ•°æ®ï¼Œä¸¥ç¦éšæœºå¼ é‡"""
        # æ£€æŸ¥åˆæˆæ•°æ®æ ‡è®°
        forbidden_keys = ['_generated', '_synthetic', '_random', '_mock', '_fake', '_simulated']
        for key in sample.keys():
            if any(forbidden in str(key).lower() for forbidden in forbidden_keys):
                raise ValueError(f"FORBIDDEN: Detected synthetic data marker in batch {batch_idx}, sample {sample_idx}: {key}")
        
        # éªŒè¯æ—¶é—´æˆ³çœŸå®æ€§
        if 'timestamp' in sample:
            timestamp = sample['timestamp'].item()
            if timestamp <= 0 or timestamp > 2e9:
                raise ValueError(f"Invalid timestamp in batch {batch_idx}: {timestamp}")
        
        # ä¸¥æ ¼æ£€æŸ¥å¼ é‡çœŸå®æ€§
        for key, value in sample.items():
            if isinstance(value, torch.Tensor):
                # æ£€æŸ¥æ˜¯å¦ä¸ºéšæœºç”Ÿæˆçš„å¼ é‡
                if value.numel() > 100:
                    # æ£€æŸ¥å€¼åˆ†å¸ƒï¼ˆçœŸå®æ•°æ®ä¸åº”è¯¥æ˜¯å®Œç¾æ­£æ€åˆ†å¸ƒï¼‰
                    mean_val = value.float().mean().item()
                    std_val = value.float().std().item()
                    
                    # çœŸå®ä¼ æ„Ÿå™¨æ•°æ®åº”è¯¥æœ‰åˆç†çš„èŒƒå›´
                    if key == 'rgb' and (mean_val < -2.0 or mean_val > 2.0):
                        warnings.warn(f"Suspicious RGB values in batch {batch_idx}: mean={mean_val}")
                    elif key == 'thermal' and std_val < 0.01:
                        raise ValueError(f"FORBIDDEN: Thermal data appears to be constant/simulated in batch {batch_idx}")
                    elif key == 'lidar' and torch.all(value == 0):
                        raise ValueError(f"FORBIDDEN: LiDAR data is all zeros (simulated) in batch {batch_idx}")
                
                # æ£€æŸ¥æ˜¯å¦å…¨ä¸ºç›¸åŒå€¼ï¼ˆå¯èƒ½çš„æ¨¡æ‹Ÿmaskï¼‰
                if torch.numel(value) > 10:
                    unique_count = len(torch.unique(value))
                    if unique_count == 1 and key not in ['boxes']:  # boxeså¯èƒ½å…¨ä¸º0
                        if 'mask' in key.lower():
                            raise ValueError(f"FORBIDDEN: Detected simulated mask '{key}' in batch {batch_idx}")
        
        # è®°å½•çœŸå®æ ·æœ¬ID
        sample_id = f"batch_{batch_idx}_sample_{sample_idx}_ts_{sample.get('timestamp', 0)}"
        self.sample_ids_log.append(sample_id)
    
    def _check_thermal_mask_validity(self, thermal_tokens: torch.Tensor, batch_idx: int):
        """æ£€æŸ¥çƒ­æˆåƒmaskçš„çœŸå®æ€§"""
        if thermal_tokens is None:
            raise ValueError(f"Missing thermal tokens in batch {batch_idx}")
        
        # æ£€æŸ¥thermal tokensä¸æ˜¯éšæœºç”Ÿæˆçš„
        mean_val = thermal_tokens.mean().item()
        std_val = thermal_tokens.std().item()
        
        if std_val < 1e-6:
            raise ValueError(f"FORBIDDEN: Thermal tokens appear constant/simulated in batch {batch_idx}")
        
        # æ£€æŸ¥å€¼èŒƒå›´åˆç†æ€§ï¼ˆå½’ä¸€åŒ–åçš„thermalæ•°æ®ï¼‰
        if torch.any(thermal_tokens < -5) or torch.any(thermal_tokens > 5):
            warnings.warn(f"Thermal tokens have extreme values in batch {batch_idx}")
    
    def _analyze_gate_weights(self, gate_weights: torch.Tensor, batch_idx: int) -> Dict[str, float]:
        """åˆ†æé—¨æ§æƒé‡ç»Ÿè®¡"""
        # gate_weights: [B, T, 3] - (Geometric, Semantic, Visual)
        batch_size, seq_len, num_experts = gate_weights.shape
        
        # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„å¹³å‡æƒé‡
        expert_weights = gate_weights.mean(dim=(0, 1))  # [3]
        
        expert_stats = {
            'geometric_weight': expert_weights[0].item(),
            'semantic_weight': expert_weights[1].item(), 
            'visual_weight': expert_weights[2].item()
        }
        
        # æ£€æŸ¥å•ä¸€ä¸“å®¶å ä¸»å¯¼ï¼ˆ>80%ï¼‰çš„æƒ…å†µ
        max_weight = max(expert_stats.values())
        dominant_expert = max(expert_stats, key=expert_stats.get)
        
        if max_weight > 0.8:
            print(f"âš ï¸  WARNING: Single expert dominance in batch {batch_idx}: {dominant_expert} = {max_weight:.3f}")
        
        expert_stats['max_weight'] = max_weight
        expert_stats['dominant_expert'] = dominant_expert
        expert_stats['batch_idx'] = batch_idx
        
        return expert_stats
    
    def _save_attention_heatmap(self, attention_weights: torch.Tensor, 
                               lidar_tokens: torch.Tensor, 
                               batch_idx: int, expert_name: str):
        """ä¿å­˜æ³¨æ„åŠ›çƒ­åŠ›å›¾å åŠ çœŸå®ç‚¹äº‘"""
        # attention_weights: [B, H, T, T] or [B, T, T]
        # lidar_tokens: [B, T_lidar, D]
        
        batch_size = attention_weights.shape[0]
        
        for b in range(batch_size):
            try:
                # æå–å•ä¸ªæ ·æœ¬çš„æ³¨æ„åŠ›æƒé‡
                if attention_weights.dim() == 4:
                    attn = attention_weights[b].mean(dim=0)  # å¹³å‡æ‰€æœ‰å¤´ [T, T]
                else:
                    attn = attention_weights[b]  # [T, T]
                
                # åˆ›å»ºçƒ­åŠ›å›¾
                plt.figure(figsize=(12, 8))
                
                # å·¦ä¾§ï¼šæ³¨æ„åŠ›çƒ­åŠ›å›¾
                plt.subplot(1, 2, 1)
                sns.heatmap(attn.detach().cpu().numpy(), 
                           cmap='hot', cbar=True, square=True)
                plt.title(f'{expert_name} Expert Attention\nBatch {batch_idx}, Sample {b}')
                plt.xlabel('Key Tokens')
                plt.ylabel('Query Tokens')
                
                # å³ä¾§ï¼šLiDARç‚¹äº‘å¯è§†åŒ–ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                plt.subplot(1, 2, 2)
                if lidar_tokens.shape[1] > 0:  # æœ‰LiDARæ•°æ®
                    # ç®€åŒ–çš„ç‚¹äº‘å¯è§†åŒ–ï¼ˆæŠ•å½±åˆ°2Dï¼‰
                    lidar_features = lidar_tokens[b, :, :3].detach().cpu().numpy()  # å–å‰3ç»´ä½œä¸ºåæ ‡
                    
                    plt.scatter(lidar_features[:, 0], lidar_features[:, 1], 
                              c=attn.diagonal().detach().cpu().numpy()[:len(lidar_features)], 
                              cmap='hot', alpha=0.7)
                    plt.colorbar(label='Attention Weight')
                    plt.title(f'LiDAR Points with Attention\nBatch {batch_idx}, Sample {b}')
                    plt.xlabel('X')
                    plt.ylabel('Y')
                else:
                    plt.text(0.5, 0.5, 'No LiDAR Data', ha='center', va='center')
                    plt.title('LiDAR Visualization')
                
                plt.tight_layout()
                
                # ä¿å­˜æ–‡ä»¶
                save_path = self.output_dir / f"attention_{expert_name}_batch{batch_idx}_sample{b}.png"
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                plt.close()
                
                print(f"âœ… Saved attention heatmap: {save_path}")
                
            except Exception as e:
                print(f"Warning: Failed to save attention heatmap for batch {batch_idx}, sample {b}: {e}")
    
    def test_moe_fusion(self, dataset: MineSLAMDataset) -> Dict[str, float]:
        """æµ‹è¯•MoEèåˆæ¨¡å—"""
        print(f"\nğŸ”€ Testing MoE Fusion on {self.num_batches} real batches...")
        
        self.encoder.eval()
        self.moe_fusion.eval()
        
        all_gate_stats = []
        total_samples = 0
        entropy_losses = []
        
        with torch.no_grad():
            for batch_idx in range(min(self.num_batches, len(dataset))):
                try:
                    # æ”¶é›†batchæ•°æ®
                    batch_data = []
                    
                    for sample_idx in range(self.batch_size):
                        data_idx = batch_idx * self.batch_size + sample_idx
                        if data_idx >= len(dataset):
                            break
                        
                        sample = dataset[data_idx]
                        self._validate_real_sample(sample, batch_idx, sample_idx)
                        batch_data.append(sample)
                    
                    if not batch_data:
                        continue
                    
                    # æ„å»ºè¾“å…¥æ•°æ®å­—å…¸
                    input_dict = {}
                    modalities = ['rgb', 'depth', 'thermal', 'lidar', 'imu']
                    
                    for modality in modalities:
                        modality_data = []
                        for sample in batch_data:
                            if modality in sample:
                                modality_data.append(sample[modality])
                        
                        if modality_data:
                            input_dict[modality] = torch.stack(modality_data).to(self.device)
                    
                    print(f"  Processing batch {batch_idx}: {len(batch_data)} samples")
                    print(f"    Available modalities: {list(input_dict.keys())}")
                    
                    # ç¼–ç å™¨å‰å‘ä¼ æ’­
                    token_dict = self.encoder(input_dict)
                    
                    # æ£€æŸ¥çƒ­æˆåƒçœŸå®æ€§
                    if 'thermal' in token_dict:
                        self._check_thermal_mask_validity(token_dict['thermal'], batch_idx)
                    
                    # MoEèåˆ
                    moe_result = self.moe_fusion(token_dict)
                    
                    # åˆ†æé—¨æ§æƒé‡
                    gate_weights = moe_result['gate_weights']  # [B, T, 3]
                    gate_stats = self._analyze_gate_weights(gate_weights, batch_idx)
                    all_gate_stats.append(gate_stats)
                    
                    # è®°å½•ç†µæŸå¤±
                    entropy_loss = moe_result['entropy_loss'].item()
                    entropy_losses.append(entropy_loss)
                    
                    # ä¿å­˜æ³¨æ„åŠ›çƒ­åŠ›å›¾ï¼ˆSemanticä¸“å®¶ï¼‰
                    if 'semantic' in self.moe_fusion.experts:
                        # è·å–Semanticä¸“å®¶çš„æ³¨æ„åŠ›æƒé‡
                        semantic_expert = self.moe_fusion.experts['semantic']
                        
                        # é‡æ–°å‰å‘è·å–æ³¨æ„åŠ›æƒé‡
                        if 'thermal' in token_dict:
                            fused_tokens = torch.cat([v for v in token_dict.values()], dim=1)
                            semantic_result = semantic_expert(fused_tokens, token_dict['thermal'])
                            attention_maps = semantic_result['attention_maps']
                            
                            if attention_maps:
                                self._save_attention_heatmap(
                                    attention_maps[-1],  # æœ€åä¸€å±‚çš„æ³¨æ„åŠ›
                                    token_dict.get('lidar', torch.empty(len(batch_data), 0, 512).to(self.device)),
                                    batch_idx, 'Semantic'
                                )
                    
                    total_samples += len(batch_data)
                    print(f"    Gate stats: G={gate_stats['geometric_weight']:.3f}, "
                          f"S={gate_stats['semantic_weight']:.3f}, V={gate_stats['visual_weight']:.3f}")
                    
                except Exception as e:
                    print(f"Warning: Skipping batch {batch_idx}: {e}")
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        if all_gate_stats:
            avg_geometric = np.mean([s['geometric_weight'] for s in all_gate_stats])
            avg_semantic = np.mean([s['semantic_weight'] for s in all_gate_stats])
            avg_visual = np.mean([s['visual_weight'] for s in all_gate_stats])
            
            # æ£€æŸ¥é•¿æœŸå•ä¸€ä¸“å®¶ä¸»å¯¼
            dominant_count = sum(1 for s in all_gate_stats if s['max_weight'] > 0.8)
            dominance_rate = dominant_count / len(all_gate_stats) if all_gate_stats else 0
            
            print(f"\nğŸ“Š Gate Weight Statistics (N={len(all_gate_stats)} batches):")
            print(f"    Average Geometric: {avg_geometric:.3f}")
            print(f"    Average Semantic:  {avg_semantic:.3f}")
            print(f"    Average Visual:    {avg_visual:.3f}")
            print(f"    Dominance Rate:    {dominance_rate:.3f} ({dominant_count}/{len(all_gate_stats)})")
            
            if dominance_rate > 0.5:
                print(f"âš ï¸  WARNING: High dominance rate {dominance_rate:.3f} - possible expert collapse")
            
            # ä¿å­˜æ ·æœ¬IDæ—¥å¿—
            sample_log_path = self.output_dir / "sample_ids_log.json"
            with open(sample_log_path, 'w') as f:
                json.dump({
                    'sample_ids': self.sample_ids_log,
                    'total_samples': total_samples,
                    'gate_statistics': all_gate_stats
                }, f, indent=2)
            
            print(f"âœ… Sample ID log saved: {sample_log_path}")
            
            metrics = {
                'total_samples': total_samples,
                'avg_geometric_weight': avg_geometric,
                'avg_semantic_weight': avg_semantic,
                'avg_visual_weight': avg_visual,
                'dominance_rate': dominance_rate,
                'avg_entropy_loss': np.mean(entropy_losses) if entropy_losses else 0,
                'num_batches': len(all_gate_stats)
            }
        else:
            raise ValueError("No valid batches processed")
        
        return metrics


class TestMoE(unittest.TestCase):
    """MoEå•å…ƒæµ‹è¯•"""
    
    @classmethod
    def setUpClass(cls):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        cls.config_path = 'configs/mineslam.yaml'
        cls.output_dir = "outputs/moe"
        
        # åŠ è½½é…ç½®
        if not os.path.exists(cls.config_path):
            raise unittest.SkipTest(f"Configuration file not found: {cls.config_path}")
        
        cls.config = load_config(cls.config_path)
        
        # æ£€æŸ¥éªŒè¯æ•°æ®ç´¢å¼•
        val_index_path = cls.config['data']['val_index']
        if not os.path.exists(val_index_path):
            raise unittest.SkipTest(f"Validation index not found: {val_index_path}")
        
        # åˆ›å»ºæµ‹è¯•å™¨
        cls.tester = MoETester(cls.config, cls.output_dir)
        
        print(f"Testing MoE on val_index with N=10 batches")
    
    def test_01_moe_architecture(self):
        """æµ‹è¯•MoEæ¶æ„"""
        print("\n" + "="*60)
        print("Testing MoE Architecture")
        print("="*60)
        
        # éªŒè¯é…ç½®
        config = self.tester.moe_config
        self.assertEqual(config.num_experts, 3, "Must have exactly 3 experts")
        self.assertEqual(config.num_encoder_layers, 2, "Must have 2 encoder layers")
        self.assertEqual(config.nhead, 4, "Must have 4 attention heads")
        self.assertTrue(config.thermal_guidance, "Must enable thermal guidance")
        
        # éªŒè¯ä¸“å®¶åç§°
        expert_names = list(self.tester.moe_fusion.experts.keys())
        expected_names = ['geometric', 'semantic', 'visual']
        self.assertEqual(set(expert_names), set(expected_names), 
                        f"Expert names mismatch: {expert_names} vs {expected_names}")
        
        print("âœ… MoE Architecture Test PASSED:")
        print(f"  Experts: {expert_names}")
        print(f"  Encoder layers: {config.num_encoder_layers}")
        print(f"  Attention heads: {config.nhead}")
        print(f"  Thermal guidance: {config.thermal_guidance}")
    
    def test_02_real_data_processing(self):
        """æµ‹è¯•çœŸå®æ•°æ®å¤„ç†"""
        print("\n" + "="*60)
        print("Testing Real Data Processing")
        print("="*60)
        
        # åˆ›å»ºéªŒè¯æ•°æ®é›†
        dataset = MineSLAMDataset(self.config, split='val')
        
        # æµ‹è¯•MoEèåˆ
        moe_metrics = self.tester.test_moe_fusion(dataset)
        
        # éªŒè¯å¤„ç†ç»“æœ
        self.assertGreater(moe_metrics['total_samples'], 0, "No samples processed")
        self.assertEqual(moe_metrics['num_batches'], min(10, len(dataset)), 
                        "Batch count mismatch")
        
        # éªŒè¯é—¨æ§æƒé‡åˆç†æ€§
        weight_sum = (moe_metrics['avg_geometric_weight'] + 
                     moe_metrics['avg_semantic_weight'] + 
                     moe_metrics['avg_visual_weight'])
        self.assertAlmostEqual(weight_sum, 1.0, places=2, 
                              msg="Gate weights should sum to 1.0")
        
        print(f"âœ… Real Data Processing Test PASSED:")
        print(f"  Total samples: {moe_metrics['total_samples']}")
        print(f"  Gate weight sum: {weight_sum:.3f}")
        print(f"  Entropy loss: {moe_metrics['avg_entropy_loss']:.6f}")
    
    def test_03_gate_weight_distribution(self):
        """æµ‹è¯•é—¨æ§æƒé‡åˆ†å¸ƒ"""
        print("\n" + "="*60)
        print("Testing Gate Weight Distribution")
        print("="*60)
        
        # åˆ›å»ºéªŒè¯æ•°æ®é›†
        dataset = MineSLAMDataset(self.config, split='val')
        
        # æµ‹è¯•MoEèåˆ
        moe_metrics = self.tester.test_moe_fusion(dataset)
        
        # éªŒè¯æ— å•ä¸€ä¸“å®¶é•¿æœŸä¸»å¯¼ï¼ˆ>80%ï¼‰
        dominance_rate = moe_metrics['dominance_rate']
        self.assertLess(dominance_rate, 0.8, 
                       f"Single expert dominance too high: {dominance_rate:.3f}")
        
        # éªŒè¯æ¯ä¸ªä¸“å®¶éƒ½æœ‰åˆç†çš„å‚ä¸åº¦
        min_weight = min(moe_metrics['avg_geometric_weight'],
                        moe_metrics['avg_semantic_weight'], 
                        moe_metrics['avg_visual_weight'])
        self.assertGreater(min_weight, 0.1, "At least one expert severely underused")
        
        print(f"âœ… Gate Weight Distribution Test PASSED:")
        print(f"  Dominance rate: {dominance_rate:.3f} (<0.8)")
        print(f"  Minimum expert weight: {min_weight:.3f} (>0.1)")
    
    def test_04_output_validation(self):
        """éªŒè¯è¾“å‡ºæ–‡ä»¶"""
        print("\n" + "="*60)
        print("Validating Output Files")
        print("="*60)
        
        output_dir = Path(self.tester.output_dir)
        
        # æ£€æŸ¥æ ·æœ¬IDæ—¥å¿—
        sample_log = output_dir / "sample_ids_log.json"
        self.assertTrue(sample_log.exists(), f"Sample ID log not found: {sample_log}")
        
        # æ£€æŸ¥æ³¨æ„åŠ›çƒ­åŠ›å›¾
        attention_files = list(output_dir.glob("attention_*.png"))
        self.assertGreater(len(attention_files), 0, "No attention heatmaps generated")
        
        # éªŒè¯æ ·æœ¬IDæ ¼å¼
        with open(sample_log) as f:
            log_data = json.load(f)
        
        self.assertIn('sample_ids', log_data, "Missing sample_ids in log")
        self.assertGreater(len(log_data['sample_ids']), 0, "No sample IDs recorded")
        
        print(f"âœ… Output Validation Test PASSED:")
        print(f"  Sample ID log: {sample_log}")
        print(f"  Attention heatmaps: {len(attention_files)} files")
        print(f"  Sample IDs logged: {len(log_data['sample_ids'])}")


def run_moe_tests():
    """è¿è¡ŒMoEæµ‹è¯•"""
    print("="*80)
    print("MINESLAM MoE TRANSFORMER TESTS - REAL DATA ONLY")
    print("="*80)
    print("Testing 3-Expert MoE (Geometric/Semantic/Visual) Ã— 2-layer Encoder")
    print("Thermal guidance, gate statistics, attention heatmaps on N=10 batches")
    print("Failure criteria: Random tensors/simulated masks detected")
    print()
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestLoader().loadTestsFromTestCase(TestMoE)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    print("\n" + "="*80)
    print("MoEæµ‹è¯•æ€»ç»“")
    print("="*80)
    
    if result.wasSuccessful():
        print("âœ… æ‰€æœ‰MoEæµ‹è¯•é€šè¿‡!")
        print("   - 3ä¸“å®¶æ¶æ„ Ã— 2å±‚Encoder Ã— 4å¤´æ³¨æ„åŠ›")
        print("   - é—¨æ§æƒé‡ç»Ÿè®¡æ­£å¸¸ï¼ˆæ— å•ä¸€ä¸“å®¶>80%ï¼‰")
        print("   - çƒ­å¼•å¯¼æ³¨æ„åŠ›æœ‰æ•ˆä½œç”¨äºSemanticä¸“å®¶")
        print("   - æ³¨æ„åŠ›çƒ­åŠ›å›¾å·²ä¿å­˜åˆ°outputs/moe/")
        print("   - æ ·æœ¬IDæ—¥å¿—è®°å½•å®Œæ•´")
        print("   - ä¸¥æ ¼éªŒè¯çœŸå®æ•°æ®ï¼Œæ— éšæœºå¼ é‡/æ¨¡æ‹Ÿmask")
    else:
        print("âŒ MoEæµ‹è¯•å¤±è´¥!")
        print(f"   å¤±è´¥: {len(result.failures)}")
        print(f"   é”™è¯¯: {len(result.errors)}")
        
        if result.failures:
            print("\nå¤±è´¥è¯¦æƒ…:")
            for test, traceback in result.failures:
                print(f"  - {test}")
        
        if result.errors:
            print("\né”™è¯¯è¯¦æƒ…:")
            for test, traceback in result.errors:
                print(f"  - {test}")
    
    print("="*80)
    
    return result.wasSuccessful()


if __name__ == '__main__':
    success = run_moe_tests()
    sys.exit(0 if success else 1)