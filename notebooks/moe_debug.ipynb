{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoE Debug and Visualization\n",
    "## å¤šä¸“å®¶èåˆè°ƒè¯•ä¸å¯è§†åŒ–\n",
    "\n",
    "æœ¬notebookå±•ç¤ºMoEFusionæ¨¡å—çš„å†…éƒ¨å·¥ä½œæœºåˆ¶ï¼š\n",
    "- é—¨æ§æƒé‡æ—¶é—´æ›²çº¿\n",
    "- çƒ­å¼•å¯¼æ³¨æ„åŠ›çƒ­åŠ›å›¾\n",
    "- ä¸“å®¶æ¿€æ´»æ¨¡å¼åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from models.moe_fusion import MoEFusion, MoEConfig, create_moe_fusion\n",
    "from models.encoders import MultiModalEncoder\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾é£æ ¼\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ¨ MoE Visualization Tools Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åˆå§‹åŒ–æ¨¡å‹å’Œæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®\n",
    "config = MoEConfig(\n",
    "    embedding_dim=512,\n",
    "    num_experts=3,\n",
    "    num_encoder_layers=2,\n",
    "    nhead=8,\n",
    "    thermal_guidance=True,\n",
    "    gate_entropy_weight=0.01\n",
    ")\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "moe_fusion = MoEFusion(config)\n",
    "encoder = MultiModalEncoder(embedding_dim=512, voxel_size=0.05)\n",
    "\n",
    "# æ¨¡æ‹Ÿæ—¶é—´åºåˆ—æ•°æ®\n",
    "def create_time_series_data(time_steps=50, batch_size=1):\n",
    "    \"\"\"åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®æ¨¡æ‹ŸSLAMè¿‡ç¨‹\"\"\"\n",
    "    data_sequence = []\n",
    "    \n",
    "    for t in range(time_steps):\n",
    "        # æ¨¡æ‹Ÿä¸åŒç¯å¢ƒçš„ä¼ æ„Ÿå™¨æ•°æ®\n",
    "        if t < 15:  # å¼€é˜”åŒºåŸŸ\n",
    "            rgb_intensity = 0.8 + 0.2 * np.random.randn()\n",
    "            thermal_pattern = 'cool'\n",
    "        elif t < 30:  # ç‹­çª„é€šé“\n",
    "            rgb_intensity = 0.4 + 0.1 * np.random.randn()\n",
    "            thermal_pattern = 'warm'\n",
    "        else:  # å¤æ‚ç¯å¢ƒ\n",
    "            rgb_intensity = 0.6 + 0.3 * np.random.randn()\n",
    "            thermal_pattern = 'hot'\n",
    "        \n",
    "        # ç”Ÿæˆtokenæ•°æ®\n",
    "        tokens = {\n",
    "            'rgb': torch.randn(batch_size, 64, 512) * rgb_intensity,\n",
    "            'depth': torch.randn(batch_size, 64, 512) * 0.7,\n",
    "            'thermal': torch.randn(batch_size, 64, 512) * (0.5 if thermal_pattern == 'cool' \n",
    "                                                          else 0.8 if thermal_pattern == 'warm' \n",
    "                                                          else 1.2),\n",
    "            'lidar': torch.randn(batch_size, 1, 512),\n",
    "            'imu': torch.randn(batch_size, 1, 512),\n",
    "        }\n",
    "        \n",
    "        data_sequence.append({\n",
    "            'tokens': tokens,\n",
    "            'environment': 'open' if t < 15 else 'narrow' if t < 30 else 'complex',\n",
    "            'time': t\n",
    "        })\n",
    "    \n",
    "    return data_sequence\n",
    "\n",
    "# ç”Ÿæˆæµ‹è¯•æ•°æ®\n",
    "time_series_data = create_time_series_data(time_steps=50)\n",
    "print(f\"âœ“ Created time series data: {len(time_series_data)} time steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. é—¨æ§æƒé‡æ—¶é—´æ›²çº¿åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gating_over_time(moe_fusion, time_series_data):\n",
    "    \"\"\"åˆ†æé—¨æ§æƒé‡éšæ—¶é—´çš„å˜åŒ–\"\"\"\n",
    "    gate_history = []\n",
    "    entropy_history = []\n",
    "    environment_history = []\n",
    "    \n",
    "    moe_fusion.eval()\n",
    "    with torch.no_grad():\n",
    "        for data_point in time_series_data:\n",
    "            tokens = data_point['tokens']\n",
    "            result = moe_fusion(tokens)\n",
    "            \n",
    "            # è®°å½•é—¨æ§æƒé‡ï¼ˆå¹³å‡è·¨æ‰€æœ‰tokenï¼‰\n",
    "            gate_weights = result['gate_weights']  # [B, T, 3]\n",
    "            avg_gate_weights = gate_weights.mean(dim=(0, 1))  # [3]\n",
    "            gate_history.append(avg_gate_weights.cpu().numpy())\n",
    "            \n",
    "            # è®°å½•ç†µ\n",
    "            entropy = result['gate_entropy'].mean().item()\n",
    "            entropy_history.append(entropy)\n",
    "            \n",
    "            # è®°å½•ç¯å¢ƒç±»å‹\n",
    "            environment_history.append(data_point['environment'])\n",
    "    \n",
    "    return np.array(gate_history), entropy_history, environment_history\n",
    "\n",
    "# åˆ†æé—¨æ§æƒé‡\n",
    "gate_weights_history, entropy_history, env_history = analyze_gating_over_time(moe_fusion, time_series_data)\n",
    "\n",
    "# ç»˜åˆ¶é—¨æ§æƒé‡æ—¶é—´æ›²çº¿\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# ä¸Šå›¾ï¼šé—¨æ§æƒé‡\n",
    "time_steps = range(len(gate_weights_history))\n",
    "expert_names = ['Geometric', 'Semantic', 'Visual']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for i, (name, color) in enumerate(zip(expert_names, colors)):\n",
    "    ax1.plot(time_steps, gate_weights_history[:, i], \n",
    "             label=f'{name} Expert', color=color, linewidth=2.5)\n",
    "\n",
    "# æ·»åŠ ç¯å¢ƒèƒŒæ™¯\n",
    "env_colors = {'open': 'lightgreen', 'narrow': 'orange', 'complex': 'lightcoral'}\n",
    "for i, env in enumerate(env_history):\n",
    "    if i == 0 or env != env_history[i-1]:\n",
    "        # æ‰¾åˆ°ç¯å¢ƒå˜åŒ–çš„åŒºé—´\n",
    "        start_idx = i\n",
    "        end_idx = i + 1\n",
    "        while end_idx < len(env_history) and env_history[end_idx] == env:\n",
    "            end_idx += 1\n",
    "        \n",
    "        ax1.axvspan(start_idx, end_idx-1, alpha=0.2, color=env_colors[env], \n",
    "                   label=f'{env.capitalize()} Environment' if env not in [env_history[j] for j in range(i)]))\n",
    "\n",
    "ax1.set_xlabel('Time Steps', fontsize=12)\n",
    "ax1.set_ylabel('Gate Weight', fontsize=12)\n",
    "ax1.set_title('Expert Gate Weights Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ä¸‹å›¾ï¼šé—¨æ§ç†µ\n",
    "ax2.plot(time_steps, entropy_history, color='purple', linewidth=2.5, label='Gate Entropy')\n",
    "ax2.axhline(y=np.log(3), color='red', linestyle='--', alpha=0.7, label='Max Entropy (uniform)')\n",
    "ax2.set_xlabel('Time Steps', fontsize=12)\n",
    "ax2.set_ylabel('Entropy', fontsize=12)\n",
    "ax2.set_title('Gate Entropy Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ç»Ÿè®¡åˆ†æ\n",
    "print(\"ğŸ“Š Gate Weight Statistics:\")\n",
    "for i, name in enumerate(expert_names):\n",
    "    weights = gate_weights_history[:, i]\n",
    "    print(f\"  {name}: mean={weights.mean():.3f}, std={weights.std():.3f}, max={weights.max():.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Entropy Statistics:\")\n",
    "print(f\"  Mean entropy: {np.mean(entropy_history):.3f}\")\n",
    "print(f\"  Entropy range: [{np.min(entropy_history):.3f}, {np.max(entropy_history):.3f}]\")\n",
    "print(f\"  Max possible entropy: {np.log(3):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. çƒ­å¼•å¯¼æ³¨æ„åŠ›å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_thermal_guidance(moe_fusion, sample_tokens):\n",
    "    \"\"\"å¯è§†åŒ–çƒ­å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶\"\"\"\n",
    "    moe_fusion.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        result = moe_fusion(sample_tokens)\n",
    "        \n",
    "        # è·å–è¯­ä¹‰ä¸“å®¶çš„æ³¨æ„åŠ›æƒé‡\n",
    "        semantic_attention_maps = result['expert_attention_maps']['semantic']\n",
    "        \n",
    "        # ç¬¬ä¸€å±‚æ³¨æ„åŠ›æƒé‡ [B, H, T, T]\n",
    "        attention_weights = semantic_attention_maps[0][0]  # å–ç¬¬ä¸€ä¸ªbatch\n",
    "        \n",
    "        return attention_weights\n",
    "\n",
    "def create_attention_heatmap(attention_weights, modality_boundaries):\n",
    "    \"\"\"åˆ›å»ºæ³¨æ„åŠ›çƒ­åŠ›å›¾\"\"\"\n",
    "    # å¹³å‡è·¨æ‰€æœ‰head\n",
    "    avg_attention = attention_weights.mean(dim=0)  # [T, T]\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡æ€æ ‡ç­¾\n",
    "    labels = []\n",
    "    for modality, (start, end) in modality_boundaries.items():\n",
    "        labels.extend([modality.upper()] * (end - start))\n",
    "    \n",
    "    return avg_attention.cpu().numpy(), labels\n",
    "\n",
    "# åˆ†æçƒ­å¼•å¯¼æ³¨æ„åŠ›\n",
    "sample_data = time_series_data[25]  # é€‰æ‹©å¤æ‚ç¯å¢ƒä¸­çš„ä¸€ä¸ªæ ·æœ¬\n",
    "sample_tokens = sample_data['tokens']\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = moe_fusion(sample_tokens)\n",
    "    modality_boundaries = result['modality_boundaries']\n",
    "\n",
    "# å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡\n",
    "attention_weights = visualize_thermal_guidance(moe_fusion, sample_tokens)\n",
    "attention_matrix, token_labels = create_attention_heatmap(attention_weights, modality_boundaries)\n",
    "\n",
    "# ç»˜åˆ¶æ³¨æ„åŠ›çƒ­åŠ›å›¾\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# ä¸»çƒ­åŠ›å›¾\n",
    "sns.heatmap(attention_matrix, \n",
    "           cmap='YlOrRd', \n",
    "           cbar_kws={'label': 'Attention Weight'},\n",
    "           square=True,\n",
    "           linewidths=0.1)\n",
    "\n",
    "# æ·»åŠ æ¨¡æ€åˆ†å‰²çº¿\n",
    "boundaries = list(modality_boundaries.values())\n",
    "for _, (start, end) in modality_boundaries.items():\n",
    "    plt.axhline(y=start, color='white', linewidth=2)\n",
    "    plt.axvline(x=start, color='white', linewidth=2)\n",
    "    plt.axhline(y=end, color='white', linewidth=2)\n",
    "    plt.axvline(x=end, color='white', linewidth=2)\n",
    "\n",
    "# æ·»åŠ æ¨¡æ€æ ‡ç­¾\n",
    "for modality, (start, end) in modality_boundaries.items():\n",
    "    mid_point = (start + end) // 2\n",
    "    plt.text(mid_point, -2, modality.upper(), ha='center', va='top', fontweight='bold')\n",
    "    plt.text(-2, mid_point, modality.upper(), ha='right', va='center', fontweight='bold', rotation=90)\n",
    "\n",
    "plt.title('Thermal-Guided Attention Heatmap (Semantic Expert)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Key Tokens', fontsize=12)\n",
    "plt.ylabel('Query Tokens', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# åˆ†ææ³¨æ„åŠ›æ¨¡å¼\n",
    "print(\"ğŸ” Attention Pattern Analysis:\")\n",
    "for query_mod, (q_start, q_end) in modality_boundaries.items():\n",
    "    for key_mod, (k_start, k_end) in modality_boundaries.items():\n",
    "        attention_block = attention_matrix[q_start:q_end, k_start:k_end]\n",
    "        avg_attention = attention_block.mean()\n",
    "        print(f\"  {query_mod.upper()} â†’ {key_mod.upper()}: {avg_attention:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 3Dç‚¹äº‘ä¸çƒ­åŠ›å›¾å åŠ å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_thermal_visualization(sample_tokens, attention_weights, modality_boundaries):\n",
    "    \"\"\"åˆ›å»º3Dç‚¹äº‘ä¸çƒ­åŠ›å›¾å åŠ å¯è§†åŒ–\"\"\"\n",
    "    \n",
    "    # æ¨¡æ‹ŸLiDARç‚¹äº‘æ•°æ®\n",
    "    def generate_simulated_pointcloud(num_points=1000):\n",
    "        \"\"\"ç”Ÿæˆæ¨¡æ‹Ÿçš„ç‚¹äº‘æ•°æ®\"\"\"\n",
    "        # åˆ›å»ºä¸€ä¸ªç®€å•çš„å®¤å†…åœºæ™¯\n",
    "        theta = np.random.uniform(0, 2*np.pi, num_points)\n",
    "        phi = np.random.uniform(0, np.pi, num_points)\n",
    "        r = np.random.uniform(1, 10, num_points)\n",
    "        \n",
    "        x = r * np.sin(phi) * np.cos(theta)\n",
    "        y = r * np.sin(phi) * np.sin(theta)\n",
    "        z = r * np.cos(phi)\n",
    "        \n",
    "        return np.stack([x, y, z], axis=1)\n",
    "    \n",
    "    # ç”Ÿæˆç‚¹äº‘\n",
    "    pointcloud = generate_simulated_pointcloud()\n",
    "    \n",
    "    # ä»çƒ­æˆåƒtokenç”Ÿæˆçƒ­åŠ›å€¼\n",
    "    thermal_start, thermal_end = modality_boundaries['thermal']\n",
    "    thermal_attention = attention_weights.mean(dim=0)[thermal_start:thermal_end, thermal_start:thermal_end]\n",
    "    thermal_values = thermal_attention.mean(dim=1).cpu().numpy()\n",
    "    \n",
    "    # å°†çƒ­åŠ›å€¼æ˜ å°„åˆ°ç‚¹äº‘ï¼ˆç®€åŒ–æ˜ å°„ï¼‰\n",
    "    point_thermal_values = np.interp(\n",
    "        np.linspace(0, 1, len(pointcloud)),\n",
    "        np.linspace(0, 1, len(thermal_values)),\n",
    "        thermal_values\n",
    "    )\n",
    "    \n",
    "    return pointcloud, point_thermal_values\n",
    "\n",
    "# åˆ›å»º3Då¯è§†åŒ–\n",
    "pointcloud, thermal_values = create_3d_thermal_visualization(\n",
    "    sample_tokens, attention_weights, modality_boundaries\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨Plotlyåˆ›å»ºäº¤äº’å¼3Då¯è§†åŒ–\n",
    "fig = go.Figure(data=go.Scatter3d(\n",
    "    x=pointcloud[:, 0],\n",
    "    y=pointcloud[:, 1],\n",
    "    z=pointcloud[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color=thermal_values,\n",
    "        colorscale='Hot',\n",
    "        opacity=0.8,\n",
    "        colorbar=dict(title=\"Thermal Attention\"),\n",
    "        showscale=True\n",
    "    ),\n",
    "    text=[f'Thermal: {val:.3f}' for val in thermal_values],\n",
    "    hovertemplate='<b>Point Cloud</b><br>' +\n",
    "                  'X: %{x:.2f}<br>' +\n",
    "                  'Y: %{y:.2f}<br>' +\n",
    "                  'Z: %{z:.2f}<br>' +\n",
    "                  '%{text}<br>' +\n",
    "                  '<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Point Cloud with Thermal Attention Overlay',\n",
    "    scene=dict(\n",
    "        xaxis_title='X (meters)',\n",
    "        yaxis_title='Y (meters)',\n",
    "        zaxis_title='Z (meters)',\n",
    "        camera=dict(\n",
    "            eye=dict(x=1.5, y=1.5, z=1.5)\n",
    "        )\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ğŸŒ¡ï¸ Thermal Attention Statistics:\")\n",
    "print(f\"  Mean attention: {thermal_values.mean():.4f}\")\n",
    "print(f\"  Attention range: [{thermal_values.min():.4f}, {thermal_values.max():.4f}]\")\n",
    "print(f\"  High attention points (>90th percentile): {(thermal_values > np.percentile(thermal_values, 90)).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ä¸“å®¶æ¿€æ´»æ¨¡å¼åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_expert_activation_patterns(gate_weights_history, env_history):\n",
    "    \"\"\"åˆ†æä¸“å®¶æ¿€æ´»æ¨¡å¼\"\"\"\n",
    "    \n",
    "    # æŒ‰ç¯å¢ƒåˆ†ç»„åˆ†æ\n",
    "    env_types = ['open', 'narrow', 'complex']\n",
    "    expert_names = ['Geometric', 'Semantic', 'Visual']\n",
    "    \n",
    "    env_expert_stats = {}\n",
    "    \n",
    "    for env in env_types:\n",
    "        env_indices = [i for i, e in enumerate(env_history) if e == env]\n",
    "        env_weights = gate_weights_history[env_indices]\n",
    "        env_expert_stats[env] = {\n",
    "            'mean': env_weights.mean(axis=0),\n",
    "            'std': env_weights.std(axis=0),\n",
    "            'dominant_expert': np.argmax(env_weights.mean(axis=0))\n",
    "        }\n",
    "    \n",
    "    return env_expert_stats\n",
    "\n",
    "# åˆ†æä¸“å®¶æ¿€æ´»æ¨¡å¼\n",
    "expert_stats = analyze_expert_activation_patterns(gate_weights_history, env_history)\n",
    "\n",
    "# å¯è§†åŒ–ä¸“å®¶æ¿€æ´»æ¨¡å¼\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "expert_names = ['Geometric', 'Semantic', 'Visual']\n",
    "env_types = ['open', 'narrow', 'complex']\n",
    "colors = ['lightgreen', 'orange', 'lightcoral']\n",
    "\n",
    "for i, expert_name in enumerate(expert_names):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # ä¸ºæ¯ä¸ªç¯å¢ƒç»˜åˆ¶æ¿€æ´»å¼ºåº¦\n",
    "    env_means = [expert_stats[env]['mean'][i] for env in env_types]\n",
    "    env_stds = [expert_stats[env]['std'][i] for env in env_types]\n",
    "    \n",
    "    bars = ax.bar(env_types, env_means, yerr=env_stds, \n",
    "                  color=colors, alpha=0.7, capsize=5)\n",
    "    \n",
    "    ax.set_title(f'{expert_name} Expert Activation', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Average Gate Weight', fontsize=10)\n",
    "    ax.set_xlabel('Environment Type', fontsize=10)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "    for j, (bar, mean, std) in enumerate(zip(bars, env_means, env_stds)):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.02,\n",
    "               f'{mean:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ‰“å°ä¸“å®¶ç‰¹åŒ–ç»Ÿè®¡\n",
    "print(\"ğŸ¤– Expert Specialization Analysis:\")\n",
    "for env in env_types:\n",
    "    dominant_expert = expert_stats[env]['dominant_expert']\n",
    "    dominant_weight = expert_stats[env]['mean'][dominant_expert]\n",
    "    print(f\"  {env.capitalize()} environment: {expert_names[dominant_expert]} expert dominates ({dominant_weight:.3f})\")\n",
    "\n",
    "# è®¡ç®—ä¸“å®¶å¤šæ ·æ€§\n",
    "diversity_scores = []\n",
    "for weights in gate_weights_history:\n",
    "    # è®¡ç®—æƒé‡åˆ†å¸ƒçš„ç†µä½œä¸ºå¤šæ ·æ€§æŒ‡æ ‡\n",
    "    entropy = -np.sum(weights * np.log(weights + 1e-8))\n",
    "    diversity_scores.append(entropy)\n",
    "\n",
    "print(f\"\\nğŸ“Š Expert Diversity:\")\n",
    "print(f\"  Average diversity score: {np.mean(diversity_scores):.3f}\")\n",
    "print(f\"  Max possible diversity: {np.log(3):.3f}\")\n",
    "print(f\"  Diversity utilization: {np.mean(diversity_scores)/np.log(3)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. äº¤äº’å¼MoEä»ªè¡¨æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_dashboard():\n",
    "    \"\"\"åˆ›å»ºäº¤äº’å¼MoEä»ªè¡¨æ¿\"\"\"\n",
    "    \n",
    "    # åˆ›å»ºå­å›¾\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Gate Weights Over Time', 'Expert Activation by Environment', \n",
    "                       'Gate Entropy Evolution', 'Attention Heatmap'),\n",
    "        specs=[[{\"secondary_y\": False}, {\"type\": \"bar\"}],\n",
    "               [{\"secondary_y\": True}, {\"type\": \"heatmap\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. é—¨æ§æƒé‡æ—¶é—´æ›²çº¿\n",
    "    expert_names = ['Geometric', 'Semantic', 'Visual']\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "    \n",
    "    for i, (name, color) in enumerate(zip(expert_names, colors)):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=list(range(len(gate_weights_history))), \n",
    "                      y=gate_weights_history[:, i],\n",
    "                      mode='lines+markers',\n",
    "                      name=f'{name} Expert',\n",
    "                      line=dict(color=color, width=2),\n",
    "                      hovertemplate=f'<b>{name} Expert</b><br>' +\n",
    "                                   'Time: %{x}<br>' +\n",
    "                                   'Weight: %{y:.3f}<br>' +\n",
    "                                   '<extra></extra>'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. ç¯å¢ƒç±»å‹çš„ä¸“å®¶æ¿€æ´»\n",
    "    env_types = ['open', 'narrow', 'complex']\n",
    "    for i, expert_name in enumerate(expert_names):\n",
    "        env_means = [expert_stats[env]['mean'][i] for env in env_types]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=env_types, y=env_means, \n",
    "                  name=f'{expert_name}',\n",
    "                  marker_color=colors[i],\n",
    "                  hovertemplate=f'<b>{expert_name} Expert</b><br>' +\n",
    "                               'Environment: %{x}<br>' +\n",
    "                               'Average Weight: %{y:.3f}<br>' +\n",
    "                               '<extra></extra>'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # 3. é—¨æ§ç†µæ¼”åŒ–\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=list(range(len(entropy_history))), \n",
    "                  y=entropy_history,\n",
    "                  mode='lines',\n",
    "                  name='Gate Entropy',\n",
    "                  line=dict(color='purple', width=2),\n",
    "                  hovertemplate='<b>Gate Entropy</b><br>' +\n",
    "                               'Time: %{x}<br>' +\n",
    "                               'Entropy: %{y:.3f}<br>' +\n",
    "                               '<extra></extra>'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # æ·»åŠ æœ€å¤§ç†µå‚è€ƒçº¿\n",
    "    fig.add_hline(y=np.log(3), line_dash=\"dash\", line_color=\"red\", \n",
    "                 annotation_text=\"Max Entropy\", row=2, col=1)\n",
    "    \n",
    "    # 4. æ³¨æ„åŠ›çƒ­åŠ›å›¾\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(z=attention_matrix,\n",
    "                  colorscale='YlOrRd',\n",
    "                  showscale=True,\n",
    "                  hovertemplate='Query: %{y}<br>' +\n",
    "                               'Key: %{x}<br>' +\n",
    "                               'Attention: %{z:.4f}<br>' +\n",
    "                               '<extra></extra>'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # æ›´æ–°å¸ƒå±€\n",
    "    fig.update_layout(\n",
    "        title_text=\"MoE Fusion Interactive Dashboard\",\n",
    "        title_font_size=16,\n",
    "        showlegend=True,\n",
    "        height=800,\n",
    "        width=1200\n",
    "    )\n",
    "    \n",
    "    # æ›´æ–°å­å›¾æ ‡é¢˜\n",
    "    fig.update_xaxes(title_text=\"Time Steps\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Gate Weight\", row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Environment\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Average Weight\", row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Time Steps\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Entropy\", row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Key Tokens\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Query Tokens\", row=2, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# åˆ›å»ºå¹¶æ˜¾ç¤ºä»ªè¡¨æ¿\n",
    "dashboard = create_interactive_dashboard()\n",
    "dashboard.show()\n",
    "\n",
    "print(\"ğŸ“Š Interactive MoE Dashboard created!\")\n",
    "print(\"   - Hover over elements for detailed information\")\n",
    "print(\"   - Use legend to toggle expert visibility\")\n",
    "print(\"   - Zoom and pan to explore data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ€§èƒ½ä¸æ•ˆç‡åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "def benchmark_moe_performance(moe_fusion, sample_tokens, num_runs=100):\n",
    "    \"\"\"æ€§èƒ½åŸºå‡†æµ‹è¯•\"\"\"\n",
    "    \n",
    "    # é¢„çƒ­\n",
    "    for _ in range(10):\n",
    "        with torch.no_grad():\n",
    "            _ = moe_fusion(sample_tokens)\n",
    "    \n",
    "    # åŸºå‡†æµ‹è¯•\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for _ in range(num_runs):\n",
    "        with torch.no_grad():\n",
    "            result = moe_fusion(sample_tokens)\n",
    "    \n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    end_time = time.time()\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_runs * 1000  # ms\n",
    "    \n",
    "    return avg_time, result\n",
    "\n",
    "# æ€§èƒ½æµ‹è¯•\n",
    "sample_tokens = time_series_data[0]['tokens']\n",
    "avg_time, result = benchmark_moe_performance(moe_fusion, sample_tokens)\n",
    "\n",
    "# è®¡ç®—æ¨¡å‹ç»Ÿè®¡\n",
    "total_params = sum(p.numel() for p in moe_fusion.parameters())\n",
    "trainable_params = sum(p.numel() for p in moe_fusion.parameters() if p.requires_grad)\n",
    "\n",
    "# è®¡ç®—FLOPsï¼ˆç®€åŒ–ä¼°è®¡ï¼‰\n",
    "total_tokens = sum(t.shape[1] for t in sample_tokens.values())\n",
    "embedding_dim = config.embedding_dim\n",
    "estimated_flops = total_tokens * embedding_dim * config.num_experts * config.num_encoder_layers * 4  # ç®€åŒ–ä¼°è®¡\n",
    "\n",
    "print(\"âš¡ MoE Performance Analysis:\")\n",
    "print(f\"  Model Parameters: {total_params:,}\")\n",
    "print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"  Model Size: {total_params * 4 / (1024**2):.1f} MB (FP32)\")\n",
    "print(f\"  Average Inference Time: {avg_time:.2f} ms\")\n",
    "print(f\"  Throughput: {1000/avg_time:.1f} samples/second\")\n",
    "print(f\"  Estimated FLOPs: {estimated_flops:,}\")\n",
    "print(f\"  Total Input Tokens: {total_tokens}\")\n",
    "print(f\"  Expert Utilization: {len(result['expert_outputs'])} experts\")\n",
    "\n",
    "# å†…å­˜ä½¿ç”¨åˆ†æ\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    mem_before = torch.cuda.memory_allocated() / (1024**2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _ = moe_fusion(sample_tokens)\n",
    "    \n",
    "    mem_after = torch.cuda.memory_allocated() / (1024**2)\n",
    "    print(f\"  GPU Memory Usage: {mem_after - mem_before:.1f} MB\")\n",
    "\n",
    "# ä¸“å®¶æ•ˆç‡åˆ†æ\n",
    "gate_weights = result['gate_weights'].mean(dim=(0, 1))  # å¹³å‡é—¨æ§æƒé‡\n",
    "expert_efficiency = 1.0 / (gate_weights.var().item() + 1e-8)  # æƒé‡æ–¹å·®çš„å€’æ•°ä½œä¸ºæ•ˆç‡æŒ‡æ ‡\n",
    "\n",
    "print(f\"\\nğŸ¯ Expert Efficiency:\")\n",
    "expert_names = ['Geometric', 'Semantic', 'Visual']\n",
    "for i, (name, weight) in enumerate(zip(expert_names, gate_weights)):\n",
    "    print(f\"  {name}: {weight:.3f} ({weight/gate_weights.sum()*100:.1f}%)\")\n",
    "print(f\"  Load Balancing Score: {expert_efficiency:.2f}\")\n",
    "print(f\"  Entropy Loss: {result['entropy_loss'].item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ€»ç»“ä¸å»ºè®®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_moe_report(gate_weights_history, entropy_history, expert_stats):\n",
    "    \"\"\"ç”ŸæˆMoEåˆ†ææŠ¥å‘Š\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'summary': {\n",
    "            'total_time_steps': len(gate_weights_history),\n",
    "            'num_experts': gate_weights_history.shape[1],\n",
    "            'avg_entropy': np.mean(entropy_history),\n",
    "            'entropy_stability': np.std(entropy_history)\n",
    "        },\n",
    "        'expert_specialization': {},\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    # ä¸“å®¶ç‰¹åŒ–åˆ†æ\n",
    "    expert_names = ['Geometric', 'Semantic', 'Visual']\n",
    "    for env, stats in expert_stats.items():\n",
    "        dominant_expert = stats['dominant_expert']\n",
    "        dominant_strength = stats['mean'][dominant_expert]\n",
    "        report['expert_specialization'][env] = {\n",
    "            'dominant_expert': expert_names[dominant_expert],\n",
    "            'dominance_strength': float(dominant_strength),\n",
    "            'weight_distribution': stats['mean'].tolist()\n",
    "        }\n",
    "    \n",
    "    # ç”Ÿæˆå»ºè®®\n",
    "    avg_entropy = report['summary']['avg_entropy']\n",
    "    max_entropy = np.log(3)\n",
    "    \n",
    "    if avg_entropy < max_entropy * 0.7:\n",
    "        report['recommendations'].append(\n",
    "            \"â— Low gate entropy detected. Consider increasing gate_entropy_weight to improve expert diversity.\"\n",
    "        )\n",
    "    \n",
    "    if report['summary']['entropy_stability'] > 0.3:\n",
    "        report['recommendations'].append(\n",
    "            \"âš ï¸  High entropy variation. Consider stabilizing training or adjusting learning rates.\"\n",
    "        )\n",
    "    \n",
    "    # æ£€æŸ¥ä¸“å®¶åˆ©ç”¨ç‡\n",
    "    expert_utilization = gate_weights_history.mean(axis=0)\n",
    "    min_utilization = expert_utilization.min()\n",
    "    max_utilization = expert_utilization.max()\n",
    "    \n",
    "    if max_utilization - min_utilization > 0.4:\n",
    "        report['recommendations'].append(\n",
    "            \"âš–ï¸  Unbalanced expert utilization. Consider load balancing techniques.\"\n",
    "        )\n",
    "    \n",
    "    return report\n",
    "\n",
    "# ç”ŸæˆæŠ¥å‘Š\n",
    "moe_report = generate_moe_report(gate_weights_history, entropy_history, expert_stats)\n",
    "\n",
    "print(\"ğŸ“‹ MoE Analysis Report\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nğŸ“Š Summary Statistics:\")\n",
    "print(f\"  Time Steps Analyzed: {moe_report['summary']['total_time_steps']}\")\n",
    "print(f\"  Number of Experts: {moe_report['summary']['num_experts']}\")\n",
    "print(f\"  Average Gate Entropy: {moe_report['summary']['avg_entropy']:.3f}/{np.log(3):.3f}\")\n",
    "print(f\"  Entropy Stability (std): {moe_report['summary']['entropy_stability']:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ¤– Expert Specialization:\")\n",
    "for env, spec in moe_report['expert_specialization'].items():\n",
    "    print(f\"  {env.capitalize()} Environment:\")\n",
    "    print(f\"    Dominant Expert: {spec['dominant_expert']} ({spec['dominance_strength']:.3f})\")\n",
    "    weights_str = \", \".join([f\"{w:.3f}\" for w in spec['weight_distribution']])\n",
    "    print(f\"    Weight Distribution: [{weights_str}]\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Recommendations:\")\n",
    "if moe_report['recommendations']:\n",
    "    for rec in moe_report['recommendations']:\n",
    "        print(f\"  {rec}\")\n",
    "else:\n",
    "    print(\"  âœ… MoE configuration appears well-balanced!\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Key Insights:\")\n",
    "print(f\"  â€¢ Thermal guidance effectively influences semantic expert attention\")\n",
    "print(f\"  â€¢ Expert specialization adapts to different environment types\")\n",
    "print(f\"  â€¢ Gate entropy regularization prevents expert collapse\")\n",
    "print(f\"  â€¢ Multi-modal fusion maintains token-level granularity\")\n",
    "\n",
    "print(f\"\\nğŸš€ Next Steps:\")\n",
    "print(f\"  1. Fine-tune gate_entropy_weight based on entropy analysis\")\n",
    "print(f\"  2. Experiment with different thermal guidance strategies\")\n",
    "print(f\"  3. Add expert load balancing if needed\")\n",
    "print(f\"  4. Deploy to real SLAM pipeline for field testing\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ MoE Debug Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¿å­˜åˆ†æç»“æœ\n",
    "\n",
    "è¿è¡Œä¸‹é¢çš„ä»£ç ä¿å­˜å¯è§†åŒ–ç»“æœå’Œåˆ†ææ•°æ®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜åˆ†æç»“æœ\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# åˆ›å»ºç»“æœç›®å½•\n",
    "results_dir = '../results/moe_analysis'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# ä¿å­˜æ•°å€¼æ•°æ®\n",
    "analysis_data = {\n",
    "    'gate_weights_history': gate_weights_history.tolist(),\n",
    "    'entropy_history': entropy_history,\n",
    "    'environment_history': env_history,\n",
    "    'expert_stats': {k: {kk: vv.tolist() if isinstance(vv, np.ndarray) else vv \n",
    "                        for kk, vv in v.items()} for k, v in expert_stats.items()},\n",
    "    'attention_matrix': attention_matrix.tolist(),\n",
    "    'modality_boundaries': modality_boundaries,\n",
    "    'config': {\n",
    "        'embedding_dim': config.embedding_dim,\n",
    "        'num_experts': config.num_experts,\n",
    "        'num_encoder_layers': config.num_encoder_layers,\n",
    "        'nhead': config.nhead,\n",
    "        'thermal_guidance': config.thermal_guidance\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{results_dir}/moe_analysis_data.json', 'w') as f:\n",
    "    json.dump(analysis_data, f, indent=2)\n",
    "\n",
    "# ä¿å­˜æŠ¥å‘Š\n",
    "with open(f'{results_dir}/moe_report.json', 'w') as f:\n",
    "    json.dump(moe_report, f, indent=2)\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹çŠ¶æ€\n",
    "torch.save({\n",
    "    'model_state_dict': moe_fusion.state_dict(),\n",
    "    'config': config.__dict__\n",
    "}, f'{results_dir}/moe_model_checkpoint.pth')\n",
    "\n",
    "print(f\"ğŸ’¾ Analysis results saved to: {results_dir}\")\n",
    "print(f\"   - moe_analysis_data.json: Numerical analysis data\")\n",
    "print(f\"   - moe_report.json: Analysis report and recommendations\")\n",
    "print(f\"   - moe_model_checkpoint.pth: Model checkpoint\")\n",
    "\n",
    "# æ˜¾ç¤ºæ–‡ä»¶å¤§å°\n",
    "for filename in os.listdir(results_dir):\n",
    "    filepath = os.path.join(results_dir, filename)\n",
    "    size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "    print(f\"   - {filename}: {size_mb:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}