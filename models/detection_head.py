"""
DetectionHead: DETR-style 3D Object Detection Head
DETRé£æ ¼3Dç›®æ ‡æ£€æµ‹å¤´ï¼šQ=20æŸ¥è¯¢ï¼ŒTransformerDecoderÃ—4ï¼Œè¾“å‡º(B,Q,10)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from typing import Dict, List, Optional, Tuple


class DetectionHead(nn.Module):
    """
    DETRé£æ ¼3Dç›®æ ‡æ£€æµ‹å¤´
    è¾“å…¥ï¼šå¤šæ¨¡æ€èåˆtoken [B, T, D]
    è¾“å‡ºï¼šæ£€æµ‹ç»“æœ [B, Q, 10] (Q=20æŸ¥è¯¢ï¼Œ10=ç±»åˆ«+3Dæ¡†)
    """

    def __init__(self,
                 input_dim: int = 512,
                 num_queries: int = 20,
                 num_classes: int = 8,  # åŸºäºDARPAæ ‡æ³¨ï¼šfiducial, extinguisher, phone, backpack, survivor, drillç­‰
                 decoder_layers: int = 4,
                 nhead: int = 8,
                 dropout: float = 0.1):
        super().__init__()
        self.input_dim = input_dim
        self.num_queries = num_queries
        self.num_classes = num_classes
        self.decoder_layers = decoder_layers

        # DETRæŸ¥è¯¢åµŒå…¥ - å¯å­¦ä¹ çš„Q=20ä¸ªæŸ¥è¯¢
        self.query_embeddings = nn.Parameter(
            torch.randn(num_queries, input_dim) * 0.1
        )

        # ä½ç½®ç¼–ç 
        self.position_embedding = nn.Parameter(
            torch.randn(1000, input_dim) * 0.1  # æ”¯æŒæœ€å¤š1000ä¸ªtoken
        )

        # TransformerDecoder Ã—4å±‚
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=input_dim,
            nhead=nhead,
            dim_feedforward=input_dim * 4,
            dropout=dropout,
            batch_first=True,
            activation='relu'
        )
        self.transformer_decoder = nn.TransformerDecoder(
            decoder_layer,
            num_layers=decoder_layers
        )

        # è¾“å‡ºå¤´
        # 3Dè¾¹ç•Œæ¡†ï¼šä¸­å¿ƒ(x,y,z) + å°ºå¯¸(w,h,l) = 6ç»´
        self.bbox_head = nn.Sequential(
            nn.Linear(input_dim, input_dim // 2),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout),
            nn.Linear(input_dim // 2, 6)  # 3D bbox: center(3) + size(3)
        )

        # åˆ†ç±»å¤´ï¼šnum_classes + 1 (èƒŒæ™¯ç±»)
        self.class_head = nn.Sequential(
            nn.Linear(input_dim, input_dim // 2),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout),
            nn.Linear(input_dim // 2, num_classes + 1)
        )

        # åˆå§‹åŒ–æƒé‡
        self._init_weights()

        print(f"DetectionHead initialized: Q={num_queries}, Classes={num_classes}, "
              f"Decoder={decoder_layers}Ã—{nhead}head â†’ (B,{num_queries},10)")

    def _init_weights(self):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡"""
        # æŸ¥è¯¢åµŒå…¥
        nn.init.normal_(self.query_embeddings, std=0.01)

        # ä½ç½®ç¼–ç 
        nn.init.normal_(self.position_embedding, std=0.01)

        # è¾“å‡ºå¤´
        for module in [self.bbox_head, self.class_head]:
            for layer in module:
                if isinstance(layer, nn.Linear):
                    nn.init.xavier_uniform_(layer.weight)
                    nn.init.zeros_(layer.bias)

        # bboxå¤´æœ€åä¸€å±‚ä½¿ç”¨å°çš„åˆå§‹åŒ–ï¼ˆDETRæƒ¯ä¾‹ï¼‰
        nn.init.xavier_uniform_(self.bbox_head[-1].weight, gain=0.01)

    def forward(self, tokens: torch.Tensor,
                token_mask: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­

        Args:
            tokens: [B, T, D] èåˆåçš„tokenåºåˆ—
            token_mask: [B, T] tokenæ©ç ï¼ˆå¯é€‰ï¼‰

        Returns:
            result_dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
                - 'logits': [B, Q, num_classes+1] åˆ†ç±»logits
                - 'boxes': [B, Q, 6] 3Dè¾¹ç•Œæ¡† [cx, cy, cz, w, h, l]
                - 'pred_combined': [B, Q, 10] ç»„åˆè¾“å‡ºï¼ˆå…¼å®¹è¦æ±‚ï¼‰
        """
        batch_size, seq_len, embed_dim = tokens.shape
        device = tokens.device

        # æ·»åŠ ä½ç½®ç¼–ç åˆ°memory tokens
        pos_embed = self.position_embedding[:seq_len].unsqueeze(0).expand(batch_size, -1, -1)
        memory = tokens + pos_embed

        # å‡†å¤‡æŸ¥è¯¢ï¼šå¤åˆ¶åˆ°batch
        queries = self.query_embeddings.unsqueeze(0).expand(batch_size, -1, -1)  # [B, Q, D]

        # å‡†å¤‡maskï¼ˆå¦‚æœéœ€è¦ï¼‰
        if token_mask is not None:
            # token_mask: [B, T] -> memory_key_padding_mask
            memory_key_padding_mask = ~token_mask  # åè½¬ï¼šTrueè¡¨ç¤ºpadding
        else:
            memory_key_padding_mask = None

        # TransformerDecoderå¤„ç†
        # queriesä½œä¸ºtgtï¼Œmemoryä½œä¸ºencoderè¾“å‡º
        decoder_output = self.transformer_decoder(
            tgt=queries,  # [B, Q, D]
            memory=memory,  # [B, T, D]
            memory_key_padding_mask=memory_key_padding_mask  # [B, T]
        )  # Output: [B, Q, D]

        # é¢„æµ‹åˆ†ç±»å’Œå›å½’
        class_logits = self.class_head(decoder_output)  # [B, Q, num_classes+1]
        bbox_preds = self.bbox_head(decoder_output)     # [B, Q, 6]

        # 3Dè¾¹ç•Œæ¡†åå¤„ç†ï¼šåº”ç”¨sigmoidçº¦æŸåˆ°åˆç†èŒƒå›´
        # centerå¯ä»¥åœ¨è¾ƒå¤§èŒƒå›´å†…ï¼Œsizeéœ€è¦ä¸ºæ­£å€¼
        bbox_centers = bbox_preds[:, :, :3]  # [B, Q, 3] ä¸­å¿ƒç‚¹
        bbox_sizes = torch.sigmoid(bbox_preds[:, :, 3:]) * 10.0  # [B, Q, 3] å°ºå¯¸ï¼Œæœ€å¤§10ç±³

        bbox_processed = torch.cat([bbox_centers, bbox_sizes], dim=-1)  # [B, Q, 6]

        # æ„å»ºç»„åˆè¾“å‡º [B, Q, 10] = [classes(1) + bbox(6) + confidence(1) + reserved(2)]
        # ä¸ºäº†å…¼å®¹(B, Q, 10)çš„è¦æ±‚ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°ç»„ç»‡è¾“å‡º
        pred_classes = torch.argmax(class_logits, dim=-1, keepdim=True).float()  # [B, Q, 1]
        pred_confidence = torch.max(F.softmax(class_logits, dim=-1), dim=-1, keepdim=True)[0]  # [B, Q, 1]
        reserved_dims = torch.zeros(batch_size, self.num_queries, 2, device=device)  # [B, Q, 2]

        pred_combined = torch.cat([
            pred_classes,      # [B, Q, 1] é¢„æµ‹ç±»åˆ«
            bbox_processed,    # [B, Q, 6] 3Dè¾¹ç•Œæ¡†
            pred_confidence,   # [B, Q, 1] ç½®ä¿¡åº¦
            reserved_dims      # [B, Q, 2] ä¿ç•™ç»´åº¦
        ], dim=-1)  # [B, Q, 10]

        return {
            'logits': class_logits,        # [B, Q, num_classes+1] ç”¨äºæŸå¤±è®¡ç®—
            'boxes': bbox_processed,       # [B, Q, 6] ç”¨äºæŸå¤±è®¡ç®—
            'pred_combined': pred_combined, # [B, Q, 10] ç¬¦åˆæ¥å£è¦æ±‚
            'decoder_features': decoder_output  # [B, Q, D] è§£ç å™¨ç‰¹å¾ï¼ˆå¯ç”¨äºå¯è§†åŒ–ï¼‰
        }

    def compute_loss(self, predictions: Dict[str, torch.Tensor],
                     targets: List[Dict[str, torch.Tensor]],
                     matcher_indices: List[Tuple[torch.Tensor, torch.Tensor]]) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—æ£€æµ‹æŸå¤±ï¼ˆéœ€è¦ä¸matcher.pyé…åˆä½¿ç”¨ï¼‰

        Args:
            predictions: æ¨¡å‹é¢„æµ‹ç»“æœå­—å…¸
            targets: çœŸå®æ ‡æ³¨åˆ—è¡¨
            matcher_indices: åŒˆç‰™åˆ©åŒ¹é…ç»“æœ

        Returns:
            loss_dict: æŸå¤±å­—å…¸
        """
        pred_logits = predictions['logits']  # [B, Q, num_classes+1]
        pred_boxes = predictions['boxes']    # [B, Q, 6]

        batch_size = pred_logits.shape[0]
        device = pred_logits.device

        # å‡†å¤‡åŒ¹é…åçš„ç›®æ ‡
        target_classes_list = []
        target_boxes_list = []

        for i, (indices_i, target_i) in enumerate(zip(matcher_indices, targets)):
            if indices_i is None or target_i is None:
                # æ— æ ‡æ³¨å¸§ï¼šå…¨éƒ¨è§†ä¸ºèƒŒæ™¯
                target_classes_list.append(
                    torch.full((self.num_queries,), self.num_classes,
                             dtype=torch.long, device=device)
                )
                target_boxes_list.append(
                    torch.zeros((self.num_queries, 6), device=device)
                )
            else:
                pred_idx, target_idx = indices_i

                # æ„å»ºåŒ¹é…åçš„ç›®æ ‡ç±»åˆ«
                target_classes = torch.full((self.num_queries,), self.num_classes,
                                           dtype=torch.long, device=device)
                target_classes[pred_idx] = target_i['labels'][target_idx]
                target_classes_list.append(target_classes)

                # æ„å»ºåŒ¹é…åçš„ç›®æ ‡æ¡†
                target_boxes = torch.zeros((self.num_queries, 6), device=device)
                if len(pred_idx) > 0:
                    target_boxes[pred_idx] = target_i['boxes'][target_idx]
                target_boxes_list.append(target_boxes)

        # å †å ç›®æ ‡
        target_classes = torch.stack(target_classes_list)  # [B, Q]
        target_boxes = torch.stack(target_boxes_list)      # [B, Q, 6]

        # åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
        loss_class = F.cross_entropy(
            pred_logits.reshape(-1, pred_logits.shape[-1]),
            target_classes.reshape(-1)
        )

        # å›å½’æŸå¤±ï¼ˆä»…å¯¹éèƒŒæ™¯ç±»è®¡ç®—ï¼‰
        # ç­›é€‰å‡ºéèƒŒæ™¯çš„é¢„æµ‹å’Œç›®æ ‡
        foreground_mask = (target_classes != self.num_classes)

        if foreground_mask.sum() > 0:
            # L1æŸå¤±
            loss_bbox = F.l1_loss(
                pred_boxes[foreground_mask],
                target_boxes[foreground_mask]
            )

            # IoUæŸå¤±ï¼ˆ3Dæƒ…å†µä¸‹ä½¿ç”¨ä¸­å¿ƒè·ç¦»ä½œä¸ºä»£ç†ï¼‰
            pred_centers = pred_boxes[foreground_mask][:, :3]
            target_centers = target_boxes[foreground_mask][:, :3]
            loss_center = F.mse_loss(pred_centers, target_centers)
        else:
            loss_bbox = torch.tensor(0.0, device=device)
            loss_center = torch.tensor(0.0, device=device)

        return {
            'loss_class': loss_class,
            'loss_bbox': loss_bbox,
            'loss_center': loss_center,
            'loss_det': loss_class + loss_bbox + loss_center  # æ€»æ£€æµ‹æŸå¤±
        }


# 3Dè¾¹ç•Œæ¡†å·¥å…·å‡½æ•°
class BBox3DUtils:
    """3Dè¾¹ç•Œæ¡†å·¥å…·å‡½æ•°"""

    @staticmethod
    def center_size_to_corners(boxes: torch.Tensor) -> torch.Tensor:
        """
        å°†ä¸­å¿ƒ-å°ºå¯¸æ ¼å¼è½¬æ¢ä¸ºè§’ç‚¹æ ¼å¼

        Args:
            boxes: [N, 6] [cx, cy, cz, w, h, l]

        Returns:
            corners: [N, 8, 3] 8ä¸ªè§’ç‚¹åæ ‡
        """
        centers = boxes[:, :3]  # [N, 3]
        sizes = boxes[:, 3:]    # [N, 3]

        # åŠå°ºå¯¸
        half_sizes = sizes / 2  # [N, 3]

        # 8ä¸ªè§’ç‚¹çš„åç§»
        offsets = torch.tensor([
            [-1, -1, -1], [1, -1, -1], [1, 1, -1], [-1, 1, -1],
            [-1, -1, 1],  [1, -1, 1],  [1, 1, 1],  [-1, 1, 1]
        ], dtype=boxes.dtype, device=boxes.device)  # [8, 3]

        # å¹¿æ’­è®¡ç®—è§’ç‚¹
        corners = centers.unsqueeze(1) + offsets.unsqueeze(0) * half_sizes.unsqueeze(1)

        return corners

    @staticmethod
    def compute_3d_iou(boxes1: torch.Tensor, boxes2: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—3Dè¾¹ç•Œæ¡†IoUï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰

        Args:
            boxes1: [N, 6] ç¬¬ä¸€ç»„æ¡†
            boxes2: [M, 6] ç¬¬äºŒç»„æ¡†

        Returns:
            iou: [N, M] IoUçŸ©é˜µ
        """
        # ç®€åŒ–å®ç°ï¼šä½¿ç”¨ä¸­å¿ƒè·ç¦»çš„å€’æ•°ä½œä¸ºIoUçš„ä»£ç†
        centers1 = boxes1[:, :3]  # [N, 3]
        centers2 = boxes2[:, :3]  # [M, 3]

        # è®¡ç®—ä¸­å¿ƒè·ç¦»
        distances = torch.cdist(centers1, centers2)  # [N, M]

        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
        iou_proxy = 1.0 / (1.0 + distances)

        return iou_proxy


# æ¨¡å—æµ‹è¯•
if __name__ == '__main__':
    print("ğŸ§ª Testing DetectionHead...")

    # åˆ›å»ºDetectionHead
    detection_head = DetectionHead(
        input_dim=512,
        num_queries=20,
        num_classes=8,
        decoder_layers=4
    )

    # æµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 100
    embed_dim = 512

    tokens = torch.randn(batch_size, seq_len, embed_dim)
    token_mask = torch.ones(batch_size, seq_len, dtype=torch.bool)

    print(f"Input tokens shape: {tokens.shape}")
    print(f"Token mask shape: {token_mask.shape}")

    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        predictions = detection_head(tokens, token_mask)

        print(f"\nPrediction shapes:")
        for key, value in predictions.items():
            print(f"  {key}: {value.shape}")

        print(f"\nCombined output shape: {predictions['pred_combined'].shape}")
        print(f"Expected shape: (B={batch_size}, Q=20, 10)")
        assert predictions['pred_combined'].shape == (batch_size, 20, 10)

    # æµ‹è¯•æ¢¯åº¦
    print("\nğŸ”„ Testing gradients...")
    predictions_grad = detection_head(tokens, token_mask)

    # æ¨¡æ‹ŸæŸå¤±
    dummy_loss = predictions_grad['pred_combined'].sum()
    dummy_loss.backward()

    # æ£€æŸ¥æ¢¯åº¦
    grad_norm = torch.norm(torch.cat([
        p.grad.flatten() for p in detection_head.parameters()
        if p.grad is not None
    ]))
    print(f"Gradient norm: {grad_norm.item():.6f}")

    # æµ‹è¯•3Då·¥å…·å‡½æ•°
    print("\nğŸ”§ Testing 3D BBox utilities...")
    test_boxes = torch.tensor([[0, 0, 0, 2, 2, 2], [1, 1, 1, 1, 1, 1]])
    corners = BBox3DUtils.center_size_to_corners(test_boxes)
    print(f"Corners shape: {corners.shape}")

    iou_matrix = BBox3DUtils.compute_3d_iou(test_boxes, test_boxes)
    print(f"IoU matrix shape: {iou_matrix.shape}")
    print(f"IoU matrix:\n{iou_matrix}")

    print("\nâœ… DetectionHead test completed!")