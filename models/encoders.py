"""
Multi-modal Encoders for MineSLAM
å¤šæ¨¡æ€ç¼–ç å™¨ï¼šRGB/Depth/Thermal/LiDAR/IMU â†’ ç»Ÿä¸€512ç»´token
æ”¯æŒçµæ´»çš„é¢„è®­ç»ƒ/ä»é›¶è®­ç»ƒåˆ‡æ¢ç­–ç•¥
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
from typing import Dict, List, Tuple, Optional
import warnings

# å°è¯•å¯¼å…¥EfficientNet
try:
    from efficientnet_pytorch import EfficientNet
    EFFICIENTNET_AVAILABLE = True
except ImportError:
    EFFICIENTNET_AVAILABLE = False
    warnings.warn("EfficientNet not available, using ResNet backbone")

# å°è¯•å¯¼å…¥MinkowskiEngine
try:
    import MinkowskiEngine as ME
    MINKOWSKI_AVAILABLE = True
except ImportError:
    MINKOWSKI_AVAILABLE = False
    warnings.warn("MinkowskiEngine not available, using stub MLP for LiDAR")


# è®­ç»ƒç­–ç•¥é…ç½®
class TrainingStrategy:
    """è®­ç»ƒç­–ç•¥é…ç½®ç±»"""
    
    @staticmethod
    def get_strategy_from_env() -> Dict[str, bool]:
        """ä»ç¯å¢ƒå˜é‡è·å–è®­ç»ƒç­–ç•¥"""
        return {
            'rgb_pretrained': not bool(os.getenv('MINESLAM_NO_PRETRAINED', False)),
            'depth_pretrained': bool(os.getenv('MINESLAM_DEPTH_PRETRAINED', False)),
            'thermal_pretrained': bool(os.getenv('MINESLAM_THERMAL_PRETRAINED', False)),
            'force_scratch': bool(os.getenv('MINESLAM_FORCE_SCRATCH', False))
        }
    
    @staticmethod
    def print_strategy(strategy: Dict[str, bool]):
        """æ‰“å°å½“å‰è®­ç»ƒç­–ç•¥"""
        print("ğŸ¯ Training Strategy:")
        print(f"  RGB: {'Pretrained' if strategy['rgb_pretrained'] else 'From Scratch'}")
        print(f"  Depth: {'Pretrained' if strategy['depth_pretrained'] else 'From Scratch'}")
        print(f"  Thermal: {'Pretrained' if strategy['thermal_pretrained'] else 'From Scratch'}")
        if strategy['force_scratch']:
            print("  âš ï¸  FORCE_SCRATCH enabled - all modalities train from scratch")


class ImageEncoder(nn.Module):
    """
    å›¾åƒç¼–ç å™¨ï¼šRGB/Depth/Thermal â†’ ç»Ÿä¸€token
    ä½¿ç”¨EfficientNet-B0æå–å¤šå°ºåº¦ç‰¹å¾ï¼Œè¾“å‡º(B, T_img, 512)
    æ”¯æŒçµæ´»çš„é¢„è®­ç»ƒ/ä»é›¶è®­ç»ƒç­–ç•¥
    """
    
    def __init__(self, in_channels: int = 3, embedding_dim: int = 512, 
                 use_pretrained: Optional[bool] = None, modality: str = 'rgb'):
        super().__init__()
        self.in_channels = in_channels
        self.embedding_dim = embedding_dim
        self.modality = modality
        
        # è·å–è®­ç»ƒç­–ç•¥
        strategy = TrainingStrategy.get_strategy_from_env()
        
        # å†³å®šæ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        if use_pretrained is None:
            # è‡ªåŠ¨ç­–ç•¥ï¼šæ ¹æ®æ¨¡æ€å’Œç¯å¢ƒå˜é‡å†³å®š
            if strategy['force_scratch']:
                use_pretrained = False
            elif modality == 'rgb':
                use_pretrained = strategy['rgb_pretrained']
            elif modality == 'depth':
                use_pretrained = strategy['depth_pretrained']
            elif modality == 'thermal':
                use_pretrained = strategy['thermal_pretrained']
            else:
                use_pretrained = False
        
        self.use_pretrained = use_pretrained
        
        # åˆå§‹åŒ–backbone
        if EFFICIENTNET_AVAILABLE:
            self._init_efficientnet_backbone()
        else:
            self._init_simple_backbone()
        
        # å¤šå°ºåº¦ç‰¹å¾èåˆ
        if EFFICIENTNET_AVAILABLE and hasattr(self, 'backbone') and hasattr(self.backbone, '_blocks'):
            # EfficientNet-B0çš„ç‰¹å¾ç»´åº¦ (ä¿®å¤: æ ¹æ®å®é™…blockè¾“å‡ºç»´åº¦)
            self.feature_dims = [40, 112, 320]  # å¯¹åº”idx=4,10,15çš„è¾“å‡ºç»´åº¦
        else:
            # ç®€åŒ–backboneçš„ç‰¹å¾ç»´åº¦
            self.feature_dims = [64, 128, 256]
            
        self.scale_convs = nn.ModuleList([
            nn.Conv2d(dim, embedding_dim, kernel_size=1, bias=False)
            for dim in self.feature_dims
        ])
        
        # æ‰¹å½’ä¸€åŒ–
        self.scale_norms = nn.ModuleList([
            nn.BatchNorm2d(embedding_dim) for _ in self.feature_dims
        ])
        
        # è‡ªé€‚åº”æ± åŒ–åˆ°å›ºå®šå¤§å°
        self.adaptive_pools = nn.ModuleList([
            nn.AdaptiveAvgPool2d((8, 8)) for _ in self.feature_dims
        ])
        
        # æœ€ç»ˆçš„tokenæ•°é‡ï¼š3ä¸ªå°ºåº¦ Ã— 8Ã—8 = 192ä¸ªtoken
        self.num_tokens = len(self.feature_dims) * 8 * 8
        
        # æ‰“å°åˆå§‹åŒ–ä¿¡æ¯
        pretrained_status = "âœ… Pretrained" if self.use_pretrained else "ğŸ†• From Scratch"
        print(f"{self.modality.upper()} ImageEncoder: {in_channels}ch â†’ {self.num_tokens} tokens Ã— {embedding_dim}D ({pretrained_status})")
    
    def _init_efficientnet_backbone(self):
        """åˆå§‹åŒ–EfficientNet backboneï¼ˆæ”¯æŒç¦»çº¿æ¨¡å¼ï¼‰"""
        try:
            if self.use_pretrained and self.in_channels == 3:
                # ä½¿ç”¨ImageNeté¢„è®­ç»ƒæƒé‡ï¼ˆä»…RGBï¼‰
                print(f"ğŸ“¥ Loading ImageNet pretrained EfficientNet-B0 for {self.modality}")
                self.backbone = EfficientNet.from_pretrained('efficientnet-b0')
                # ç§»é™¤åˆ†ç±»å¤´
                self.backbone._fc = nn.Identity()
            else:
                # ä»é›¶å¼€å§‹è®­ç»ƒ - åªåˆ›å»ºæ¶æ„ï¼Œä¸ä¸‹è½½æƒé‡
                if self.use_pretrained and self.in_channels != 3:
                    print(f"âš ï¸  Cannot use ImageNet pretrained weights for {self.in_channels}-channel input, using scratch")
                print(f"ğŸ†• Creating EfficientNet-B0 from scratch for {self.modality}")
                
                # å°è¯•æœ¬åœ°åˆ›å»ºæ¶æ„ï¼ˆé¿å…ç½‘ç»œä¸‹è½½ï¼‰
                try:
                    # æ–¹æ³•1ï¼šç›´æ¥åˆ›å»ºæ¶æ„ï¼Œä¸é€šè¿‡from_name
                    from efficientnet_pytorch.model import EfficientNet
                    from efficientnet_pytorch.utils import get_model_params
                    
                    # è·å–EfficientNet-B0å‚æ•°
                    blocks_args, global_params = get_model_params('efficientnet-b0', override_params={'num_classes': 1000})
                    self.backbone = EfficientNet(blocks_args, global_params)
                    
                except Exception as e1:
                    print(f"âš ï¸  Direct architecture creation failed: {e1}")
                    try:
                        # æ–¹æ³•2ï¼šä½¿ç”¨from_nameï¼ˆå¯èƒ½è§¦å‘ä¸‹è½½ï¼‰
                        self.backbone = EfficientNet.from_name('efficientnet-b0')
                    except Exception as e2:
                        print(f"âš ï¸  from_name also failed: {e2}")
                        raise e2
                
                # ä¿®æ”¹ç¬¬ä¸€å±‚ä»¥é€‚åº”ä¸åŒé€šé“æ•°
                if self.in_channels != 3:
                    self.backbone._conv_stem = nn.Conv2d(
                        self.in_channels, 32, kernel_size=3, stride=2, padding=1, bias=False
                    )
                # ç§»é™¤åˆ†ç±»å¤´
                self.backbone._fc = nn.Identity()
                
        except Exception as e:
            print(f"âš ï¸  EfficientNet initialization failed: {e}")
            print(f"ğŸ”„ Falling back to simple backbone for {self.modality}")
            self._init_simple_backbone()
    
    def _init_simple_backbone(self):
        """åˆå§‹åŒ–ç®€åŒ–backboneï¼ˆfallbacké€‰é¡¹ï¼‰"""
        print(f"ğŸ”§ Using simple ResNet-like backbone for {self.modality} ({self.in_channels} channels)")
        self.backbone = self._create_simple_backbone(self.in_channels)
    
    def _create_simple_backbone(self, in_channels: int) -> nn.Module:
        """åˆ›å»ºç®€åŒ–çš„backboneï¼ˆå½“EfficientNetä¸å¯ç”¨æ—¶ï¼‰"""
        return nn.Sequential(
            # Stage 1
            nn.Conv2d(in_channels, 32, 7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2, padding=1),
            
            # Stage 2 
            nn.Conv2d(32, 64, 3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            
            # Stage 3
            nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            
            # Stage 4
            nn.Conv2d(128, 256, 3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
        )
    
    def extract_multiscale_features(self, x: torch.Tensor) -> List[torch.Tensor]:
        """æå–EfficientNet-B0ç¬¬2/3/4å°ºåº¦ç‰¹å¾"""
        if EFFICIENTNET_AVAILABLE and hasattr(self.backbone, '_blocks'):
            # EfficientNetè·¯å¾„ - ä½¿ç”¨EfficientNetç‰¹å¾æå–
            x = self.backbone._conv_stem(x)
            x = self.backbone._bn0(x)
            x = self.backbone._swish(x)
            
            stage_features = []
            
            # éå†å„ä¸ªMBConv blockï¼Œæå–ç¬¬2/3/4å°ºåº¦
            for idx, block in enumerate(self.backbone._blocks):
                x = block(x)
                
                # EfficientNet-B0çš„ç²¾ç¡®å°ºåº¦åˆ’åˆ†ï¼š
                # Stage 1: blocks 0-1 (stem->16)
                # Stage 2: blocks 2-4 (24->40) â† ç¬¬2å°ºåº¦ï¼Œè¾“å‡º40é€šé“
                # Stage 3: blocks 5-10 (40->112) â† ç¬¬3å°ºåº¦ï¼Œè¾“å‡º112é€šé“
                # Stage 4: blocks 11-15 (112->320) â† ç¬¬4å°ºåº¦ï¼Œè¾“å‡º320é€šé“
                if idx == 4:  # ç¬¬2å°ºåº¦ç»“æŸ
                    stage_features.append(x)
                elif idx == 10:  # ç¬¬3å°ºåº¦ç»“æŸ
                    stage_features.append(x)
                elif idx == 15:  # ç¬¬4å°ºåº¦ç»“æŸ
                    stage_features.append(x)
            
            return stage_features
            
        else:
            # ç®€åŒ–backboneè·¯å¾„ - å¯¹åº”stage 2/3/4
            features = []
            x = self.backbone[:4](x)  # Stage 1
            
            x = self.backbone[4:6](x)  # Stage 2
            features.append(x)
            
            x = self.backbone[6:8](x)  # Stage 3
            features.append(x)
            
            x = self.backbone[8:](x)   # Stage 4
            features.append(x)
            
            return features
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥å›¾åƒ [B, C, H, W]
            
        Returns:
            tokens: [B, T_img, D] å…¶ä¸­T_img=192, D=512
        """
        batch_size = x.shape[0]
        
        # æå–å¤šå°ºåº¦ç‰¹å¾
        multiscale_features = self.extract_multiscale_features(x)
        
        # å¤„ç†æ¯ä¸ªå°ºåº¦çš„ç‰¹å¾
        scale_tokens = []
        for i, features in enumerate(multiscale_features):
            # 1x1å·ç§¯é™ç»´åˆ°embedding_dim
            features = self.scale_convs[i](features)
            features = self.scale_norms[i](features)
            features = F.relu(features, inplace=True)
            
            # è‡ªé€‚åº”æ± åŒ–åˆ°8x8
            features = self.adaptive_pools[i](features)  # [B, D, 8, 8]
            
            # å±•å¹³ä¸ºtokenåºåˆ—
            tokens = features.flatten(2).transpose(1, 2)  # [B, 64, D]
            scale_tokens.append(tokens)
        
        # æ‹¼æ¥æ‰€æœ‰å°ºåº¦çš„token
        all_tokens = torch.cat(scale_tokens, dim=1)  # [B, 192, D]
        
        return all_tokens


class LidarEncoder(nn.Module):
    """
    LiDARç‚¹äº‘ç¼–ç å™¨
    å¿…é¡»ä½¿ç”¨MinkowskiUNet14ï¼Œä¸å¯ç”¨æ—¶ç›´æ¥æŠ¥é”™
    """
    
    def __init__(self, embedding_dim: int = 512, voxel_size: float = 0.05):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.voxel_size = voxel_size
        
        if not MINKOWSKI_AVAILABLE:
            raise RuntimeError("MinkowskiEngine is required for LidarEncoder but not available. "
                             "Please install MinkowskiEngine: pip install MinkowskiEngine")
        
        self._init_minkowski_encoder()
        print(f"LidarEncoder initialized: MinkowskiUNet14 â†’ {embedding_dim}D")
    
    def _init_minkowski_encoder(self):
        """åˆå§‹åŒ–MinkowskiUNet14ç¼–ç å™¨"""
        try:
            # æ£€æŸ¥å¯ç”¨çš„MinkowskiEngine API
            available_nets = []
            
            if hasattr(ME, 'MinkUNet14'):
                available_nets.append('MinkUNet14')
                self.unet = ME.MinkUNet14(
                    in_channels=1,
                    out_channels=self.embedding_dim,
                    D=3
                )
            elif hasattr(ME, 'MinkowskiUNet14'):
                available_nets.append('MinkowskiUNet14')
                self.unet = ME.MinkowskiUNet14(
                    in_channels=1,
                    out_channels=self.embedding_dim,
                    D=3
                )
            elif hasattr(ME, 'MinkowskiUNet'):
                available_nets.append('MinkowskiUNet')
                # æ–°ç‰ˆæœ¬API - å°è¯•åˆ›å»ºUNet14ç­‰æ•ˆç»“æ„
                self.unet = ME.MinkowskiUNet(
                    in_nchannel=1,
                    out_nchannel=self.embedding_dim,
                    D=3
                )
            else:
                # å¦‚æœæ²¡æœ‰é¢„å®šä¹‰çš„UNetï¼Œåˆ›å»ºè‡ªå®šä¹‰14å±‚ç»“æ„
                print("âš ï¸  Creating custom 14-layer sparse UNet")
                self.unet = self._create_custom_unet14()
                available_nets.append('Custom14Layer')
            
            # å…¨å±€å¹³å‡æ± åŒ–
            if hasattr(ME, 'MinkowskiGlobalAvgPooling'):
                self.global_pool = ME.MinkowskiGlobalAvgPooling()
            else:
                # é™çº§åˆ°æ™®é€šæ± åŒ–
                self.global_pool = ME.MinkowskiAvgPooling(kernel_size=2, stride=2, dimension=3)
            
            # è¾“å‡ºtokenæ•°é‡
            self.num_tokens = 1
            
            print(f"âœ… MinkowskiEngine encoder initialized: {available_nets[0]}")
            
        except Exception as e:
            print(f"MinkowskiEngine available APIs: {[attr for attr in dir(ME) if 'UNet' in attr]}")
            raise RuntimeError(f"Failed to initialize MinkowskiUNet14: {e}")
    
    def _create_custom_unet14(self):
        """åˆ›å»ºè‡ªå®šä¹‰14å±‚UNetç»“æ„"""
        # 14å±‚UNetçš„ç®€åŒ–å®ç°
        layers = []
        
        # Encoderéƒ¨åˆ†
        in_channels = 1
        base_channels = 32
        
        for i, out_channels in enumerate([32, 64, 128, 256, 512]):
            layers.extend([
                ME.MinkowskiConvolution(in_channels, out_channels, kernel_size=3, stride=1 if i == 0 else 2, dimension=3),
                ME.MinkowskiBatchNorm(out_channels),
                ME.MinkowskiReLU(inplace=True),
                ME.MinkowskiConvolution(out_channels, out_channels, kernel_size=3, dimension=3),
                ME.MinkowskiBatchNorm(out_channels),
                ME.MinkowskiReLU(inplace=True)
            ])
            in_channels = out_channels
        
        # è¾“å‡ºå±‚
        layers.extend([
            ME.MinkowskiConvolution(512, self.embedding_dim, kernel_size=1, dimension=3),
            ME.MinkowskiBatchNorm(self.embedding_dim),
            ME.MinkowskiReLU(inplace=True)
        ])
        
        return nn.Sequential(*layers)
    
    def voxelize_pointcloud(self, points: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ä½“ç´ åŒ–ç‚¹äº‘
        
        Args:
            points: [B, N, 4] ç‚¹äº‘æ•°æ® [x,y,z,intensity]
            
        Returns:
            coords: [M, 4] ä½“ç´ åæ ‡ [batch_idx, x, y, z]
            features: [M, 1] ä½“ç´ ç‰¹å¾
        """
        batch_size = points.shape[0]
        
        all_coords = []
        all_features = []
        
        for b in range(batch_size):
            pts = points[b]  # [N, 4]
            
            # è¿‡æ»¤æ— æ•ˆç‚¹
            valid_mask = torch.all(pts[:, :3] != 0, dim=1)
            if valid_mask.sum() == 0:
                continue
                
            pts = pts[valid_mask]
            
            # ä½“ç´ åŒ–
            coords = pts[:, :3] / self.voxel_size
            coords = coords.round().int()  # ä¿®å¤ï¼šæ˜¾å¼è½¬æ¢ä¸ºintç±»å‹

            # æ·»åŠ batchç´¢å¼•
            batch_coords = torch.full((coords.shape[0], 1), b,
                                    dtype=torch.int32, device=coords.device)  # ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šint32ç±»å‹
            coords = torch.cat([batch_coords, coords], dim=1)  # ç°åœ¨coordsæ˜¯intç±»å‹
            
            # ä½¿ç”¨å¼ºåº¦ä½œä¸ºç‰¹å¾
            features = pts[:, 3:4]  # [N, 1]
            
            all_coords.append(coords)
            all_features.append(features)
        
        if len(all_coords) == 0:
            # æ²¡æœ‰æœ‰æ•ˆç‚¹ï¼Œè¿”å›ç©ºå¼ é‡
            empty_coords = torch.zeros((0, 4), dtype=torch.long, device=points.device)
            empty_features = torch.zeros((0, 1), dtype=torch.float32, device=points.device)
            return empty_coords, empty_features
        
        coords = torch.cat(all_coords, dim=0)
        features = torch.cat(all_features, dim=0)
        
        return coords, features
    
    def forward(self, points: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            points: [B, N, 4] ç‚¹äº‘æ•°æ® [x,y,z,intensity]
            
        Returns:
            tokens: [B, T_lidar, D] å…¶ä¸­T_lidar=1, D=512
        """
        batch_size = points.shape[0]
        
        # ä½“ç´ åŒ–ç‚¹äº‘
        coords, features = self.voxelize_pointcloud(points)
        
        if coords.shape[0] == 0:
            # æ²¡æœ‰æœ‰æ•ˆç‚¹ï¼Œè¿”å›é›¶å‘é‡
            return torch.zeros(batch_size, self.num_tokens, self.embedding_dim, 
                             device=points.device)
        
        # åˆ›å»ºç¨€ç–å¼ é‡
        sparse_tensor = ME.SparseTensor(features, coords)
        
        # UNetç¼–ç 
        encoded = self.unet(sparse_tensor)
        
        # å…¨å±€æ± åŒ–
        pooled = self.global_pool(encoded)
        
        # é‡ç»„ä¸ºbatchæ ¼å¼
        output_features = pooled.F  # [B, D]
        tokens = output_features.unsqueeze(1)  # [B, 1, D]
        
        return tokens


class IMUEncoder(nn.Module):
    """
    IMUç¼–ç å™¨ï¼šæ—¶åºIMUæ•°æ® â†’ å•ä¸ªtoken
    ä½¿ç”¨2å±‚LSTM + LinearæŠ•å½±
    """
    
    def __init__(self, input_dim: int = 6, hidden_dim: int = 256, embedding_dim: int = 512):
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.embedding_dim = embedding_dim
        
        # 2å±‚LSTM
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True,
            dropout=0.1,
            bidirectional=False
        )
        
        # æŠ•å½±åˆ°embeddingç»´åº¦
        self.projection = nn.Linear(hidden_dim, embedding_dim)
        
        # è¾“å‡ºtokenæ•°é‡
        self.num_tokens = 1
        
        print(f"IMUEncoder initialized: {input_dim}D Ã— T=20 â†’ 1 token Ã— {embedding_dim}D")
    
    def forward(self, imu_sequence: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            imu_sequence: [B, T, 6] IMUæ—¶åºæ•°æ® [ax,ay,az,gx,gy,gz]
            
        Returns:
            tokens: [B, 1, D] å…¶ä¸­D=512
        """
        batch_size = imu_sequence.shape[0]
        
        # LSTMç¼–ç 
        lstm_out, (hidden, cell) = self.lstm(imu_sequence)
        
        # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        last_output = lstm_out[:, -1, :]  # [B, hidden_dim]
        
        # æŠ•å½±åˆ°embeddingç»´åº¦
        tokens = self.projection(last_output)  # [B, embedding_dim]
        tokens = tokens.unsqueeze(1)  # [B, 1, embedding_dim]
        
        return tokens


class MultiModalEncoder(nn.Module):
    """
    å¤šæ¨¡æ€ç¼–ç å™¨é›†åˆ
    ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ¨¡æ€çš„ç¼–ç å™¨
    æ”¯æŒçµæ´»çš„é¢„è®­ç»ƒ/ä»é›¶è®­ç»ƒç­–ç•¥
    """
    
    def __init__(self, embedding_dim: int = 512, voxel_size: float = 0.05, 
                 training_strategy: Optional[Dict[str, bool]] = None):
        super().__init__()
        self.embedding_dim = embedding_dim
        
        # è·å–è®­ç»ƒç­–ç•¥
        if training_strategy is None:
            training_strategy = TrainingStrategy.get_strategy_from_env()
        
        # æ‰“å°è®­ç»ƒç­–ç•¥
        TrainingStrategy.print_strategy(training_strategy)
        
        print(f"\nğŸ”§ Initializing MultiModalEncoder (embedding_dim={embedding_dim})...")
        
        # å„æ¨¡æ€ç¼–ç å™¨ï¼ˆä¼ å…¥æ¨¡æ€åç§°ä»¥ä¾¿æ™ºèƒ½å†³å®šé¢„è®­ç»ƒç­–ç•¥ï¼‰
        self.rgb_encoder = ImageEncoder(
            in_channels=3, 
            embedding_dim=embedding_dim, 
            modality='rgb'
        )
        
        self.depth_encoder = ImageEncoder(
            in_channels=1, 
            embedding_dim=embedding_dim, 
            modality='depth'
        )
        
        self.thermal_encoder = ImageEncoder(
            in_channels=1, 
            embedding_dim=embedding_dim, 
            modality='thermal'
        )
        
        self.lidar_encoder = LidarEncoder(
            embedding_dim=embedding_dim, 
            voxel_size=voxel_size
        )
        
        self.imu_encoder = IMUEncoder(embedding_dim=embedding_dim)
        
        # ç»Ÿè®¡tokenæ•°é‡
        self.token_counts = {
            'rgb': self.rgb_encoder.num_tokens,
            'depth': self.depth_encoder.num_tokens,
            'thermal': self.thermal_encoder.num_tokens,
            'lidar': self.lidar_encoder.num_tokens,
            'imu': self.imu_encoder.num_tokens,
        }
        
        print(f"\nğŸ“Š MultiModalEncoder Summary:")
        print(f"  Token counts: {self.token_counts}")
        print(f"  Total tokens: {sum(self.token_counts.values())}")
        print(f"  Memory efficient: {self._estimate_memory_usage():.1f} MB")
    
    def _estimate_memory_usage(self) -> float:
        """ä¼°ç®—æ¨¡å‹å†…å­˜ä½¿ç”¨é‡"""
        total_params = sum(p.numel() for p in self.parameters())
        return total_params * 4 / (1024 ** 2)  # FP32
    
    def forward(self, data_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­ï¼Œæ”¯æŒè·¯çº¿Bæ©ç å¤„ç†

        Args:
            data_dict: åŒ…å«å„æ¨¡æ€æ•°æ®å’Œæ©ç çš„å­—å…¸
                - 'rgb': [B, 3, H, W]
                - 'depth': [B, 1, H, W]
                - 'thermal': [B, 1, H, W]
                - 'lidar': [B, P, 4]  # P=16384 å›ºå®šé•¿åº¦
                - 'imu': [B, T, 6]
                - 'present_mask': {'rgb': [B], 'thermal': [B], 'lidar': [B], ...}

        Returns:
            token_dict: åŒ…å«å„æ¨¡æ€tokençš„å­—å…¸
                - 'rgb': [B, T_rgb, D]
                - 'depth': [B, T_depth, D]
                - 'thermal': [B, T_thermal, D]
                - 'lidar': [B, T_lidar, D]
                - 'imu': [B, T_imu, D]
        """
        token_dict = {}
        present_mask = data_dict.get('present_mask', {})

        if 'rgb' in data_dict:
            mask = present_mask.get('rgb', None)
            token_dict['rgb'] = self._forward_with_mask(
                self.rgb_encoder, data_dict['rgb'], mask
            )

        if 'depth' in data_dict:
            mask = present_mask.get('depth', None)
            token_dict['depth'] = self._forward_with_mask(
                self.depth_encoder, data_dict['depth'], mask
            )

        if 'thermal' in data_dict:
            mask = present_mask.get('thermal', None)
            token_dict['thermal'] = self._forward_with_mask(
                self.thermal_encoder, data_dict['thermal'], mask
            )

        if 'lidar' in data_dict:
            mask = present_mask.get('lidar', None)
            token_dict['lidar'] = self._forward_lidar_with_mask(
                data_dict['lidar'], mask
            )

        if 'imu' in data_dict:
            mask = present_mask.get('imu', None)
            token_dict['imu'] = self._forward_with_mask(
                self.imu_encoder, data_dict['imu'], mask
            )

        return token_dict

    def _forward_with_mask(self, encoder: nn.Module, x: torch.Tensor,
                          mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        å¸¦æ©ç çš„å‰å‘ä¼ æ’­ï¼ˆé€šç”¨å›¾åƒå’ŒIMUç¼–ç å™¨ï¼‰

        Args:
            encoder: ç¼–ç å™¨æ¨¡å—
            x: è¾“å…¥æ•°æ® [B, ...]
            mask: æ©ç  [B]ï¼ŒTrueè¡¨ç¤ºçœŸå®æ•°æ®ï¼ŒFalseè¡¨ç¤ºå¡«å……

        Returns:
            tokens: [B, T, D] ç¼–ç åçš„tokenï¼Œå¡«å……æ ·æœ¬ä¸ºé›¶å‘é‡
        """
        batch_size = x.shape[0]

        if mask is None:
            # æ²¡æœ‰æ©ç ï¼Œæ­£å¸¸å¤„ç†
            return encoder(x)

        # æ­£å¸¸ç¼–ç 
        tokens = encoder(x)  # [B, T, D]

        # åº”ç”¨æ©ç ï¼šå¡«å……æ ·æœ¬ç½®é›¶
        mask_expanded = mask.view(batch_size, 1, 1)  # [B, 1, 1]
        tokens = tokens * mask_expanded.float()  # å¹¿æ’­ä¹˜æ³•ï¼Œå¡«å……æ ·æœ¬å˜ä¸ºé›¶å‘é‡

        return tokens

    def _forward_lidar_with_mask(self, points: torch.Tensor,
                                mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        LiDARç¼–ç å™¨çš„æ©ç å‰å‘ä¼ æ’­

        Args:
            points: [B, P, 4] ç‚¹äº‘æ•°æ®ï¼ˆå¯èƒ½åŒ…å«å¡«å……çš„é›¶ç‚¹äº‘ï¼‰
            mask: [B] å¸ƒå°”æ©ç ï¼ŒTrueè¡¨ç¤ºçœŸå®æ•°æ®ï¼ŒFalseè¡¨ç¤ºå¡«å……

        Returns:
            tokens: [B, 1, D] ç¼–ç åçš„token
        """
        batch_size = points.shape[0]

        if mask is None:
            # æ²¡æœ‰æ©ç ï¼Œæ­£å¸¸å¤„ç†
            return self.lidar_encoder(points)

        # å¤„ç†æ¯ä¸ªæ ·æœ¬
        output_tokens = []
        for i in range(batch_size):
            if mask[i]:
                # çœŸå®æ•°æ®ï¼šæ­£å¸¸å¤„ç†
                sample_points = points[i:i+1]  # [1, P, 4]
                coords, features = self.lidar_encoder.voxelize_pointcloud(sample_points)

                if coords.shape[0] > 0:
                    sparse_tensor = ME.SparseTensor(features, coords)
                    encoded = self.lidar_encoder.unet(sparse_tensor)
                    pooled = self.lidar_encoder.global_pool(encoded)
                    token = pooled.F.unsqueeze(1)  # [1, 1, D]
                else:
                    token = torch.zeros(1, 1, self.embedding_dim, device=points.device)
            else:
                # å¡«å……æ•°æ®ï¼šè¾“å‡ºé›¶å‘é‡
                token = torch.zeros(1, 1, self.embedding_dim, device=points.device)

            output_tokens.append(token)

        return torch.cat(output_tokens, dim=0)  # [B, 1, D]
    
    def get_total_tokens(self, available_modalities: List[str]) -> int:
        """è·å–ç»™å®šæ¨¡æ€çš„æ€»tokenæ•°é‡"""
        return sum(self.token_counts[mod] for mod in available_modalities 
                  if mod in self.token_counts)