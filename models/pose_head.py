"""
PoseHead: Multi-task Pose Estimation Head
å¤šä»»åŠ¡å§¿æ€ä¼°è®¡å¤´ï¼šmean-pool â†’ MLP â†’ SE(3) å¢é‡
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional, Tuple


class PoseHead(nn.Module):
    """
    å§¿æ€ä¼°è®¡å¤´
    è¾“å…¥ï¼šå¤šæ¨¡æ€èåˆtoken [B, T, D]
    è¾“å‡ºï¼šSE(3) 6DOF å¢é‡ [B, 6] (translation + rotation)
    """
    
    def __init__(self, 
                 input_dim: int = 512,
                 hidden_dims: list = [512, 256, 128],
                 dropout_rate: float = 0.1):
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dims = hidden_dims
        
        # å…¨å±€å¹³å‡æ± åŒ–ï¼ˆmean-poolæ‰€æœ‰tokenï¼‰
        self.global_pool = nn.AdaptiveAvgPool1d(1)
        
        # MLP layers
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate)
            ])
            prev_dim = hidden_dim
        
        # è¾“å‡ºå±‚ï¼š6DOF pose (3 translation + 3 rotation)
        layers.append(nn.Linear(prev_dim, 6))
        
        self.mlp = nn.Sequential(*layers)
        
        # åˆå§‹åŒ–æœ€åä¸€å±‚æƒé‡ä¸ºå°å€¼
        nn.init.xavier_uniform_(self.mlp[-1].weight, gain=0.01)
        nn.init.zeros_(self.mlp[-1].bias)
        
        print(f"PoseHead initialized: {input_dim} â†’ {hidden_dims} â†’ 6DOF")
    
    def forward(self, tokens: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            tokens: [B, T, D] èåˆåçš„tokenåºåˆ—
            
        Returns:
            pose_delta: [B, 6] SE(3) å¢é‡ [tx, ty, tz, rx, ry, rz]
        """
        batch_size, seq_len, embed_dim = tokens.shape
        
        # å…¨å±€å¹³å‡æ± åŒ–: [B, T, D] â†’ [B, D]
        # è½¬ç½®åˆ° [B, D, T] è¿›è¡Œæ± åŒ–
        pooled = self.global_pool(tokens.transpose(1, 2))  # [B, D, 1]
        pooled = pooled.squeeze(-1)  # [B, D]
        
        # MLPé¢„æµ‹6DOFå¢é‡
        pose_delta = self.mlp(pooled)  # [B, 6]
        
        return pose_delta
    
    def compute_loss(self, 
                     pred_pose: torch.Tensor, 
                     target_pose: torch.Tensor,
                     delta: float = 1.0) -> torch.Tensor:
        """
        è®¡ç®—HuberæŸå¤±
        
        Args:
            pred_pose: [B, 6] é¢„æµ‹çš„poseå¢é‡
            target_pose: [B, 6] ç›®æ ‡poseå¢é‡  
            delta: HuberæŸå¤±çš„deltaå‚æ•°
            
        Returns:
            loss: scalar HuberæŸå¤±
        """
        return F.huber_loss(pred_pose, target_pose, delta=delta)
    
    def decompose_pose(self, pose_6dof: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        åˆ†è§£6DOF poseä¸ºå¹³ç§»å’Œæ—‹è½¬
        
        Args:
            pose_6dof: [B, 6] 6DOF pose
            
        Returns:
            translation: [B, 3] å¹³ç§»
            rotation: [B, 3] æ—‹è½¬ (è½´è§’è¡¨ç¤º)
        """
        translation = pose_6dof[:, :3]  # [B, 3]
        rotation = pose_6dof[:, 3:]     # [B, 3]
        return translation, rotation


class SE3Utils:
    """SE(3)å·¥å…·å‡½æ•°"""
    
    @staticmethod
    def se3_to_matrix(se3_vec: torch.Tensor) -> torch.Tensor:
        """
        å°†SE(3) 6ç»´å‘é‡è½¬æ¢ä¸º4x4å˜æ¢çŸ©é˜µ
        
        Args:
            se3_vec: [B, 6] SE(3)å‘é‡ [tx, ty, tz, rx, ry, rz]
            
        Returns:
            transform_matrix: [B, 4, 4] å˜æ¢çŸ©é˜µ
        """
        batch_size = se3_vec.shape[0]
        device = se3_vec.device
        
        # æå–å¹³ç§»å’Œæ—‹è½¬
        translation = se3_vec[:, :3]  # [B, 3]
        rotation_vec = se3_vec[:, 3:]  # [B, 3]
        
        # è®¡ç®—æ—‹è½¬è§’åº¦
        angle = torch.norm(rotation_vec, dim=1, keepdim=True)  # [B, 1]
        
        # é¿å…é™¤é›¶
        safe_angle = torch.where(angle < 1e-6, 
                                torch.ones_like(angle) * 1e-6, 
                                angle)
        
        # å½’ä¸€åŒ–æ—‹è½¬è½´
        axis = rotation_vec / safe_angle  # [B, 3]
        
        # ä½¿ç”¨Rodrigueså…¬å¼æ„å»ºæ—‹è½¬çŸ©é˜µ
        cos_angle = torch.cos(angle).unsqueeze(-1)  # [B, 1, 1]
        sin_angle = torch.sin(angle).unsqueeze(-1)  # [B, 1, 1]
        
        # å•ä½çŸ©é˜µ
        I = torch.eye(3, device=device).unsqueeze(0).repeat(batch_size, 1, 1)  # [B, 3, 3]
        
        # åå¯¹ç§°çŸ©é˜µ
        K = torch.zeros(batch_size, 3, 3, device=device)
        K[:, 0, 1] = -axis[:, 2]
        K[:, 0, 2] = axis[:, 1]
        K[:, 1, 0] = axis[:, 2]
        K[:, 1, 2] = -axis[:, 0]
        K[:, 2, 0] = -axis[:, 1]
        K[:, 2, 1] = axis[:, 0]
        
        # Rodrigueså…¬å¼: R = I + sin(Î¸)K + (1-cos(Î¸))KÂ²
        R = I + sin_angle * K + (1 - cos_angle) * torch.bmm(K, K)
        
        # æ„å»º4x4å˜æ¢çŸ©é˜µ
        transform_matrix = torch.zeros(batch_size, 4, 4, device=device)
        transform_matrix[:, :3, :3] = R
        transform_matrix[:, :3, 3] = translation
        transform_matrix[:, 3, 3] = 1.0
        
        return transform_matrix
    
    @staticmethod
    def matrix_to_se3(transform_matrix: torch.Tensor) -> torch.Tensor:
        """
        å°†4x4å˜æ¢çŸ©é˜µè½¬æ¢ä¸ºSE(3) 6ç»´å‘é‡
        
        Args:
            transform_matrix: [B, 4, 4] å˜æ¢çŸ©é˜µ
            
        Returns:
            se3_vec: [B, 6] SE(3)å‘é‡
        """
        batch_size = transform_matrix.shape[0]
        device = transform_matrix.device
        
        # æå–å¹³ç§»
        translation = transform_matrix[:, :3, 3]  # [B, 3]
        
        # æå–æ—‹è½¬çŸ©é˜µ
        R = transform_matrix[:, :3, :3]  # [B, 3, 3]
        
        # ä»æ—‹è½¬çŸ©é˜µè®¡ç®—è½´è§’è¡¨ç¤º
        trace = R.diagonal(dim1=1, dim2=2).sum(dim=1)  # [B]
        angle = torch.acos(torch.clamp((trace - 1) / 2, -1, 1))  # [B]
        
        # è®¡ç®—æ—‹è½¬è½´
        axis = torch.zeros(batch_size, 3, device=device)
        axis[:, 0] = R[:, 2, 1] - R[:, 1, 2]
        axis[:, 1] = R[:, 0, 2] - R[:, 2, 0]
        axis[:, 2] = R[:, 1, 0] - R[:, 0, 1]
        
        # å½’ä¸€åŒ–å¹¶ä¹˜ä»¥è§’åº¦
        axis_norm = torch.norm(axis, dim=1, keepdim=True)
        safe_norm = torch.where(axis_norm < 1e-6, 
                               torch.ones_like(axis_norm), 
                               axis_norm)
        rotation_vec = axis / safe_norm * angle.unsqueeze(-1)
        
        # æ‹¼æ¥SE(3)å‘é‡
        se3_vec = torch.cat([translation, rotation_vec], dim=1)  # [B, 6]
        
        return se3_vec


# æ¨¡å—æµ‹è¯•
if __name__ == '__main__':
    print("ğŸ§ª Testing PoseHead...")
    
    # åˆ›å»ºPoseHead
    pose_head = PoseHead(input_dim=512, hidden_dims=[256, 128])
    
    # æµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 100
    embed_dim = 512
    
    tokens = torch.randn(batch_size, seq_len, embed_dim)
    target_pose = torch.randn(batch_size, 6) * 0.1  # å°çš„poseå¢é‡
    
    print(f"Input tokens shape: {tokens.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        pred_pose = pose_head(tokens)
        print(f"Predicted pose shape: {pred_pose.shape}")
        print(f"Predicted pose sample: {pred_pose[0]}")
    
    # è®¡ç®—æŸå¤±
    pred_pose_grad = pose_head(tokens)
    loss = pose_head.compute_loss(pred_pose_grad, target_pose)
    print(f"Huber loss: {loss.item():.6f}")
    
    # æµ‹è¯•æ¢¯åº¦
    loss.backward()
    grad_norm = torch.norm(torch.cat([p.grad.flatten() for p in pose_head.parameters() if p.grad is not None]))
    print(f"Gradient norm: {grad_norm.item():.6f}")
    
    # æµ‹è¯•SE(3)å·¥å…·
    print("\nğŸ”§ Testing SE(3) utilities...")
    se3_vec = torch.randn(2, 6) * 0.1
    print(f"Original SE(3): {se3_vec}")
    
    transform_matrix = SE3Utils.se3_to_matrix(se3_vec)
    print(f"Transform matrix shape: {transform_matrix.shape}")
    
    recovered_se3 = SE3Utils.matrix_to_se3(transform_matrix)
    print(f"Recovered SE(3): {recovered_se3}")
    
    error = torch.norm(se3_vec - recovered_se3, dim=1)
    print(f"Reconstruction error: {error}")
    
    print("\nâœ… PoseHead test completed!")