"""
MineSLAM Unified Model
ç»Ÿä¸€çš„MineSLAMæ¨¡å‹ç±» - é›†æˆæ‰€æœ‰ç»„ä»¶å¹¶æä¾›å®Œæ•´çš„å‰å‘ä¼ æ’­
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple, Any
import warnings

from .encoders import MultiModalEncoder
from .moe_fusion import MoEFusion, MoEConfig
from .pose_head import PoseHead
from .detection_head import DetectionHead
from .kendall_uncertainty import create_fixed_kendall_uncertainty


class MineSLAMModel(nn.Module):
    """
    MineSLAMå®Œæ•´æ¨¡å‹
    é›†æˆå¤šæ¨¡æ€ç¼–ç ã€MoEèåˆã€å¤šä»»åŠ¡å¤´éƒ¨å’ŒKendallä¸ç¡®å®šæ€§
    """

    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–MineSLAMæ¨¡å‹

        Args:
            config: æ¨¡å‹é…ç½®å­—å…¸ï¼ŒåŒ…å«å„ç»„ä»¶å‚æ•°
        """
        super().__init__()

        # é»˜è®¤é…ç½®
        self.config = config or self._get_default_config()

        # 1. å¤šæ¨¡æ€ç¼–ç å™¨
        encoder_config = self.config.get('encoder', {})
        self.encoder = MultiModalEncoder(**encoder_config)

        # 2. MoEèåˆæ¨¡å—
        moe_config = self.config.get('moe_fusion', {})
        if isinstance(moe_config, dict):
            moe_config = MoEConfig(**moe_config)
        elif not isinstance(moe_config, MoEConfig):
            moe_config = MoEConfig()

        self.moe_fusion = MoEFusion(moe_config)

        # 3. ä»»åŠ¡å¤´éƒ¨
        pose_config = self.config.get('pose_head', {})
        self.pose_head = PoseHead(**pose_config)

        detection_config = self.config.get('detection_head', {})
        self.detection_head = DetectionHead(**detection_config)

        # 4. Kendallä¸ç¡®å®šæ€§æƒé‡ (ä½¿ç”¨ä¿®å¤ç‰ˆ)
        kendall_config = self.config.get('kendall_uncertainty', {})
        self.kendall_uncertainty = create_fixed_kendall_uncertainty(kendall_config)

        # æ¨¡å‹ä¿¡æ¯
        self.model_info = {
            'total_params': self._count_parameters(),
            'encoder_params': sum(p.numel() for p in self.encoder.parameters()),
            'moe_params': sum(p.numel() for p in self.moe_fusion.parameters()),
            'pose_head_params': sum(p.numel() for p in self.pose_head.parameters()),
            'detection_head_params': sum(p.numel() for p in self.detection_head.parameters()),
            'kendall_params': sum(p.numel() for p in self.kendall_uncertainty.parameters())
        }

        print(f"ğŸ—ï¸ MineSLAM Model initialized:")
        print(f"   Total parameters: {self.model_info['total_params']:,}")
        print(f"   Encoder: {self.model_info['encoder_params']:,}")
        print(f"   MoE Fusion: {self.model_info['moe_params']:,}")
        print(f"   Pose Head: {self.model_info['pose_head_params']:,}")
        print(f"   Detection Head: {self.model_info['detection_head_params']:,}")
        print(f"   Kendall Uncertainty: {self.model_info['kendall_params']:,}")

    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'encoder': {},
            'moe_fusion': {
                'embedding_dim': 512,
                'num_experts': 3,
                'num_encoder_layers': 2,
                'nhead': 4,
                'feedforward_dim': 2048,
                'dropout': 0.1,
                'thermal_guidance': True
            },
            'pose_head': {
                'input_dim': 512,
                'hidden_dims': [512, 256, 128],
                'dropout_rate': 0.1
            },
            'detection_head': {
                'input_dim': 512,
                'num_queries': 20,
                'num_classes': 8,
                'decoder_layers': 4,
                'nhead': 8,
                'dropout': 0.1
            },
            'kendall_uncertainty': {
                'initial_pose_log_var': -1.0,
                'initial_detection_log_var': 0.0,
                'initial_gate_log_var': -0.4,
                'enable_weight_constraints': True,
                'min_log_var': -2.0,
                'max_log_var': 2.0
            }
        }

    def forward(self, batch: Dict[str, torch.Tensor],
                return_intermediate: bool = False) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­

        Args:
            batch: è¾“å…¥æ‰¹æ¬¡æ•°æ®
            return_intermediate: æ˜¯å¦è¿”å›ä¸­é—´ç»“æœ

        Returns:
            è¾“å‡ºå­—å…¸ï¼ŒåŒ…å«ä½å§¿ã€æ£€æµ‹ç»“æœå’Œä¸­é—´ç‰¹å¾
        """
        outputs = {}

        # 1. å¤šæ¨¡æ€ç¼–ç 
        try:
            encoded_features = self.encoder(batch)
            if return_intermediate:
                outputs['encoded_features'] = encoded_features
        except Exception as e:
            warnings.warn(f"Encoder forward failed: {e}")
            # åˆ›å»ºé»˜è®¤ç‰¹å¾ç”¨äºè°ƒè¯•
            batch_size = list(batch.values())[0].shape[0] if batch else 1
            encoded_features = {
                'rgb': torch.zeros(batch_size, 512).to(self.device),
                'depth': torch.zeros(batch_size, 512).to(self.device),
                'thermal': torch.zeros(batch_size, 512).to(self.device),
                'lidar': torch.zeros(batch_size, 512).to(self.device),
                'imu': torch.zeros(batch_size, 512).to(self.device)
            }

        # 2. MoEèåˆ
        try:
            fused_features, moe_output = self.moe_fusion(encoded_features, batch)
            if return_intermediate:
                outputs['fused_features'] = fused_features
                outputs['moe_output'] = moe_output
        except Exception as e:
            warnings.warn(f"MoE fusion failed: {e}")
            # ä½¿ç”¨å¹³å‡èåˆä½œä¸ºå¤‡é€‰
            feature_tensors = [f for f in encoded_features.values() if isinstance(f, torch.Tensor)]
            if feature_tensors:
                fused_features = torch.stack(feature_tensors).mean(dim=0)
            else:
                fused_features = torch.zeros(batch_size, 512).to(self.device)
            moe_output = {}

        # 3. ä»»åŠ¡å¤´éƒ¨é¢„æµ‹
        # ä½å§¿ä¼°è®¡
        pose_output = self.pose_head(fused_features)
        outputs['pose'] = pose_output

        # ç‰©ä½“æ£€æµ‹
        detection_output = self.detection_head(fused_features)
        outputs['detection'] = detection_output

        # 4. æ·»åŠ MoEåˆ†æç»“æœ
        if moe_output:
            outputs['moe_analysis'] = moe_output

        return outputs

    def compute_loss(self, model_output: Dict[str, torch.Tensor],
                    targets: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å¤šä»»åŠ¡æŸå¤±

        Args:
            model_output: æ¨¡å‹è¾“å‡º
            targets: çœŸå€¼æ ‡ç­¾

        Returns:
            æŸå¤±å­—å…¸
        """
        # æå–å„ä»»åŠ¡é¢„æµ‹å’ŒçœŸå€¼
        pose_pred = model_output['pose']
        detection_pred = model_output['detection']

        pose_target = targets.get('pose', torch.zeros_like(pose_pred))
        detection_target = targets.get('detection', {})

        # è®¡ç®—åŸå§‹æŸå¤±
        pose_loss = F.mse_loss(pose_pred, pose_target)

        # æ£€æµ‹æŸå¤± (ç®€åŒ–å®ç°)
        if 'classes' in detection_pred and 'classes' in detection_target:
            detection_loss = F.cross_entropy(
                detection_pred['classes'].flatten(0, 1),
                detection_target['classes'].flatten().long()
            )
        else:
            detection_loss = torch.tensor(0.0, device=pose_pred.device)

        # MoEé—¨æ§æŸå¤±
        moe_output = model_output.get('moe_analysis', {})
        gate_loss = moe_output.get('gate_loss', torch.tensor(0.0, device=pose_pred.device))

        # ä½¿ç”¨ä¿®å¤ç‰ˆKendallä¸ç¡®å®šæ€§æƒé‡
        kendall_result = self.kendall_uncertainty.compute_multitask_loss(
            pose_loss, detection_loss, gate_loss
        )

        return {
            'total_loss': kendall_result['total_loss'],
            'pose_loss': pose_loss,
            'detection_loss': detection_loss,
            'gate_loss': gate_loss,
            'weighted_pose_loss': kendall_result['weighted_pose_loss'],
            'weighted_detection_loss': kendall_result['weighted_detection_loss'],
            'weighted_gate_loss': kendall_result['weighted_gate_loss'],
            'kendall_weights': {
                'pose_weight': kendall_result['pose_weight'],
                'detection_weight': kendall_result['detection_weight'],
                'gate_weight': kendall_result['gate_weight'],
                'pose_sigma': kendall_result['pose_sigma'],
                'detection_sigma': kendall_result['detection_sigma'],
                'gate_sigma': kendall_result['gate_sigma']
            }
        }

    def get_model_summary(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹æ‘˜è¦ä¿¡æ¯"""
        return {
            'model_name': 'MineSLAM',
            'version': '1.0.0',
            'parameters': self.model_info,
            'components': {
                'encoder': type(self.encoder).__name__,
                'moe_fusion': type(self.moe_fusion).__name__,
                'pose_head': type(self.pose_head).__name__,
                'detection_head': type(self.detection_head).__name__,
                'kendall_uncertainty': type(self.kendall_uncertainty).__name__
            },
            'config': self.config
        }

    def _count_parameters(self) -> int:
        """è®¡ç®—æ€»å‚æ•°æ•°é‡"""
        return sum(p.numel() for p in self.parameters() if p.requires_grad)

    @property
    def device(self) -> torch.device:
        """è·å–æ¨¡å‹è®¾å¤‡"""
        return next(self.parameters()).device

    def print_kendall_status(self, epoch: int = None):
        """æ‰“å°Kendallæƒé‡çŠ¶æ€"""
        self.kendall_uncertainty.print_status(epoch)

    def get_kendall_weights(self) -> Dict[str, float]:
        """è·å–å½“å‰Kendallæƒé‡"""
        return self.kendall_uncertainty.get_weights()

    def get_weight_balance_metrics(self) -> Dict[str, float]:
        """è·å–æƒé‡å¹³è¡¡æŒ‡æ ‡"""
        return self.kendall_uncertainty.get_weight_balance_metrics()

    def save_model(self, path: str, additional_info: Dict = None):
        """ä¿å­˜æ¨¡å‹"""
        save_dict = {
            'model_state_dict': self.state_dict(),
            'model_config': self.config,
            'model_info': self.model_info,
            'model_summary': self.get_model_summary()
        }

        if additional_info:
            save_dict.update(additional_info)

        torch.save(save_dict, path)
        print(f"ğŸ’¾ MineSLAM model saved to: {path}")

    @classmethod
    def load_model(cls, path: str, device: str = 'cuda'):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(path, map_location=device)

        config = checkpoint.get('model_config', {})
        model = cls(config)

        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])

        model.to(device)
        print(f"ğŸ“‚ MineSLAM model loaded from: {path}")

        return model, checkpoint


def create_mineslam_model(config: Dict[str, Any] = None) -> MineSLAMModel:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºMineSLAMæ¨¡å‹

    Args:
        config: æ¨¡å‹é…ç½®

    Returns:
        MineSLAMæ¨¡å‹å®ä¾‹
    """
    return MineSLAMModel(config)


# å‘åå…¼å®¹
MineSLAM = MineSLAMModel


if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹åˆ›å»º
    print("ğŸ§ª Testing MineSLAM Model Creation...")

    model = create_mineslam_model()
    print(f"âœ… Model created successfully")

    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 2
    dummy_batch = {
        'rgb': torch.randn(batch_size, 3, 224, 224),
        'depth': torch.randn(batch_size, 1, 224, 224),
        'thermal': torch.randn(batch_size, 1, 224, 224),
        'lidar': torch.randn(batch_size, 16384, 3),
        'imu': torch.randn(batch_size, 6)
    }

    try:
        with torch.no_grad():
            outputs = model(dummy_batch, return_intermediate=True)

        print(f"âœ… Forward pass successful")
        print(f"   Output keys: {list(outputs.keys())}")

        # æµ‹è¯•æŸå¤±è®¡ç®—
        dummy_targets = {
            'pose': torch.randn(batch_size, 6),
            'detection': {
                'classes': torch.randint(0, 8, (batch_size, 20)),
                'boxes': torch.randn(batch_size, 20, 6)
            }
        }

        loss_dict = model.compute_loss(outputs, dummy_targets)
        print(f"âœ… Loss computation successful")
        print(f"   Total loss: {loss_dict['total_loss']:.6f}")

        # æ‰“å°æ¨¡å‹æ‘˜è¦
        summary = model.get_model_summary()
        print(f"âœ… Model summary: {summary['parameters']['total_params']:,} parameters")

    except Exception as e:
        print(f"âŒ Forward pass failed: {e}")
        import traceback
        traceback.print_exc()

    print("âœ… MineSLAM Model test completed!")